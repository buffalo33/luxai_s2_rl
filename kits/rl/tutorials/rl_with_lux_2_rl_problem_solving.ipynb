{
  "cells": [
    {
      "source": [
        "<a href=\"https://www.kaggle.com/code/stonet2000/rl-with-lux-2-rl-problem-solving?scriptVersionId=119773123\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>"
      ],
      "metadata": {
        "id": "dCvKz-1pPPct"
      },
      "cell_type": "markdown",
      "id": "dCvKz-1pPPct"
    },
    {
      "cell_type": "markdown",
      "id": "0379e2a6",
      "metadata": {
        "papermill": {
          "duration": 0.009234,
          "end_time": "2023-02-20T17:41:11.511182",
          "exception": false,
          "start_time": "2023-02-20T17:41:11.501948",
          "status": "completed"
        },
        "tags": [],
        "id": "0379e2a6"
      },
      "source": [
        "## Setup Code\n",
        "\n",
        "Before we start lets install some dependencies. This will also run some extra code that your local notebook may not need to due to how Kaggle Notebooks are setup. **Note that this tutorial is only using the CPU luxai_s2 engine, the jax version will be released later**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "DRIVE_PATH = '/content/gdrive/My\\ Drive/Lux-Design-S2'\n",
        "DRIVE_PYTHON_PATH = DRIVE_PATH.replace('\\\\', '')\n",
        "if not os.path.exists(DRIVE_PYTHON_PATH):\n",
        "  %mkdir $DRIVE_PATH\n",
        "\n",
        "## the space in `My Drive` causes some issues,\n",
        "## make a symlink to avoid this\n",
        "SYM_PATH = '/content/Lux-Design-S2'\n",
        "if not os.path.exists(SYM_PATH):\n",
        "  !ln -s $DRIVE_PATH $SYM_PATH\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wk6Nh7kAYfUv",
        "outputId": "caa49b87-53e6-43a2-8515-a5c631190217"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "id": "wk6Nh7kAYfUv"
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/Lux-Design-S2/kits/rl/sb3'\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0BnwfAvKMud",
        "outputId": "0549f0bb-a208-4374-a1ec-14ef1da14993"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/Lux-Design-S2/kits/rl/sb3\n",
            "/content/gdrive/My Drive/Lux-Design-S2/kits/rl/sb3\n"
          ]
        }
      ],
      "id": "k0BnwfAvKMud"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f3ec560e",
      "metadata": {
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2023-02-20T17:41:11.530127Z",
          "iopub.status.busy": "2023-02-20T17:41:11.529248Z",
          "iopub.status.idle": "2023-02-20T17:42:14.774076Z",
          "shell.execute_reply": "2023-02-20T17:42:14.771884Z"
        },
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": true
        },
        "papermill": {
          "duration": 63.25777,
          "end_time": "2023-02-20T17:42:14.77696",
          "exception": false,
          "start_time": "2023-02-20T17:41:11.51919",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3ec560e",
        "outputId": "8fcf07f0-c90a-4ed9-caa6-ed671cef46c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting setuptools==65.5.0\n",
            "  Downloading setuptools-65.5.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: setuptools\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 67.6.0\n",
            "    Uninstalling setuptools-67.6.0:\n",
            "      Successfully uninstalled setuptools-67.6.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\n",
            "cvxpy 1.3.1 requires setuptools>65.5.1, but you have setuptools 65.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed setuptools-65.5.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting luxai_s2\n",
            "  Downloading luxai_s2-2.1.9-py3-none-any.whl (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.2/63.2 KB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from luxai_s2) (3.7.1)\n",
            "Collecting pettingzoo\n",
            "  Downloading pettingzoo-1.22.4-py3-none-any.whl (822 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m822.8/822.8 KB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from luxai_s2) (1.10.1)\n",
            "Collecting importlib-metadata<5.0\n",
            "  Downloading importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\n",
            "Collecting vec-noise\n",
            "  Downloading vec_noise-1.1.4.zip (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.1/134.1 KB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gym==0.21.0\n",
            "  Downloading gym-0.21.0.tar.gz (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.9/dist-packages (from luxai_s2) (2.2.0)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.9/dist-packages (from luxai_s2) (2.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from luxai_s2) (1.22.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from gym==0.21.0->luxai_s2) (2.2.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata<5.0->luxai_s2) (3.15.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->luxai_s2) (8.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->luxai_s2) (1.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->luxai_s2) (2.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->luxai_s2) (23.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->luxai_s2) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->luxai_s2) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->luxai_s2) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->luxai_s2) (4.39.2)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->luxai_s2) (5.12.0)\n",
            "Collecting gymnasium>=0.26.0\n",
            "  Downloading gymnasium-0.28.1-py3-none-any.whl (925 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m925.5/925.5 KB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting farama-notifications>=0.0.1\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Collecting jax-jumpy>=1.0.0\n",
            "  Downloading jax_jumpy-1.0.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.9/dist-packages (from gymnasium>=0.26.0->pettingzoo->luxai_s2) (4.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib->luxai_s2) (1.16.0)\n",
            "Building wheels for collected packages: gym, vec-noise\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for gym\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for gym\n",
            "  Building wheel for vec-noise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for vec-noise: filename=vec_noise-1.1.4-cp39-cp39-linux_x86_64.whl size=83924 sha256=e6cccdcbc0f76bca4c60706b07b2b8bf9d03115b3cb6afc2cf0958e253e84d87\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/e4/27/255c85b3043fd94a3fd1b36b7dbdca5ee30ed4a442b544707d\n",
            "Successfully built vec-noise\n",
            "Failed to build gym\n",
            "Installing collected packages: farama-notifications, vec-noise, jax-jumpy, importlib-metadata, gym, gymnasium, pettingzoo, luxai_s2\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 6.1.0\n",
            "    Uninstalling importlib-metadata-6.1.0:\n",
            "      Successfully uninstalled importlib-metadata-6.1.0\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "  Running setup.py install for gym ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  DEPRECATION: gym was installed using the legacy 'setup.py install' method, because a wheel could not be built for it. A possible replacement is to fix the wheel build issue reported above. Discussion can be found at https://github.com/pypa/pip/issues/8368\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed farama-notifications-0.0.4 gym-0.21.0 gymnasium-0.28.1 importlib-metadata-4.13.0 jax-jumpy-1.0.0 luxai_s2-2.1.9 pettingzoo-1.22.4 vec-noise-1.1.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pettingzoo==1.12.0\n",
            "  Downloading PettingZoo-1.12.0.tar.gz (756 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.1/756.1 KB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: gym==0.21.0 in /usr/local/lib/python3.9/dist-packages (0.21.0)\n",
            "Collecting stable-baselines3\n",
            "  Downloading stable_baselines3-1.7.0-py3-none-any.whl (171 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.8/171.8 KB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.9/dist-packages (from pettingzoo==1.12.0) (1.22.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from gym==0.21.0) (2.2.1)\n",
            "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.9/dist-packages (from stable-baselines3) (1.13.1+cu116)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from stable-baselines3) (1.4.4)\n",
            "Requirement already satisfied: importlib-metadata~=4.13 in /usr/local/lib/python3.9/dist-packages (from stable-baselines3) (4.13.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from stable-baselines3) (3.7.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata~=4.13->stable-baselines3) (3.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.11->stable-baselines3) (4.5.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable-baselines3) (8.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable-baselines3) (23.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable-baselines3) (4.39.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable-baselines3) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable-baselines3) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable-baselines3) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable-baselines3) (2.8.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable-baselines3) (1.0.7)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable-baselines3) (5.12.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->stable-baselines3) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.16.0)\n",
            "Building wheels for collected packages: pettingzoo\n",
            "  Building wheel for pettingzoo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pettingzoo: filename=PettingZoo-1.12.0-py3-none-any.whl size=873582 sha256=cad560000632ff00fcd75b9b517084cc73f425752d031eaa249ffb1baeb30b0c\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/7f/39/9b8a0503cd032e71cfab712afd8b1c36b1f4aa9b8864c9cf24\n",
            "Successfully built pettingzoo\n",
            "Installing collected packages: pettingzoo, stable-baselines3\n",
            "  Attempting uninstall: pettingzoo\n",
            "    Found existing installation: pettingzoo 1.22.4\n",
            "    Uninstalling pettingzoo-1.22.4:\n",
            "      Successfully uninstalled pettingzoo-1.22.4\n",
            "Successfully installed pettingzoo-1.12.0 stable-baselines3-1.7.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: importlib_metadata<5.0 in /usr/local/lib/python3.9/dist-packages (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib_metadata<5.0) (3.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install setuptools==65.5.0\n",
        "!pip install --upgrade luxai_s2\n",
        "!pip install pettingzoo==1.12.0 gym==0.21.0 stable-baselines3\n",
        "!pip install --upgrade \"importlib_metadata<5.0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ce6ed1d0",
      "metadata": {
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "execution": {
          "iopub.execute_input": "2023-02-20T17:42:14.864881Z",
          "iopub.status.busy": "2023-02-20T17:42:14.86421Z",
          "iopub.status.idle": "2023-02-20T17:42:14.890829Z",
          "shell.execute_reply": "2023-02-20T17:42:14.888594Z"
        },
        "jupyter": {
          "source_hidden": true
        },
        "papermill": {
          "duration": 0.049253,
          "end_time": "2023-02-20T17:42:14.893349",
          "exception": false,
          "start_time": "2023-02-20T17:42:14.844096",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce6ed1d0",
        "outputId": "543da244-3553-4d17-f5b7-1d1365ccae48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[autoreload of pkg_resources.extern.packaging.specifiers failed: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
            "    superreload(m, reload, self.old_objects)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/IPython/extensions/autoreload.py\", line 410, in superreload\n",
            "    update_generic(old_obj, new_obj)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n",
            "    update(a, b)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/IPython/extensions/autoreload.py\", line 302, in update_class\n",
            "    if update_generic(old_obj, new_obj): continue\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n",
            "    update(a, b)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/IPython/extensions/autoreload.py\", line 266, in update_function\n",
            "    setattr(old, name, getattr(new, name))\n",
            "ValueError: _compare_compatible() requires a code object with 0 free vars, not 1\n",
            "]\n",
            "[autoreload of pkg_resources failed: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
            "    superreload(m, reload, self.old_objects)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/IPython/extensions/autoreload.py\", line 394, in superreload\n",
            "    module = reload(module)\n",
            "  File \"/usr/lib/python3.9/imp.py\", line 314, in reload\n",
            "    return importlib.reload(module)\n",
            "  File \"/usr/lib/python3.9/importlib/__init__.py\", line 169, in reload\n",
            "    _bootstrap._exec(spec, module)\n",
            "  File \"<frozen importlib._bootstrap>\", line 613, in _exec\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 850, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 228, in _call_with_frames_removed\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pkg_resources/__init__.py\", line 3095, in <module>\n",
            "    class RequirementParseError(packaging.requirements.InvalidRequirement):\n",
            "AttributeError: module 'pkg_resources._vendor.packaging' has no attribute 'requirements'\n",
            "]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'importlib_metadata' from '/usr/local/lib/python3.9/dist-packages/importlib_metadata/__init__.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import importlib\n",
        "import importlib_metadata\n",
        "# kaggle has 6.0.0 installed but we need version <5.0\n",
        "importlib.reload(importlib_metadata)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "937c61c2",
      "metadata": {
        "papermill": {
          "duration": 0.013417,
          "end_time": "2023-02-20T17:42:14.922104",
          "exception": false,
          "start_time": "2023-02-20T17:42:14.908687",
          "status": "completed"
        },
        "tags": [],
        "id": "937c61c2"
      },
      "source": [
        "# Reinforcement Learning for Lux AI Season 2 🤖\n",
        "\n",
        "Part 2 of the RL series will now dig into building a working RL agent for the Lux AI Challenge, Season 2!\n",
        "\n",
        "Lux AI is designed to be intuitive to understand, but heavily layered in complexity and interactions of game mechanics in an multi-agent cooperative and competitive environment. \n",
        "\n",
        "Lux AI Season 2's rules can be found here: https://www.lux-ai.org/specs-s2. Make sure to read them to learn how to the game works, and the rest of this tutorial will be much easier to understand.\n",
        "\n",
        "Part 1 of the series covered the single-agent RL setup, but Lux AI Season 2 is multi-agent! Moreover, the environment has different phases and a complex action space which makes it difficult to learn or use of the box. \n",
        "\n",
        "This tutorial will cover simple tools and tricks on how to reduce a complex problem into a easier one! We will primarily focus on three things: \n",
        "\n",
        "1. Simplifying the action space with controllers/action wrappers\n",
        "2. Simplifying observations\n",
        "3. Transforming the three phase Lux AI game into a single phase game\n",
        "\n",
        "Ultimately this will modify the standard RL diagram into one that is \"single-agent\", with modified observations and actions:\n",
        "\n",
        "![](https://github.com/Lux-AI-Challenge/Lux-Design-S2/raw/main/docs/assets/anatomyluxrl.png)\n",
        "\n",
        "\n",
        "This starter kit is also implemented in https://github.com/Lux-AI-Challenge/Lux-Design-S2/tree/main/kits/rl/sb3\n",
        "\n",
        "We highly **recommend running this code with more CPU cores** as RL training can be fairly slow and needs good tuning. A GPU can also speed up the optimization part of RL training, but the rollout/interaction phase is CPU heavy in this tutorial and is typically the bottleneck.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "812fa344",
      "metadata": {
        "papermill": {
          "duration": 0.014833,
          "end_time": "2023-02-20T17:42:14.951054",
          "exception": false,
          "start_time": "2023-02-20T17:42:14.936221",
          "status": "completed"
        },
        "tags": [],
        "id": "812fa344"
      },
      "source": [
        "## 1. Simplifying the Action Space\n",
        "\n",
        "The action space is quite complicated in Lux S2 as each robot can move, dig, transfer/pickup, all in addition to being able to combine any sequence of these primitives into an action queue of up to length 20. For machine learning, such a massive action space leads to the [curse of dimensionality](https://en.wikipedia.org/wiki/Curse_of_dimensionality), making any ML algorithm have a much harder time to learn something useful, especially in RL.\n",
        "\n",
        "To handle this, we can program a custom Controller that translates actions from one action space to the original action space and adds a few tricks and heuristics to be integrated with RL training. Since the original lux action space is large, this controller can be a little complicated. For those who want to dive straight into training you can use the controller as is. \n",
        "\n",
        "For a high-level overview this controller will\n",
        "- Define a massively simplified action space\n",
        "- Translate actions from the discrete action space into the Lux S2 action space `action_to_lux_action`\n",
        "- Add a heuristic factory action to build one Heavy robot\n",
        "- Generate action masks where False = an action is invalid\n",
        "\n",
        "Overall, the action space of the controller is a discrete action space with just 12 dimensions to control just one heavy robot. It allows for a robot's 4 directional movement, transferring ice in 4 directions in addition to center, picking up power, digging, and a no-op action. This doesn't include factory actions, self destruct, recharging, transferring other types of resources, or longer planned action queues in the action space, which are all open problems for you to potentially tackle!\n",
        "\n",
        "The controller also includes a trick to allow agents to reduce power costs incurred by action queue updates. The controller skips updating action queues if the existing action queue is the same as the new one the agent wants to use for the robot.\n",
        "\n",
        "While this simplification doesn't include adding in more complex things like more heavy robots or planting lichen, it will train out a succesful policy that with simple modifications, will beat the majority of bots using the rule-based starter kits.\n",
        "\n",
        "More advanced usages can consider how to model the actions of different types of units on a game board (e.g. heavy, light, or factory) by using a MultiDiscrete action space. A more practical and likely winning solution can be to use a image-like controller by generating actions for each tile on the board and only using the actions with friendly units on that tile. See [Season 1's solution by ToadBrigade](https://www.kaggle.com/competitions/lux-ai-2021/discussion/294993) and our previous [research paper: Emergent Collective Intelligence from Massive-Agent Cooperation and Competition](https://arxiv.org/abs/2301.01609) for how a image-like controller can work.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52590cd6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T17:42:14.98113Z",
          "iopub.status.busy": "2023-02-20T17:42:14.980563Z",
          "iopub.status.idle": "2023-02-20T17:42:15.330392Z",
          "shell.execute_reply": "2023-02-20T17:42:15.328998Z"
        },
        "papermill": {
          "duration": 0.368491,
          "end_time": "2023-02-20T17:42:15.333537",
          "exception": false,
          "start_time": "2023-02-20T17:42:14.965046",
          "status": "completed"
        },
        "tags": [],
        "id": "52590cd6"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "from typing import Any, Dict\n",
        "\n",
        "import numpy as np\n",
        "import numpy.typing as npt\n",
        "from gym import spaces\n",
        "\n",
        "\n",
        "# Controller class copied here since you won't have access to the luxai_s2 package directly on the competition server\n",
        "class Controller:\n",
        "    def __init__(self, action_space: spaces.Space) -> None:\n",
        "        self.action_space = action_space\n",
        "\n",
        "    def action_to_lux_action(\n",
        "        self, agent: str, obs: Dict[str, Any], action: npt.NDArray\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Takes as input the current \"raw observation\" and the parameterized action and returns\n",
        "        an action formatted for the Lux env\n",
        "        \"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def action_masks(self, agent: str, obs: Dict[str, Any]):\n",
        "        \"\"\"\n",
        "        Generates a boolean action mask indicating in each discrete dimension whether it would be valid or not\n",
        "        \"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "class SimpleUnitDiscreteController(Controller):\n",
        "    def __init__(self, env_cfg) -> None:\n",
        "        \"\"\"\n",
        "        A simple controller that controls only the robot that will get spawned.\n",
        "        Moreover, it will always try to spawn one heavy robot if there are none regardless of action given\n",
        "\n",
        "        For the robot unit\n",
        "        - 4 cardinal direction movement (4 dims)\n",
        "        - a move center no-op action (1 dim)\n",
        "        - transfer action just for transferring ice in 4 cardinal directions or center (5)\n",
        "        - pickup action for power (1 dims)\n",
        "        - dig action (1 dim)\n",
        "        - no op action (1 dim) - equivalent to not submitting an action queue which costs power\n",
        "\n",
        "        It does not include\n",
        "        - self destruct action\n",
        "        - recharge action\n",
        "        - planning (via actions executing multiple times or repeating actions)\n",
        "        - factory actions\n",
        "        - transferring power or resources other than ice\n",
        "\n",
        "        To help understand how to this controller works to map one action space to the original lux action space,\n",
        "        see how the lux action space is defined in luxai_s2/spaces/action.py\n",
        "\n",
        "        \"\"\"\n",
        "        self.env_cfg = env_cfg\n",
        "        self.move_act_dims = 4\n",
        "        self.transfer_act_dims = 5\n",
        "        self.pickup_act_dims = 1\n",
        "        self.dig_act_dims = 1\n",
        "        self.no_op_dims = 1\n",
        "\n",
        "        self.move_dim_high = self.move_act_dims\n",
        "        self.transfer_dim_high = self.move_dim_high + self.transfer_act_dims\n",
        "        self.pickup_dim_high = self.transfer_dim_high + self.pickup_act_dims\n",
        "        self.dig_dim_high = self.pickup_dim_high + self.dig_act_dims\n",
        "        self.no_op_dim_high = self.dig_dim_high + self.no_op_dims\n",
        "\n",
        "        self.total_act_dims = self.no_op_dim_high\n",
        "        action_space = spaces.Discrete(self.total_act_dims)\n",
        "        super().__init__(action_space)\n",
        "\n",
        "    def _is_move_action(self, id):\n",
        "        return id < self.move_dim_high\n",
        "\n",
        "    def _get_move_action(self, id):\n",
        "        # move direction is id + 1 since we don't allow move center here\n",
        "        return np.array([0, id + 1, 0, 0, 0, 1])\n",
        "\n",
        "    def _is_transfer_action(self, id):\n",
        "        return id < self.transfer_dim_high\n",
        "\n",
        "    def _get_transfer_action(self, id):\n",
        "        id = id - self.move_dim_high\n",
        "        transfer_dir = id % 5\n",
        "        return np.array([1, transfer_dir, 0, self.env_cfg.max_transfer_amount, 0, 1])\n",
        "\n",
        "    def _is_pickup_action(self, id):\n",
        "        return id < self.pickup_dim_high\n",
        "\n",
        "    def _get_pickup_action(self, id):\n",
        "        return np.array([2, 0, 4, self.env_cfg.max_transfer_amount, 0, 1])\n",
        "\n",
        "    def _is_dig_action(self, id):\n",
        "        return id < self.dig_dim_high\n",
        "\n",
        "    def _get_dig_action(self, id):\n",
        "        return np.array([3, 0, 0, 0, 0, 1])\n",
        "\n",
        "    def action_to_lux_action(\n",
        "        self, agent: str, obs: Dict[str, Any], action: npt.NDArray\n",
        "    ):\n",
        "        shared_obs = obs[\"player_0\"]\n",
        "        lux_action = dict()\n",
        "        units = shared_obs[\"units\"][agent]\n",
        "        for unit_id in units.keys():\n",
        "            unit = units[unit_id]\n",
        "            choice = action\n",
        "            action_queue = []\n",
        "            no_op = False\n",
        "            if self._is_move_action(choice):\n",
        "                action_queue = [self._get_move_action(choice)]\n",
        "            elif self._is_transfer_action(choice):\n",
        "                action_queue = [self._get_transfer_action(choice)]\n",
        "            elif self._is_pickup_action(choice):\n",
        "                action_queue = [self._get_pickup_action(choice)]\n",
        "            elif self._is_dig_action(choice):\n",
        "                action_queue = [self._get_dig_action(choice)]\n",
        "            else:\n",
        "                # action is a no_op, so we don't update the action queue\n",
        "                no_op = True\n",
        "\n",
        "            # simple trick to help agents conserve power is to avoid updating the action queue\n",
        "            # if the agent was previously trying to do that particular action already\n",
        "            if len(unit[\"action_queue\"]) > 0 and len(action_queue) > 0:\n",
        "                same_actions = (unit[\"action_queue\"][0] == action_queue[0]).all()\n",
        "                if same_actions:\n",
        "                    no_op = True\n",
        "            if not no_op:\n",
        "                lux_action[unit_id] = action_queue\n",
        "\n",
        "            break\n",
        "\n",
        "        factories = shared_obs[\"factories\"][agent]\n",
        "        if len(units) == 0:\n",
        "            for unit_id in factories.keys():\n",
        "                lux_action[unit_id] = 1  # build a single heavy\n",
        "\n",
        "        return lux_action\n",
        "\n",
        "    def action_masks(self, agent: str, obs: Dict[str, Any]):\n",
        "        \"\"\"\n",
        "        Defines a simplified action mask for this controller's action space\n",
        "\n",
        "        Doesn't account for whether robot has enough power\n",
        "        \"\"\"\n",
        "\n",
        "        # compute a factory occupancy map that will be useful for checking if a board tile\n",
        "        # has a factory and which team's factory it is.\n",
        "        shared_obs = obs[agent]\n",
        "        factory_occupancy_map = (\n",
        "            np.ones_like(shared_obs[\"board\"][\"rubble\"], dtype=int) * -1\n",
        "        )\n",
        "        factories = dict()\n",
        "        for player in shared_obs[\"factories\"]:\n",
        "            factories[player] = dict()\n",
        "            for unit_id in shared_obs[\"factories\"][player]:\n",
        "                f_data = shared_obs[\"factories\"][player][unit_id]\n",
        "                f_pos = f_data[\"pos\"]\n",
        "                # store in a 3x3 space around the factory position it's strain id.\n",
        "                factory_occupancy_map[\n",
        "                    f_pos[0] - 1 : f_pos[0] + 2, f_pos[1] - 1 : f_pos[1] + 2\n",
        "                ] = f_data[\"strain_id\"]\n",
        "\n",
        "        units = shared_obs[\"units\"][agent]\n",
        "        action_mask = np.zeros((self.total_act_dims), dtype=bool)\n",
        "        for unit_id in units.keys():\n",
        "            action_mask = np.zeros(self.total_act_dims)\n",
        "            # movement is always valid\n",
        "            action_mask[:4] = True\n",
        "\n",
        "            # transferring is valid only if the target exists\n",
        "            unit = units[unit_id]\n",
        "            pos = np.array(unit[\"pos\"])\n",
        "            # a[1] = direction (0 = center, 1 = up, 2 = right, 3 = down, 4 = left)\n",
        "            move_deltas = np.array([[0, 0], [0, -1], [1, 0], [0, 1], [-1, 0]])\n",
        "            for i, move_delta in enumerate(move_deltas):\n",
        "                transfer_pos = np.array(\n",
        "                    [pos[0] + move_delta[0], pos[1] + move_delta[1]]\n",
        "                )\n",
        "                # check if theres a factory tile there\n",
        "                if (\n",
        "                    transfer_pos[0] < 0\n",
        "                    or transfer_pos[1] < 0\n",
        "                    or transfer_pos[0] >= len(factory_occupancy_map)\n",
        "                    or transfer_pos[1] >= len(factory_occupancy_map[0])\n",
        "                ):\n",
        "                    continue\n",
        "                factory_there = factory_occupancy_map[transfer_pos[0], transfer_pos[1]]\n",
        "                if factory_there in shared_obs[\"teams\"][agent][\"factory_strains\"]:\n",
        "                    action_mask[\n",
        "                        self.transfer_dim_high - self.transfer_act_dims + i\n",
        "                    ] = True\n",
        "\n",
        "            factory_there = factory_occupancy_map[pos[0], pos[1]]\n",
        "            on_top_of_factory = (\n",
        "                factory_there in shared_obs[\"teams\"][agent][\"factory_strains\"]\n",
        "            )\n",
        "\n",
        "            # dig is valid only if on top of tile with rubble or resources or lichen\n",
        "            board_sum = (\n",
        "                shared_obs[\"board\"][\"ice\"][pos[0], pos[1]]\n",
        "                + shared_obs[\"board\"][\"ore\"][pos[0], pos[1]]\n",
        "                + shared_obs[\"board\"][\"rubble\"][pos[0], pos[1]]\n",
        "                + shared_obs[\"board\"][\"lichen\"][pos[0], pos[1]]\n",
        "            )\n",
        "            if board_sum > 0 and not on_top_of_factory:\n",
        "                action_mask[\n",
        "                    self.dig_dim_high - self.dig_act_dims : self.dig_dim_high\n",
        "                ] = True\n",
        "\n",
        "            # pickup is valid only if on top of factory tile\n",
        "            if on_top_of_factory:\n",
        "                action_mask[\n",
        "                    self.pickup_dim_high - self.pickup_act_dims : self.pickup_dim_high\n",
        "                ] = True\n",
        "                action_mask[\n",
        "                    self.dig_dim_high - self.dig_act_dims : self.dig_dim_high\n",
        "                ] = False\n",
        "\n",
        "            # no-op is always valid\n",
        "            action_mask[-1] = True\n",
        "            break\n",
        "        return action_mask\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b60e0548",
      "metadata": {
        "papermill": {
          "duration": 0.012872,
          "end_time": "2023-02-20T17:42:15.360409",
          "exception": false,
          "start_time": "2023-02-20T17:42:15.347537",
          "status": "completed"
        },
        "tags": [],
        "id": "b60e0548"
      },
      "source": [
        "## 2. Simplifying the Observation Space\n",
        "\n",
        "Lux S2 is fully observable which means you can see everything on the map, the opponents units etc. However, this is very high dimensional and not necessarily easy to learn from due to the curse of dimensionality (again!). We want to simplify this observation space in a way that contains sufficient information to learn a good policy but is also easy to learn from.\n",
        "\n",
        "For this tutorial, we will create a state-based observation space (no image like features e.g. the rubble, ice, ore maps) with some feature engineering that includes useful information such as the distance to the closest factory and ice tile. The wrapper we provide below will use the `gym.ObservationWrapper` interface. Note that since we are focusing on just controlling one heavy robot, the observation wrapper is written to only support one heavy robot (and returns 0 if there are none).\n",
        "\n",
        "\n",
        "More advanced solutions can look into using the full set of observations and designing the appropriate neural net architecture to process them. One idea would be to use convolutional neural networks to process board features like images. See [Season 1's solution by ToadBrigade](https://www.kaggle.com/competitions/lux-ai-2021/discussion/294993) and our previous [research paper: Emergent Collective Intelligence from Massive-Agent Cooperation and Competition](https://arxiv.org/abs/2301.01609) for example architectures and feature engineering choices.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d576905",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T17:42:15.388868Z",
          "iopub.status.busy": "2023-02-20T17:42:15.388433Z",
          "iopub.status.idle": "2023-02-20T17:42:15.404822Z",
          "shell.execute_reply": "2023-02-20T17:42:15.403856Z"
        },
        "papermill": {
          "duration": 0.033753,
          "end_time": "2023-02-20T17:42:15.407287",
          "exception": false,
          "start_time": "2023-02-20T17:42:15.373534",
          "status": "completed"
        },
        "tags": [],
        "id": "4d576905"
      },
      "outputs": [],
      "source": [
        "from typing import Any, Dict\n",
        "\n",
        "import gym\n",
        "import numpy as np\n",
        "import numpy.typing as npt\n",
        "from gym import spaces\n",
        "\n",
        "\n",
        "class SimpleUnitObservationWrapper(gym.ObservationWrapper):\n",
        "    \"\"\"\n",
        "    A simple state based observation to work with in pair with the SimpleUnitDiscreteController\n",
        "\n",
        "    It contains info only on the first robot, the first factory you own, and some useful features. If there are no owned robots the observation is just zero.\n",
        "    No information about the opponent is included. This will generate observations for all teams.\n",
        "\n",
        "    Included features:\n",
        "    - First robot's stats\n",
        "    - distance vector to closest ice tile\n",
        "    - distance vector to first factory\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, env: gym.Env) -> None:\n",
        "        super().__init__(env)\n",
        "        self.observation_space = spaces.Box(-999, 999, shape=(13,))\n",
        "\n",
        "    def observation(self, obs):\n",
        "        return SimpleUnitObservationWrapper.convert_obs(obs, self.env.state.env_cfg)\n",
        "\n",
        "    # we make this method static so the submission/evaluation code can use this as well\n",
        "    @staticmethod\n",
        "    def convert_obs(obs: Dict[str, Any], env_cfg: Any) -> Dict[str, npt.NDArray]:\n",
        "        observation = dict()\n",
        "        shared_obs = obs[\"player_0\"]\n",
        "        ice_map = shared_obs[\"board\"][\"ice\"]\n",
        "        ice_tile_locations = np.argwhere(ice_map == 1)\n",
        "\n",
        "        for agent in obs.keys():\n",
        "            obs_vec = np.zeros(\n",
        "                13,\n",
        "            )\n",
        "\n",
        "            factories = shared_obs[\"factories\"][agent]\n",
        "            factory_vec = np.zeros(2)\n",
        "            for k in factories.keys():\n",
        "                # here we track a normalized position of the first friendly factory\n",
        "                factory = factories[k]\n",
        "                factory_vec = np.array(factory[\"pos\"]) / env_cfg.map_size\n",
        "                break\n",
        "            units = shared_obs[\"units\"][agent]\n",
        "            for k in units.keys():\n",
        "                unit = units[k]\n",
        "\n",
        "                # store cargo+power values scaled to [0, 1]\n",
        "                cargo_space = env_cfg.ROBOTS[unit[\"unit_type\"]].CARGO_SPACE\n",
        "                battery_cap = env_cfg.ROBOTS[unit[\"unit_type\"]].BATTERY_CAPACITY\n",
        "                cargo_vec = np.array(\n",
        "                    [\n",
        "                        unit[\"power\"] / battery_cap,\n",
        "                        unit[\"cargo\"][\"ice\"] / cargo_space,\n",
        "                        unit[\"cargo\"][\"ore\"] / cargo_space,\n",
        "                        unit[\"cargo\"][\"water\"] / cargo_space,\n",
        "                        unit[\"cargo\"][\"metal\"] / cargo_space,\n",
        "                    ]\n",
        "                )\n",
        "                unit_type = (\n",
        "                    0 if unit[\"unit_type\"] == \"LIGHT\" else 1\n",
        "                )  # note that build actions use 0 to encode Light\n",
        "                # normalize the unit position\n",
        "                pos = np.array(unit[\"pos\"]) / env_cfg.map_size\n",
        "                unit_vec = np.concatenate(\n",
        "                    [pos, [unit_type], cargo_vec, [unit[\"team_id\"]]], axis=-1\n",
        "                )\n",
        "\n",
        "                # we add some engineered features down here\n",
        "                # compute closest ice tile\n",
        "                ice_tile_distances = np.mean(\n",
        "                    (ice_tile_locations - np.array(unit[\"pos\"])) ** 2, 1\n",
        "                )\n",
        "                # normalize the ice tile location\n",
        "                closest_ice_tile = (\n",
        "                    ice_tile_locations[np.argmin(ice_tile_distances)] / env_cfg.map_size\n",
        "                )\n",
        "                obs_vec = np.concatenate(\n",
        "                    [unit_vec, factory_vec - pos, closest_ice_tile - pos], axis=-1\n",
        "                )\n",
        "                break\n",
        "            observation[agent] = obs_vec\n",
        "\n",
        "        return observation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c086547d",
      "metadata": {
        "papermill": {
          "duration": 0.01358,
          "end_time": "2023-02-20T17:42:15.434603",
          "exception": false,
          "start_time": "2023-02-20T17:42:15.421023",
          "status": "completed"
        },
        "tags": [],
        "id": "c086547d"
      },
      "source": [
        "## 3. Transforming Lux S2 into a Single Phase\n",
        "\n",
        "Normally RL frameworks like Stable Baselines 3, RLlib, Tianshou etc. expect the action space and observation space to be consistent throughout an episode. Lux S2 does not conform to this as we add some additional complexity like bidding and factory placement phases. A simple way to get around this is to **upgrade the reset function.**\n",
        "\n",
        "Previously we saw that `env.reset()` resets an environment to a clean slate. We will upgrade this function by building a environment wrapper that not only resets to the clean slate, but also handles the bidding and factory placement phases so effectively agents that are learning start from game states with factories already placed.\n",
        "\n",
        "Below will build a wrapper that works with the SB3 package. To do this, we want to provide the wrapper a bidding policy and factory placement policy which will be used by all teams to handle the first two phases in the reset function. The code below does just that by overriding the environment's reset function in the wrapper. \n",
        "\n",
        "Furthermore, we want to use the Controller we defined earlier, so that is also an argument to the SB3Wrapper and we use it to transform actions inside the `env.step` function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55f7d44c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T17:42:15.464038Z",
          "iopub.status.busy": "2023-02-20T17:42:15.46358Z",
          "iopub.status.idle": "2023-02-20T17:42:15.962104Z",
          "shell.execute_reply": "2023-02-20T17:42:15.960262Z"
        },
        "papermill": {
          "duration": 0.517248,
          "end_time": "2023-02-20T17:42:15.965414",
          "exception": false,
          "start_time": "2023-02-20T17:42:15.448166",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55f7d44c",
        "outputId": "9f27b18e-6844-47e4-80c5-66c9809124e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pygame 2.3.0 (SDL 2.24.2, Python 3.9.16)\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
          ]
        }
      ],
      "source": [
        "from typing import Callable, Dict\n",
        "\n",
        "import gym\n",
        "import numpy as np\n",
        "import numpy.typing as npt\n",
        "from gym import spaces\n",
        "\n",
        "import luxai_s2.env\n",
        "from luxai_s2.env import LuxAI_S2\n",
        "from luxai_s2.state import ObservationStateDict\n",
        "from luxai_s2.unit import ActionType, BidActionType, FactoryPlacementActionType\n",
        "from luxai_s2.utils import my_turn_to_place_factory\n",
        "from luxai_s2.wrappers.controllers import (\n",
        "    Controller,\n",
        ")\n",
        "\n",
        "\n",
        "class SB3Wrapper(gym.Wrapper):\n",
        "    def __init__(\n",
        "        self,\n",
        "        env: LuxAI_S2,\n",
        "        bid_policy: Callable[\n",
        "            [str, ObservationStateDict], Dict[str, BidActionType]\n",
        "        ] = None,\n",
        "        factory_placement_policy: Callable[\n",
        "            [str, ObservationStateDict], Dict[str, FactoryPlacementActionType]\n",
        "        ] = None,\n",
        "        controller: Controller = None,\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        A environment wrapper for Stable Baselines 3. It reduces the LuxAI_S2 env\n",
        "        into a single phase game and places the first two phases (bidding and factory placement) into the env.reset function so that\n",
        "        interacting agents directly start generating actions to play the third phase of the game.\n",
        "\n",
        "        It also accepts a Controller that translates action's in one action space to a Lux S2 compatible action\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        bid_policy: Function\n",
        "            A function accepting player: str and obs: ObservationStateDict as input that returns a bid action\n",
        "            such as dict(bid=10, faction=\"AlphaStrike\"). By default will bid 0\n",
        "        factory_placement_policy: Function\n",
        "            A function accepting player: str and obs: ObservationStateDict as input that returns a factory placement action\n",
        "            such as dict(spawn=np.array([2, 4]), metal=150, water=150). By default will spawn in a random valid location with metal=150, water=150\n",
        "        controller : Controller\n",
        "            A controller that parameterizes the action space into something more usable and converts parameterized actions to lux actions.\n",
        "            See luxai_s2/wrappers/controllers.py for available controllers and how to make your own\n",
        "        \"\"\"\n",
        "        gym.Wrapper.__init__(self, env)\n",
        "        self.env = env\n",
        "        \n",
        "        assert controller is not None\n",
        "        \n",
        "        # set our controller and replace the action space\n",
        "        self.controller = controller\n",
        "        self.action_space = controller.action_space\n",
        "\n",
        "        # The simplified wrapper removes the first two phases of the game by using predefined policies (trained or heuristic)\n",
        "        # to handle those two phases during each reset\n",
        "        if factory_placement_policy is None:\n",
        "            def factory_placement_policy(player, obs: ObservationStateDict):\n",
        "                potential_spawns = np.array(\n",
        "                    list(zip(*np.where(obs[\"board\"][\"valid_spawns_mask\"] == 1)))\n",
        "                )\n",
        "                spawn_loc = potential_spawns[\n",
        "                    np.random.randint(0, len(potential_spawns))\n",
        "                ]\n",
        "                return dict(spawn=spawn_loc, metal=150, water=150)\n",
        "\n",
        "        self.factory_placement_policy = factory_placement_policy\n",
        "        if bid_policy is None:\n",
        "            def bid_policy(player, obs: ObservationStateDict):\n",
        "                faction = \"AlphaStrike\"\n",
        "                if player == \"player_1\":\n",
        "                    faction = \"MotherMars\"\n",
        "                return dict(bid=0, faction=faction)\n",
        "\n",
        "        self.bid_policy = bid_policy\n",
        "\n",
        "        self.prev_obs = None\n",
        "\n",
        "    def step(self, action: Dict[str, npt.NDArray]):\n",
        "        \n",
        "        # here, for each agent in the game we translate their action into a Lux S2 action\n",
        "        lux_action = dict()\n",
        "        for agent in self.env.agents:\n",
        "            if agent in action:\n",
        "                lux_action[agent] = self.controller.action_to_lux_action(\n",
        "                    agent=agent, obs=self.prev_obs, action=action[agent]\n",
        "                )\n",
        "            else:\n",
        "                lux_action[agent] = dict()\n",
        "        \n",
        "        # lux_action is now a dict mapping agent name to an action\n",
        "        obs, reward, done, info = self.env.step(lux_action)\n",
        "        self.prev_obs = obs\n",
        "        return obs, reward, done, info\n",
        "\n",
        "    def reset(self, **kwargs):\n",
        "        # we upgrade the reset function here\n",
        "        \n",
        "        # we call the original reset function first\n",
        "        obs = self.env.reset(**kwargs)\n",
        "        \n",
        "        # then use the bid policy to go through the bidding phase\n",
        "        action = dict()\n",
        "        for agent in self.env.agents:\n",
        "            action[agent] = self.bid_policy(agent, obs[agent])\n",
        "        obs, _, _, _ = self.env.step(action)\n",
        "        \n",
        "        # while real_env_steps < 0, we are in the factory placement phase\n",
        "        # so we use the factory placement policy to step through this\n",
        "        while self.env.state.real_env_steps < 0:\n",
        "            action = dict()\n",
        "            for agent in self.env.agents:\n",
        "                if my_turn_to_place_factory(\n",
        "                    obs[\"player_0\"][\"teams\"][agent][\"place_first\"],\n",
        "                    self.env.state.env_steps,\n",
        "                ):\n",
        "                    action[agent] = self.factory_placement_policy(agent, obs[agent])\n",
        "                else:\n",
        "                    action[agent] = dict()\n",
        "            obs, _, _, _ = self.env.step(action)\n",
        "        self.prev_obs = obs\n",
        "        \n",
        "        return obs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5de5b845",
      "metadata": {
        "papermill": {
          "duration": 0.014122,
          "end_time": "2023-02-20T17:42:15.994395",
          "exception": false,
          "start_time": "2023-02-20T17:42:15.980273",
          "status": "completed"
        },
        "tags": [],
        "id": "5de5b845"
      },
      "source": [
        "### Defining a Bid and Factory Placement policy\n",
        "\n",
        "To test the code above, we can program some heuristic bid and factory placement policies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef757f69",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T17:42:16.02598Z",
          "iopub.status.busy": "2023-02-20T17:42:16.025565Z",
          "iopub.status.idle": "2023-02-20T17:42:16.038544Z",
          "shell.execute_reply": "2023-02-20T17:42:16.037298Z"
        },
        "papermill": {
          "duration": 0.031499,
          "end_time": "2023-02-20T17:42:16.040491",
          "exception": false,
          "start_time": "2023-02-20T17:42:16.008992",
          "status": "completed"
        },
        "tags": [],
        "id": "ef757f69"
      },
      "outputs": [],
      "source": [
        "def zero_bid(player, obs):\n",
        "    # a policy that always bids 0\n",
        "    faction = \"AlphaStrike\"\n",
        "    if player == \"player_1\":\n",
        "        faction = \"MotherMars\"\n",
        "    return dict(bid=0, faction=faction)\n",
        "\n",
        "def place_near_random_ice(player, obs):\n",
        "    \"\"\"\n",
        "    This policy will place a single factory with all the starting resources\n",
        "    near a random ice tile\n",
        "    \"\"\"\n",
        "    if obs[\"teams\"][player][\"metal\"] == 0:\n",
        "        return dict()\n",
        "    potential_spawns = list(zip(*np.where(obs[\"board\"][\"valid_spawns_mask\"] == 1)))\n",
        "    potential_spawns_set = set(potential_spawns)\n",
        "    done_search = False\n",
        "    \n",
        "    # simple numpy trick to find locations adjacent to ice tiles.\n",
        "    ice_diff = np.diff(obs[\"board\"][\"ice\"])\n",
        "    pot_ice_spots = np.argwhere(ice_diff == 1)\n",
        "    if len(pot_ice_spots) == 0:\n",
        "        pot_ice_spots = potential_spawns\n",
        "    \n",
        "    # pick a random ice spot and search around it for spawnable locations.\n",
        "    trials = 5\n",
        "    while trials > 0:\n",
        "        pos_idx = np.random.randint(0, len(pot_ice_spots))\n",
        "        pos = pot_ice_spots[pos_idx]\n",
        "        area = 3\n",
        "        for x in range(area):\n",
        "            for y in range(area):\n",
        "                check_pos = [pos[0] + x - area // 2, pos[1] + y - area // 2]\n",
        "                if tuple(check_pos) in potential_spawns_set:\n",
        "                    done_search = True\n",
        "                    pos = check_pos\n",
        "                    break\n",
        "            if done_search:\n",
        "                break\n",
        "        if done_search:\n",
        "            break\n",
        "        trials -= 1\n",
        "    \n",
        "    if not done_search:\n",
        "        spawn_loc = potential_spawns[np.random.randint(0, len(potential_spawns))]\n",
        "        pos = spawn_loc\n",
        "    \n",
        "    # this will spawn a factory at pos and with all the starting metal and water\n",
        "    #metal = obs[\"teams\"][player][\"metal\"]\n",
        "    return dict(spawn=pos, metal=min(obs[\"teams\"][player][\"metal\"],300), water=min(obs[\"teams\"][player][\"water\"],300))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc9d6a1a",
      "metadata": {
        "papermill": {
          "duration": 0.012857,
          "end_time": "2023-02-20T17:42:16.067185",
          "exception": false,
          "start_time": "2023-02-20T17:42:16.054328",
          "status": "completed"
        },
        "tags": [],
        "id": "cc9d6a1a"
      },
      "source": [
        "So **without the wrapper**, when we reset the environment it looks like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "624406f7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T17:42:16.097926Z",
          "iopub.status.busy": "2023-02-20T17:42:16.097513Z",
          "iopub.status.idle": "2023-02-20T17:42:16.340523Z",
          "shell.execute_reply": "2023-02-20T17:42:16.33966Z"
        },
        "papermill": {
          "duration": 0.260588,
          "end_time": "2023-02-20T17:42:16.342631",
          "exception": false,
          "start_time": "2023-02-20T17:42:16.082043",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "624406f7",
        "outputId": "67814989-a93b-492a-be53-7a6147d17004"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fccdb649820>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "env = gym.make(\"LuxAI_S2-v0\")\n",
        "env.reset(seed=0)\n",
        "img = env.render(\"rgb_array\")\n",
        "plt.imshow(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9f5f6ac",
      "metadata": {
        "papermill": {
          "duration": 0.013744,
          "end_time": "2023-02-20T17:42:16.371161",
          "exception": false,
          "start_time": "2023-02-20T17:42:16.357417",
          "status": "completed"
        },
        "tags": [],
        "id": "a9f5f6ac"
      },
      "source": [
        "**With the wrapper**, when we reset the environment it looks like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac9352e3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T17:42:16.404155Z",
          "iopub.status.busy": "2023-02-20T17:42:16.40277Z",
          "iopub.status.idle": "2023-02-20T17:42:17.500482Z",
          "shell.execute_reply": "2023-02-20T17:42:17.499004Z"
        },
        "papermill": {
          "duration": 1.116886,
          "end_time": "2023-02-20T17:42:17.50365",
          "exception": false,
          "start_time": "2023-02-20T17:42:16.386764",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "ac9352e3",
        "outputId": "c665e1e1-0a2d-48d5-a63a-c79a05617cba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fcc9dc1aa00>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "env = gym.make(\"LuxAI_S2-v0\")\n",
        "env = SB3Wrapper(env, zero_bid, place_near_random_ice, controller=SimpleUnitDiscreteController(env.env_cfg))\n",
        "env.reset(seed=12)\n",
        "img = env.render(\"rgb_array\")\n",
        "plt.imshow(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41cfc14b",
      "metadata": {
        "papermill": {
          "duration": 0.015701,
          "end_time": "2023-02-20T17:42:17.536113",
          "exception": false,
          "start_time": "2023-02-20T17:42:17.520412",
          "status": "completed"
        },
        "tags": [],
        "id": "41cfc14b"
      },
      "source": [
        "Success! Our upgraded reset function makes the environment now start from the start of the normal game phase, meaning the action space can be consistently the same throughout the game."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a4f13e1",
      "metadata": {
        "papermill": {
          "duration": 0.015451,
          "end_time": "2023-02-20T17:42:17.567132",
          "exception": false,
          "start_time": "2023-02-20T17:42:17.551681",
          "status": "completed"
        },
        "tags": [],
        "id": "8a4f13e1"
      },
      "source": [
        "## 4. Training with RL\n",
        "\n",
        "In the previous tutorial, we saw how to train an agent with SB3 in single-agent environments. Handling true multi-agent via training separate or shared policies to control all agents requires a few extra things so instead, for the purpose of a tutorial we will treat Lux S2 like a single agent environment by training a policy for one team and letting the other team simply do nothing.\n",
        "\n",
        "Moreover, we want to define our own reward function to encourage our robots to seek ice, dig it, and return to a factory so it can generate water and survive longer. To do this all, we will just create a custom environment wrapper.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27510659",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T17:42:17.600577Z",
          "iopub.status.busy": "2023-02-20T17:42:17.600152Z",
          "iopub.status.idle": "2023-02-20T17:42:17.615682Z",
          "shell.execute_reply": "2023-02-20T17:42:17.614047Z"
        },
        "papermill": {
          "duration": 0.036663,
          "end_time": "2023-02-20T17:42:17.619186",
          "exception": false,
          "start_time": "2023-02-20T17:42:17.582523",
          "status": "completed"
        },
        "tags": [],
        "id": "27510659"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "class CustomEnvWrapper(gym.Wrapper):\n",
        "    def __init__(self, env: gym.Env) -> None:\n",
        "        \"\"\"\n",
        "        Adds a custom reward and turns the LuxAI_S2 environment into a single-agent environment for easy training\n",
        "        \"\"\"\n",
        "        super().__init__(env)\n",
        "        self.prev_step_metrics = None\n",
        "\n",
        "    def step(self, action):\n",
        "        agent = \"player_0\"\n",
        "        opp_agent = \"player_1\"\n",
        "\n",
        "        opp_factories = self.env.state.factories[opp_agent]\n",
        "        for k in opp_factories.keys():\n",
        "            factory = opp_factories[k]\n",
        "            # set enemy factories to have 1000 water to keep them alive the whole around and treat the game as single-agent\n",
        "            factory.cargo.water = 1000\n",
        "\n",
        "        # submit actions for just one agent to make it single-agent\n",
        "        # and save single-agent versions of the data below\n",
        "        action = {agent: action}\n",
        "        obs, _, done, info = self.env.step(action)\n",
        "        obs = obs[agent]\n",
        "        done = done[agent]\n",
        "\n",
        "        # we collect stats on teams here. These are useful stats that can be used to help generate reward functions\n",
        "        stats: StatsStateDict = self.env.state.stats[agent]\n",
        "\n",
        "        info = dict()\n",
        "        metrics = dict()\n",
        "        metrics[\"ice_dug\"] = (\n",
        "            stats[\"generation\"][\"ice\"][\"HEAVY\"] + stats[\"generation\"][\"ice\"][\"LIGHT\"]\n",
        "        )\n",
        "        metrics[\"water_produced\"] = stats[\"generation\"][\"water\"]\n",
        "        metrics[\"lichen_produced\"] = stats[\"generation\"][\"lichen\"]\n",
        "\n",
        "        # we save these two to see often the agent updates robot action queues and how often enough\n",
        "        # power to do so and succeed (less frequent updates = more power is saved)\n",
        "        metrics[\"action_queue_updates_success\"] = stats[\"action_queue_updates_success\"]\n",
        "        metrics[\"action_queue_updates_total\"] = stats[\"action_queue_updates_total\"]\n",
        "\n",
        "        # we can save the metrics to info so we can use tensorboard to log them to get a glimpse into how our agent is behaving\n",
        "        info[\"metrics\"] = metrics\n",
        "\n",
        "        reward = 0\n",
        "        if self.prev_step_metrics is not None:\n",
        "            # we check how much ice and water is produced and reward the agent for generating both\n",
        "            ice_dug_this_step = metrics[\"ice_dug\"] - self.prev_step_metrics[\"ice_dug\"]\n",
        "            water_produced_this_step = (\n",
        "                metrics[\"water_produced\"] - self.prev_step_metrics[\"water_produced\"]\n",
        "            )\n",
        "            lichen_produced_this_step = (\n",
        "                metrics[\"lichen_produced\"] - self.prev_step_metrics[\"lichen_produced\"]\n",
        "            )\n",
        "            # we reward water production more as it is the most important resource for survival\n",
        "            reward = ice_dug_this_step / 100 + water_produced_this_step\n",
        "\n",
        "        self.prev_step_metrics = copy.deepcopy(metrics)\n",
        "        return obs, reward, done, info\n",
        "\n",
        "    def reset(self, **kwargs):\n",
        "        obs = self.env.reset(**kwargs)[\"player_0\"]\n",
        "        self.prev_step_metrics = None\n",
        "        return obs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8d084c2",
      "metadata": {
        "papermill": {
          "duration": 0.016407,
          "end_time": "2023-02-20T17:42:17.651273",
          "exception": false,
          "start_time": "2023-02-20T17:42:17.634866",
          "status": "completed"
        },
        "tags": [],
        "id": "f8d084c2"
      },
      "source": [
        "### 3.1 Defining the Environment and using Wrappers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "282327eb",
      "metadata": {
        "papermill": {
          "duration": 0.014347,
          "end_time": "2023-02-20T17:42:17.680049",
          "exception": false,
          "start_time": "2023-02-20T17:42:17.665702",
          "status": "completed"
        },
        "tags": [],
        "id": "282327eb"
      },
      "source": [
        "Next, we will define a `make_env` function and use it with SB3 to create multiple environments in parallel that scale with the number of CPU cores you have. A future tutorial will show a variant that creates a single jax-powered environment to achieve the same functionality but scaling with GPU.\n",
        "\n",
        "We will use the SB3Wrapper, the controller and observation wrapper we defined, and the custom env wrapper as well. These put together will give us an environment that resets to the start of the normal game phase, has a consistent and simplified observation and action space, and contains our reward function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43a1c68f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T17:42:17.714187Z",
          "iopub.status.busy": "2023-02-20T17:42:17.713193Z",
          "iopub.status.idle": "2023-02-20T17:42:20.169259Z",
          "shell.execute_reply": "2023-02-20T17:42:20.168088Z"
        },
        "papermill": {
          "duration": 2.47594,
          "end_time": "2023-02-20T17:42:20.172236",
          "exception": false,
          "start_time": "2023-02-20T17:42:17.696296",
          "status": "completed"
        },
        "tags": [],
        "id": "43a1c68f"
      },
      "outputs": [],
      "source": [
        "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from gym.wrappers import TimeLimit\n",
        "def make_env(env_id: str, rank: int, seed: int = 0, max_episode_steps=200):\n",
        "    def _init() -> gym.Env:\n",
        "        # verbose = 0\n",
        "        # collect_stats=True lets us track stats like total ice dug during an episode to help create reward functions\n",
        "        # max factories set to 2 for simplification and keeping returns consistent as we survive longer \n",
        "        # if there are more initial resources\n",
        "        env = gym.make(env_id, verbose=0, collect_stats=True, MAX_FACTORIES=2)\n",
        "\n",
        "        # Add a SB3 wrapper to make it work with SB3 and simplify the action space with the controller\n",
        "        # this will remove the bidding phase and factory placement phase. For factory placement we use\n",
        "        # the provided place_near_random_ice function which will randomly select an ice tile and place a factory near it.\n",
        "        env = SB3Wrapper(\n",
        "            env,\n",
        "            factory_placement_policy=place_near_random_ice,\n",
        "            controller=SimpleUnitDiscreteController(env.env_cfg),\n",
        "        )\n",
        "        \n",
        "        # changes observation to include a few simple features\n",
        "        env = SimpleUnitObservationWrapper(\n",
        "            env\n",
        "        )\n",
        "        \n",
        "        # convert to single agent, adds our reward\n",
        "        env = CustomEnvWrapper(env)  \n",
        "        \n",
        "        # Add a timelimit to the environment, which can truncate episodes, speed up training\n",
        "        env = TimeLimit(\n",
        "            env, max_episode_steps=max_episode_steps\n",
        "        )\n",
        "        env = Monitor(env) # for SB3 to allow it to record metrics\n",
        "        env.reset(seed=seed + rank)\n",
        "        set_random_seed(seed)\n",
        "        return env\n",
        "\n",
        "    return _init"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7c2f6e1",
      "metadata": {
        "papermill": {
          "duration": 0.015859,
          "end_time": "2023-02-20T17:42:20.203492",
          "exception": false,
          "start_time": "2023-02-20T17:42:20.187633",
          "status": "completed"
        },
        "tags": [],
        "id": "a7c2f6e1"
      },
      "source": [
        "Next we will define a useful callback function to log some of the custom metrics we defined earlier in the CustomEnvWrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "304b5650",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T17:42:20.236637Z",
          "iopub.status.busy": "2023-02-20T17:42:20.235412Z",
          "iopub.status.idle": "2023-02-20T17:42:20.247003Z",
          "shell.execute_reply": "2023-02-20T17:42:20.244903Z"
        },
        "papermill": {
          "duration": 0.030769,
          "end_time": "2023-02-20T17:42:20.249845",
          "exception": false,
          "start_time": "2023-02-20T17:42:20.219076",
          "status": "completed"
        },
        "tags": [],
        "id": "304b5650"
      },
      "outputs": [],
      "source": [
        "from stable_baselines3.common.callbacks import BaseCallback, EvalCallback\n",
        "class TensorboardCallback(BaseCallback):\n",
        "    def __init__(self, tag: str, verbose=0):\n",
        "        super().__init__(verbose)\n",
        "        self.tag = tag\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        c = 0\n",
        "\n",
        "        for i, done in enumerate(self.locals[\"dones\"]):\n",
        "            if done:\n",
        "                info = self.locals[\"infos\"][i]\n",
        "                c += 1\n",
        "                for k in info[\"metrics\"]:\n",
        "                    stat = info[\"metrics\"][k]\n",
        "                    self.logger.record_mean(f\"{self.tag}/{k}\", stat)\n",
        "        return True"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de19fb3b",
      "metadata": {
        "papermill": {
          "duration": 0.018109,
          "end_time": "2023-02-20T17:42:20.282346",
          "exception": false,
          "start_time": "2023-02-20T17:42:20.264237",
          "status": "completed"
        },
        "tags": [],
        "id": "de19fb3b"
      },
      "source": [
        "### 3.2 Training Setup\n",
        "\n",
        "Now we can prepare for training by creating training and evaluation environments, as well as defining our algorithm and model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21ac78e2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T17:42:20.320852Z",
          "iopub.status.busy": "2023-02-20T17:42:20.319188Z",
          "iopub.status.idle": "2023-02-20T17:42:28.609995Z",
          "shell.execute_reply": "2023-02-20T17:42:28.608291Z"
        },
        "papermill": {
          "duration": 8.315235,
          "end_time": "2023-02-20T17:42:28.612523",
          "exception": false,
          "start_time": "2023-02-20T17:42:20.297288",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "21ac78e2",
        "outputId": "33f86b47-4447-4802-87e9-f76f6d1d530d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-7ffd9fe21882>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# set max episode steps to 200 for training environments to train faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSubprocVecEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmake_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LuxAI_S2-v0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_episode_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# set max episode steps to 1000 to match original environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/stable_baselines3/common/vec_env/subproc_vec_env.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, env_fns, start_method)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremotes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"get_spaces\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0mobservation_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremotes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0mVecEnv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import os.path as osp\n",
        "from stable_baselines3.common.utils import set_random_seed\n",
        "from stable_baselines3.ppo import PPO\n",
        "\n",
        "set_random_seed(42)\n",
        "log_path = \"logs/exp_1\"\n",
        "num_envs = 4\n",
        "\n",
        "# set max episode steps to 200 for training environments to train faster\n",
        "env = SubprocVecEnv([make_env(\"LuxAI_S2-v0\", i, max_episode_steps=400) for i in range(num_envs)])\n",
        "env.reset()\n",
        "# set max episode steps to 1000 to match original environment\n",
        "eval_env = SubprocVecEnv([make_env(\"LuxAI_S2-v0\", i, max_episode_steps=1000) for i in range(4)])\n",
        "eval_env.reset()\n",
        "rollout_steps = 4000\n",
        "policy_kwargs = dict(net_arch=(128, 128))\n",
        "model = PPO(\n",
        "    \"MlpPolicy\",\n",
        "    env,\n",
        "    n_steps=rollout_steps // num_envs,\n",
        "    batch_size=800,\n",
        "    learning_rate=3e-4,\n",
        "    policy_kwargs=policy_kwargs,\n",
        "    verbose=1,\n",
        "    n_epochs=2,\n",
        "    target_kl=0.05,\n",
        "    gamma=0.99,\n",
        "    tensorboard_log=osp.join(log_path),\n",
        ")\n",
        "\n",
        "eval_callback = EvalCallback(\n",
        "    eval_env,\n",
        "    best_model_save_path=osp.join(log_path, \"models\"),\n",
        "    log_path=osp.join(log_path, \"eval_logs\"),\n",
        "    eval_freq=24_000,\n",
        "    deterministic=False,\n",
        "    render=False,\n",
        "    n_eval_episodes=5,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ef97f99",
      "metadata": {
        "papermill": {
          "duration": 0.013638,
          "end_time": "2023-02-20T17:42:28.64116",
          "exception": false,
          "start_time": "2023-02-20T17:42:28.627522",
          "status": "completed"
        },
        "tags": [],
        "id": "2ef97f99"
      },
      "source": [
        "With our callback functions and model defined, we can now begin training using `model.learn`. On CPU this training can take around 3-4 hours to train, on GPU it can take 30min to an hour to train. The hyperparameters and reward function can be improved to make it train much faster. A simple way to also increase training speed is to train on a machine with more CPU cores and increasing `num_envs` above. Kaggle notebooks by default only have 4, but with e.g. 10 you can easily train a policy in around 30 minutes.\n",
        "\n",
        "If you want to skip this training you can also just use the pretrained model that's in the downloaded dataset for the RL kit called `best_model.dontunzipme`. (kaggle auto unzips files but we need to keep it as a zip so the file extention is called .dontunzipme but for submission just change it to a .zip)\n",
        "\n",
        "To track the progress we recommend using tensorboard which you can run with\n",
        "```\n",
        "tensorboard --logdir logs\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64e24412",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T17:42:28.672708Z",
          "iopub.status.busy": "2023-02-20T17:42:28.671974Z",
          "iopub.status.idle": "2023-02-20T21:08:25.698631Z",
          "shell.execute_reply": "2023-02-20T21:08:25.696767Z"
        },
        "papermill": {
          "duration": 12357.04555,
          "end_time": "2023-02-20T21:08:25.701412",
          "exception": false,
          "start_time": "2023-02-20T17:42:28.655862",
          "status": "completed"
        },
        "scrolled": true,
        "tags": [],
        "id": "64e24412"
      },
      "outputs": [],
      "source": [
        "total_timesteps = 10_000_000 #10_000_000\n",
        "model.learn(\n",
        "    total_timesteps,\n",
        "    callback=[TensorboardCallback(tag=\"train_metrics\"), eval_callback],\n",
        ")\n",
        "model.save(osp.join(log_path, \"models/latest_model\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca4506c8",
      "metadata": {
        "papermill": {
          "duration": 0.257607,
          "end_time": "2023-02-20T21:08:26.20571",
          "exception": false,
          "start_time": "2023-02-20T21:08:25.948103",
          "status": "completed"
        },
        "tags": [],
        "id": "ca4506c8"
      },
      "source": [
        "## Packaging and Submission\n",
        "\n",
        "We now have a trained policy. In order to make it submittable to the competition we recommend you write code on separate files and only use kaggle notebooks for training as it can get very messy to program an RL agent just using a Kaggle notebook interface. The starter kit that was downloaded earlier has all of the code above written already and organized into separate files and folders. The observation wrapper and controller written here are saved to the `wrappers` folder. The SB3Wrapper is not in the kit, but is a part of the official luxai_s2 package and you can import it with\n",
        "\n",
        "```\n",
        "from luxai_s2.wrappers import SB3Wrapper\n",
        "```\n",
        "\n",
        "The main files to take note of are `nn.py` and `agent.py`. Since kaggle servers don't have Stable Baselines 3 installed, `nn.py` is where we program some utility functions as well as the neural network model to load the SB3 trained weights into a PyTorch neural network model. `agent.py` will then use those utilities to load the model zip file at `MODEL_WEIGHTS_RELATIVE_PATH` which can be changed at the top of `agent.py`\n",
        "\n",
        "`agent.py` also uses the s_mask function to invalidate some actions so that the policy only generates valid actions, which is a easy way to improve performance."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --log-path \"logs/exp_1\" -s 42 --max-episode-steps 400 --total-timesteps 10_000_000 -n 4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUeWfPnRZNGh",
        "outputId": "e82748a5-d3b7-49c9-eb5d-c2ff9a46aa5f"
      },
      "id": "sUeWfPnRZNGh",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mLe flux de sortie a été tronqué et ne contient que les 5000 dernières lignes.\u001b[0m\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 181          |\n",
            "|    n_updates                    | 4634         |\n",
            "|    policy_gradient_loss         | -0.00146     |\n",
            "|    value_loss                   | 377          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 354          |\n",
            "|    action_queue_updates_total   | 354          |\n",
            "|    ice_dug                      | 4.03e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 963          |\n",
            "--------------------------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 400         |\n",
            "|    ep_rew_mean                  | 1.01e+03    |\n",
            "| time/                           |             |\n",
            "|    fps                          | 782         |\n",
            "|    iterations                   | 2319        |\n",
            "|    time_elapsed                 | 11856       |\n",
            "|    total_timesteps              | 9276000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.000697099 |\n",
            "|    clip_fraction                | 0.001       |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.727      |\n",
            "|    explained_variance           | 0.656       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 196         |\n",
            "|    n_updates                    | 4636        |\n",
            "|    policy_gradient_loss         | -0.00228    |\n",
            "|    value_loss                   | 426         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 352         |\n",
            "|    action_queue_updates_total   | 356         |\n",
            "|    ice_dug                      | 4.36e+03    |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 1.04e+03    |\n",
            "-------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 400          |\n",
            "|    ep_rew_mean                  | 1.02e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 782          |\n",
            "|    iterations                   | 2320         |\n",
            "|    time_elapsed                 | 11860        |\n",
            "|    total_timesteps              | 9280000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0028491572 |\n",
            "|    clip_fraction                | 0.0185       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.697       |\n",
            "|    explained_variance           | 0.567        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 164          |\n",
            "|    n_updates                    | 4638         |\n",
            "|    policy_gradient_loss         | 0.00182      |\n",
            "|    value_loss                   | 341          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 353          |\n",
            "|    action_queue_updates_total   | 359          |\n",
            "|    ice_dug                      | 4.45e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.07e+03     |\n",
            "--------------------------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 400         |\n",
            "|    ep_rew_mean                  | 1.02e+03    |\n",
            "| time/                           |             |\n",
            "|    fps                          | 782         |\n",
            "|    iterations                   | 2321        |\n",
            "|    time_elapsed                 | 11864       |\n",
            "|    total_timesteps              | 9284000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.005214475 |\n",
            "|    clip_fraction                | 0.0344      |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.723      |\n",
            "|    explained_variance           | 0.62        |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 114         |\n",
            "|    n_updates                    | 4640        |\n",
            "|    policy_gradient_loss         | 0.00247     |\n",
            "|    value_loss                   | 259         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 357         |\n",
            "|    action_queue_updates_total   | 361         |\n",
            "|    ice_dug                      | 3.78e+03    |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 892         |\n",
            "-------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 400          |\n",
            "|    ep_rew_mean                  | 1.02e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 782          |\n",
            "|    iterations                   | 2322         |\n",
            "|    time_elapsed                 | 11870        |\n",
            "|    total_timesteps              | 9288000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0024064973 |\n",
            "|    clip_fraction                | 0.006        |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.714       |\n",
            "|    explained_variance           | 0.589        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 214          |\n",
            "|    n_updates                    | 4642         |\n",
            "|    policy_gradient_loss         | -0.00126     |\n",
            "|    value_loss                   | 427          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 363          |\n",
            "|    action_queue_updates_total   | 370          |\n",
            "|    ice_dug                      | 4.15e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 948          |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 400          |\n",
            "|    ep_rew_mean                  | 1.03e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 782          |\n",
            "|    iterations                   | 2323         |\n",
            "|    time_elapsed                 | 11874        |\n",
            "|    total_timesteps              | 9292000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0048844973 |\n",
            "|    clip_fraction                | 0.0249       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.72        |\n",
            "|    explained_variance           | 0.606        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 191          |\n",
            "|    n_updates                    | 4644         |\n",
            "|    policy_gradient_loss         | -0.00237     |\n",
            "|    value_loss                   | 427          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 374          |\n",
            "|    action_queue_updates_total   | 378          |\n",
            "|    ice_dug                      | 4.64e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.09e+03     |\n",
            "--------------------------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 400         |\n",
            "|    ep_rew_mean                  | 1.03e+03    |\n",
            "| time/                           |             |\n",
            "|    fps                          | 782         |\n",
            "|    iterations                   | 2324        |\n",
            "|    time_elapsed                 | 11878       |\n",
            "|    total_timesteps              | 9296000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.002162554 |\n",
            "|    clip_fraction                | 0.00975     |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.701      |\n",
            "|    explained_variance           | 0.619       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 210         |\n",
            "|    n_updates                    | 4646        |\n",
            "|    policy_gradient_loss         | 0.000456    |\n",
            "|    value_loss                   | 451         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 364         |\n",
            "|    action_queue_updates_total   | 366         |\n",
            "|    ice_dug                      | 4.51e+03    |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 1.07e+03    |\n",
            "-------------------------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 400         |\n",
            "|    ep_rew_mean                  | 1.03e+03    |\n",
            "| time/                           |             |\n",
            "|    fps                          | 782         |\n",
            "|    iterations                   | 2325        |\n",
            "|    time_elapsed                 | 11884       |\n",
            "|    total_timesteps              | 9300000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.003661858 |\n",
            "|    clip_fraction                | 0.0205      |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.706      |\n",
            "|    explained_variance           | 0.696       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 184         |\n",
            "|    n_updates                    | 4648        |\n",
            "|    policy_gradient_loss         | 0.00156     |\n",
            "|    value_loss                   | 360         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 357         |\n",
            "|    action_queue_updates_total   | 364         |\n",
            "|    ice_dug                      | 4.22e+03    |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 973         |\n",
            "-------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 400          |\n",
            "|    ep_rew_mean                  | 1.03e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 782          |\n",
            "|    iterations                   | 2326         |\n",
            "|    time_elapsed                 | 11889        |\n",
            "|    total_timesteps              | 9304000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0016828729 |\n",
            "|    clip_fraction                | 0.00612      |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.72        |\n",
            "|    explained_variance           | 0.602        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 152          |\n",
            "|    n_updates                    | 4650         |\n",
            "|    policy_gradient_loss         | -0.000308    |\n",
            "|    value_loss                   | 326          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 367          |\n",
            "|    action_queue_updates_total   | 370          |\n",
            "|    ice_dug                      | 3.91e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 931          |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 400          |\n",
            "|    ep_rew_mean                  | 1.05e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 782          |\n",
            "|    iterations                   | 2327         |\n",
            "|    time_elapsed                 | 11893        |\n",
            "|    total_timesteps              | 9308000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0033734918 |\n",
            "|    clip_fraction                | 0.0116       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.771       |\n",
            "|    explained_variance           | 0.727        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 204          |\n",
            "|    n_updates                    | 4652         |\n",
            "|    policy_gradient_loss         | -0.00262     |\n",
            "|    value_loss                   | 459          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 370          |\n",
            "|    action_queue_updates_total   | 370          |\n",
            "|    ice_dug                      | 4.56e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.12e+03     |\n",
            "--------------------------------------------------\n",
            "Eval num_timesteps=9312000, episode_reward=2204.72 +/- 1122.64\n",
            "Episode length: 860.20 +/- 279.60\n",
            "-------------------------------------------------\n",
            "| eval/                           |             |\n",
            "|    mean_ep_length               | 860         |\n",
            "|    mean_reward                  | 2.2e+03     |\n",
            "| time/                           |             |\n",
            "|    total_timesteps              | 9312000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.001450965 |\n",
            "|    clip_fraction                | 0.00612     |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.716      |\n",
            "|    explained_variance           | 0.618       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 114         |\n",
            "|    n_updates                    | 4654        |\n",
            "|    policy_gradient_loss         | -0.00066    |\n",
            "|    value_loss                   | 238         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 359         |\n",
            "|    action_queue_updates_total   | 365         |\n",
            "|    ice_dug                      | 4.27e+03    |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 1.02e+03    |\n",
            "-------------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 400      |\n",
            "|    ep_rew_mean     | 1.06e+03 |\n",
            "| time/              |          |\n",
            "|    fps             | 782      |\n",
            "|    iterations      | 2328     |\n",
            "|    time_elapsed    | 11907    |\n",
            "|    total_timesteps | 9312000  |\n",
            "---------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 400          |\n",
            "|    ep_rew_mean                  | 1.06e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 782          |\n",
            "|    iterations                   | 2329         |\n",
            "|    time_elapsed                 | 11911        |\n",
            "|    total_timesteps              | 9316000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0024542413 |\n",
            "|    clip_fraction                | 0.0119       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.711       |\n",
            "|    explained_variance           | 0.61         |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 182          |\n",
            "|    n_updates                    | 4656         |\n",
            "|    policy_gradient_loss         | 0.00218      |\n",
            "|    value_loss                   | 353          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 357          |\n",
            "|    action_queue_updates_total   | 359          |\n",
            "|    ice_dug                      | 4.43e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.07e+03     |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 400          |\n",
            "|    ep_rew_mean                  | 1.05e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 782          |\n",
            "|    iterations                   | 2330         |\n",
            "|    time_elapsed                 | 11917        |\n",
            "|    total_timesteps              | 9320000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0010977153 |\n",
            "|    clip_fraction                | 0.00462      |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.703       |\n",
            "|    explained_variance           | 0.591        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 152          |\n",
            "|    n_updates                    | 4658         |\n",
            "|    policy_gradient_loss         | -0.0007      |\n",
            "|    value_loss                   | 328          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 351          |\n",
            "|    action_queue_updates_total   | 359          |\n",
            "|    ice_dug                      | 4.09e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 977          |\n",
            "--------------------------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 399         |\n",
            "|    ep_rew_mean                  | 1.05e+03    |\n",
            "| time/                           |             |\n",
            "|    fps                          | 782         |\n",
            "|    iterations                   | 2331        |\n",
            "|    time_elapsed                 | 11921       |\n",
            "|    total_timesteps              | 9324000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.010951327 |\n",
            "|    clip_fraction                | 0.0826      |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.752      |\n",
            "|    explained_variance           | 0.631       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 207         |\n",
            "|    n_updates                    | 4660        |\n",
            "|    policy_gradient_loss         | 0.00727     |\n",
            "|    value_loss                   | 411         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 360         |\n",
            "|    action_queue_updates_total   | 361         |\n",
            "|    ice_dug                      | 3.68e+03    |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 856         |\n",
            "-------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 399          |\n",
            "|    ep_rew_mean                  | 1.04e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 782          |\n",
            "|    iterations                   | 2332         |\n",
            "|    time_elapsed                 | 11925        |\n",
            "|    total_timesteps              | 9328000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0018563311 |\n",
            "|    clip_fraction                | 0.00812      |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.703       |\n",
            "|    explained_variance           | 0.467        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 379          |\n",
            "|    n_updates                    | 4662         |\n",
            "|    policy_gradient_loss         | -0.00123     |\n",
            "|    value_loss                   | 783          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 370          |\n",
            "|    action_queue_updates_total   | 375          |\n",
            "|    ice_dug                      | 3.96e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 909          |\n",
            "--------------------------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 399         |\n",
            "|    ep_rew_mean                  | 1.05e+03    |\n",
            "| time/                           |             |\n",
            "|    fps                          | 782         |\n",
            "|    iterations                   | 2333        |\n",
            "|    time_elapsed                 | 11931       |\n",
            "|    total_timesteps              | 9332000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.005676786 |\n",
            "|    clip_fraction                | 0.0294      |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.704      |\n",
            "|    explained_variance           | 0.575       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 217         |\n",
            "|    n_updates                    | 4664        |\n",
            "|    policy_gradient_loss         | -0.00226    |\n",
            "|    value_loss                   | 438         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 372         |\n",
            "|    action_queue_updates_total   | 373         |\n",
            "|    ice_dug                      | 4.77e+03    |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 1.14e+03    |\n",
            "-------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 399          |\n",
            "|    ep_rew_mean                  | 1.05e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 782          |\n",
            "|    iterations                   | 2334         |\n",
            "|    time_elapsed                 | 11935        |\n",
            "|    total_timesteps              | 9336000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0023146935 |\n",
            "|    clip_fraction                | 0.0145       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.66        |\n",
            "|    explained_variance           | 0.488        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 192          |\n",
            "|    n_updates                    | 4666         |\n",
            "|    policy_gradient_loss         | 0.0024       |\n",
            "|    value_loss                   | 378          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 359          |\n",
            "|    action_queue_updates_total   | 366          |\n",
            "|    ice_dug                      | 4.54e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.1e+03      |\n",
            "--------------------------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 399         |\n",
            "|    ep_rew_mean                  | 1.06e+03    |\n",
            "| time/                           |             |\n",
            "|    fps                          | 782         |\n",
            "|    iterations                   | 2335        |\n",
            "|    time_elapsed                 | 11939       |\n",
            "|    total_timesteps              | 9340000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.002164911 |\n",
            "|    clip_fraction                | 0.00725     |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.687      |\n",
            "|    explained_variance           | 0.67        |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 167         |\n",
            "|    n_updates                    | 4668        |\n",
            "|    policy_gradient_loss         | 0.000806    |\n",
            "|    value_loss                   | 325         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 359         |\n",
            "|    action_queue_updates_total   | 363         |\n",
            "|    ice_dug                      | 4.32e+03    |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 1.05e+03    |\n",
            "-------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 398          |\n",
            "|    ep_rew_mean                  | 1.06e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 782          |\n",
            "|    iterations                   | 2336         |\n",
            "|    time_elapsed                 | 11946        |\n",
            "|    total_timesteps              | 9344000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0074839825 |\n",
            "|    clip_fraction                | 0.0547       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.723       |\n",
            "|    explained_variance           | 0.567        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 134          |\n",
            "|    n_updates                    | 4670         |\n",
            "|    policy_gradient_loss         | -0.00015     |\n",
            "|    value_loss                   | 268          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 344          |\n",
            "|    action_queue_updates_total   | 348          |\n",
            "|    ice_dug                      | 4e+03        |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 958          |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 398          |\n",
            "|    ep_rew_mean                  | 1.05e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 782          |\n",
            "|    iterations                   | 2337         |\n",
            "|    time_elapsed                 | 11950        |\n",
            "|    total_timesteps              | 9348000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0049457755 |\n",
            "|    clip_fraction                | 0.034        |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.667       |\n",
            "|    explained_variance           | 0.625        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 240          |\n",
            "|    n_updates                    | 4672         |\n",
            "|    policy_gradient_loss         | -0.00035     |\n",
            "|    value_loss                   | 494          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 348          |\n",
            "|    action_queue_updates_total   | 351          |\n",
            "|    ice_dug                      | 4.39e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.06e+03     |\n",
            "--------------------------------------------------\n",
            "------------------------------------------------\n",
            "| rollout/                        |            |\n",
            "|    ep_len_mean                  | 398        |\n",
            "|    ep_rew_mean                  | 1.05e+03   |\n",
            "| time/                           |            |\n",
            "|    fps                          | 782        |\n",
            "|    iterations                   | 2338       |\n",
            "|    time_elapsed                 | 11954      |\n",
            "|    total_timesteps              | 9352000    |\n",
            "| train/                          |            |\n",
            "|    approx_kl                    | 0.01044253 |\n",
            "|    clip_fraction                | 0.0551     |\n",
            "|    clip_range                   | 0.2        |\n",
            "|    entropy_loss                 | -0.653     |\n",
            "|    explained_variance           | 0.531      |\n",
            "|    learning_rate                | 0.0003     |\n",
            "|    loss                         | 154        |\n",
            "|    n_updates                    | 4674       |\n",
            "|    policy_gradient_loss         | -0.00336   |\n",
            "|    value_loss                   | 340        |\n",
            "| train_metrics/                  |            |\n",
            "|    action_queue_updates_success | 357        |\n",
            "|    action_queue_updates_total   | 362        |\n",
            "|    ice_dug                      | 4.31e+03   |\n",
            "|    lichen_produced              | 0          |\n",
            "|    water_produced               | 1e+03      |\n",
            "------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 398          |\n",
            "|    ep_rew_mean                  | 1.06e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 782          |\n",
            "|    iterations                   | 2339         |\n",
            "|    time_elapsed                 | 11960        |\n",
            "|    total_timesteps              | 9356000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0052730627 |\n",
            "|    clip_fraction                | 0.0416       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.686       |\n",
            "|    explained_variance           | 0.65         |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 154          |\n",
            "|    n_updates                    | 4676         |\n",
            "|    policy_gradient_loss         | -0.00148     |\n",
            "|    value_loss                   | 344          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 373          |\n",
            "|    action_queue_updates_total   | 378          |\n",
            "|    ice_dug                      | 4.96e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.17e+03     |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 398          |\n",
            "|    ep_rew_mean                  | 1.07e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 782          |\n",
            "|    iterations                   | 2340         |\n",
            "|    time_elapsed                 | 11966        |\n",
            "|    total_timesteps              | 9360000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0026982443 |\n",
            "|    clip_fraction                | 0.0166       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.687       |\n",
            "|    explained_variance           | 0.533        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 190          |\n",
            "|    n_updates                    | 4678         |\n",
            "|    policy_gradient_loss         | 0.00249      |\n",
            "|    value_loss                   | 397          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 358          |\n",
            "|    action_queue_updates_total   | 368          |\n",
            "|    ice_dug                      | 4.45e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.08e+03     |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 399          |\n",
            "|    ep_rew_mean                  | 1.1e+03      |\n",
            "| time/                           |              |\n",
            "|    fps                          | 782          |\n",
            "|    iterations                   | 2341         |\n",
            "|    time_elapsed                 | 11970        |\n",
            "|    total_timesteps              | 9364000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0038509748 |\n",
            "|    clip_fraction                | 0.0261       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.691       |\n",
            "|    explained_variance           | 0.684        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 141          |\n",
            "|    n_updates                    | 4680         |\n",
            "|    policy_gradient_loss         | 0.00428      |\n",
            "|    value_loss                   | 274          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 358          |\n",
            "|    action_queue_updates_total   | 367          |\n",
            "|    ice_dug                      | 4.62e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.13e+03     |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 399          |\n",
            "|    ep_rew_mean                  | 1.1e+03      |\n",
            "| time/                           |              |\n",
            "|    fps                          | 782          |\n",
            "|    iterations                   | 2342         |\n",
            "|    time_elapsed                 | 11976        |\n",
            "|    total_timesteps              | 9368000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0046663606 |\n",
            "|    clip_fraction                | 0.0295       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.7         |\n",
            "|    explained_variance           | 0.696        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 114          |\n",
            "|    n_updates                    | 4682         |\n",
            "|    policy_gradient_loss         | -0.000965    |\n",
            "|    value_loss                   | 221          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 353          |\n",
            "|    action_queue_updates_total   | 359          |\n",
            "|    ice_dug                      | 3.86e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 939          |\n",
            "--------------------------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 399         |\n",
            "|    ep_rew_mean                  | 1.09e+03    |\n",
            "| time/                           |             |\n",
            "|    fps                          | 782         |\n",
            "|    iterations                   | 2343        |\n",
            "|    time_elapsed                 | 11981       |\n",
            "|    total_timesteps              | 9372000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.009686343 |\n",
            "|    clip_fraction                | 0.057       |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.761      |\n",
            "|    explained_variance           | 0.691       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 167         |\n",
            "|    n_updates                    | 4684        |\n",
            "|    policy_gradient_loss         | 0.000922    |\n",
            "|    value_loss                   | 340         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 372         |\n",
            "|    action_queue_updates_total   | 377         |\n",
            "|    ice_dug                      | 4.4e+03     |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 1.04e+03    |\n",
            "-------------------------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 399         |\n",
            "|    ep_rew_mean                  | 1.09e+03    |\n",
            "| time/                           |             |\n",
            "|    fps                          | 782         |\n",
            "|    iterations                   | 2344        |\n",
            "|    time_elapsed                 | 11985       |\n",
            "|    total_timesteps              | 9376000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.005921988 |\n",
            "|    clip_fraction                | 0.0384      |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.727      |\n",
            "|    explained_variance           | 0.504       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 140         |\n",
            "|    n_updates                    | 4686        |\n",
            "|    policy_gradient_loss         | -0.00143    |\n",
            "|    value_loss                   | 266         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 367         |\n",
            "|    action_queue_updates_total   | 370         |\n",
            "|    ice_dug                      | 4.57e+03    |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 1.1e+03     |\n",
            "-------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 399          |\n",
            "|    ep_rew_mean                  | 1.09e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 782          |\n",
            "|    iterations                   | 2345         |\n",
            "|    time_elapsed                 | 11991        |\n",
            "|    total_timesteps              | 9380000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0028551351 |\n",
            "|    clip_fraction                | 0.0226       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.707       |\n",
            "|    explained_variance           | 0.539        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 119          |\n",
            "|    n_updates                    | 4688         |\n",
            "|    policy_gradient_loss         | 0.00177      |\n",
            "|    value_loss                   | 251          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 368          |\n",
            "|    action_queue_updates_total   | 369          |\n",
            "|    ice_dug                      | 4.38e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.07e+03     |\n",
            "--------------------------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 400         |\n",
            "|    ep_rew_mean                  | 1.11e+03    |\n",
            "| time/                           |             |\n",
            "|    fps                          | 782         |\n",
            "|    iterations                   | 2346        |\n",
            "|    time_elapsed                 | 11995       |\n",
            "|    total_timesteps              | 9384000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.008484403 |\n",
            "|    clip_fraction                | 0.0511      |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.746      |\n",
            "|    explained_variance           | 0.625       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 129         |\n",
            "|    n_updates                    | 4690        |\n",
            "|    policy_gradient_loss         | -0.00341    |\n",
            "|    value_loss                   | 265         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 358         |\n",
            "|    action_queue_updates_total   | 365         |\n",
            "|    ice_dug                      | 4.33e+03    |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 1.05e+03    |\n",
            "-------------------------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 400         |\n",
            "|    ep_rew_mean                  | 1.1e+03     |\n",
            "| time/                           |             |\n",
            "|    fps                          | 782         |\n",
            "|    iterations                   | 2347        |\n",
            "|    time_elapsed                 | 11999       |\n",
            "|    total_timesteps              | 9388000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.008403128 |\n",
            "|    clip_fraction                | 0.0701      |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.706      |\n",
            "|    explained_variance           | 0.573       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 152         |\n",
            "|    n_updates                    | 4692        |\n",
            "|    policy_gradient_loss         | 0.00136     |\n",
            "|    value_loss                   | 299         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 370         |\n",
            "|    action_queue_updates_total   | 377         |\n",
            "|    ice_dug                      | 4.35e+03    |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 1.02e+03    |\n",
            "-------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 400          |\n",
            "|    ep_rew_mean                  | 1.1e+03      |\n",
            "| time/                           |              |\n",
            "|    fps                          | 782          |\n",
            "|    iterations                   | 2348         |\n",
            "|    time_elapsed                 | 12005        |\n",
            "|    total_timesteps              | 9392000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0030799836 |\n",
            "|    clip_fraction                | 0.0231       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.667       |\n",
            "|    explained_variance           | 0.635        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 197          |\n",
            "|    n_updates                    | 4694         |\n",
            "|    policy_gradient_loss         | 0.000567     |\n",
            "|    value_loss                   | 401          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 333          |\n",
            "|    action_queue_updates_total   | 355          |\n",
            "|    ice_dug                      | 4.16e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 992          |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 400          |\n",
            "|    ep_rew_mean                  | 1.08e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 782          |\n",
            "|    iterations                   | 2349         |\n",
            "|    time_elapsed                 | 12010        |\n",
            "|    total_timesteps              | 9396000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0038330448 |\n",
            "|    clip_fraction                | 0.0216       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.725       |\n",
            "|    explained_variance           | 0.62         |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 194          |\n",
            "|    n_updates                    | 4696         |\n",
            "|    policy_gradient_loss         | 0.000872     |\n",
            "|    value_loss                   | 431          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 332          |\n",
            "|    action_queue_updates_total   | 349          |\n",
            "|    ice_dug                      | 4.05e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 965          |\n",
            "--------------------------------------------------\n",
            "------------------------------------------------\n",
            "| rollout/                        |            |\n",
            "|    ep_len_mean                  | 400        |\n",
            "|    ep_rew_mean                  | 1.09e+03   |\n",
            "| time/                           |            |\n",
            "|    fps                          | 782        |\n",
            "|    iterations                   | 2350       |\n",
            "|    time_elapsed                 | 12014      |\n",
            "|    total_timesteps              | 9400000    |\n",
            "| train/                          |            |\n",
            "|    approx_kl                    | 0.01920655 |\n",
            "|    clip_fraction                | 0.0941     |\n",
            "|    clip_range                   | 0.2        |\n",
            "|    entropy_loss                 | -0.705     |\n",
            "|    explained_variance           | 0.678      |\n",
            "|    learning_rate                | 0.0003     |\n",
            "|    loss                         | 215        |\n",
            "|    n_updates                    | 4698       |\n",
            "|    policy_gradient_loss         | 0.0115     |\n",
            "|    value_loss                   | 440        |\n",
            "| train_metrics/                  |            |\n",
            "|    action_queue_updates_success | 363        |\n",
            "|    action_queue_updates_total   | 372        |\n",
            "|    ice_dug                      | 4.71e+03   |\n",
            "|    lichen_produced              | 0          |\n",
            "|    water_produced               | 1.12e+03   |\n",
            "------------------------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 400         |\n",
            "|    ep_rew_mean                  | 1.1e+03     |\n",
            "| time/                           |             |\n",
            "|    fps                          | 782         |\n",
            "|    iterations                   | 2351        |\n",
            "|    time_elapsed                 | 12019       |\n",
            "|    total_timesteps              | 9404000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.002681411 |\n",
            "|    clip_fraction                | 0.017       |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.641      |\n",
            "|    explained_variance           | 0.529       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 198         |\n",
            "|    n_updates                    | 4700        |\n",
            "|    policy_gradient_loss         | -0.000173   |\n",
            "|    value_loss                   | 430         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 372         |\n",
            "|    action_queue_updates_total   | 382         |\n",
            "|    ice_dug                      | 5.07e+03    |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 1.23e+03    |\n",
            "-------------------------------------------------\n",
            "Eval num_timesteps=9408000, episode_reward=3212.36 +/- 194.38\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-------------------------------------------------\n",
            "| eval/                           |             |\n",
            "|    mean_ep_length               | 1e+03       |\n",
            "|    mean_reward                  | 3.21e+03    |\n",
            "| time/                           |             |\n",
            "|    total_timesteps              | 9408000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.012395689 |\n",
            "|    clip_fraction                | 0.0631      |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.616      |\n",
            "|    explained_variance           | 0.415       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 162         |\n",
            "|    n_updates                    | 4702        |\n",
            "|    policy_gradient_loss         | 0.00948     |\n",
            "|    value_loss                   | 359         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 360         |\n",
            "|    action_queue_updates_total   | 367         |\n",
            "|    ice_dug                      | 4.69e+03    |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 1.14e+03    |\n",
            "-------------------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 400      |\n",
            "|    ep_rew_mean     | 1.12e+03 |\n",
            "| time/              |          |\n",
            "|    fps             | 781      |\n",
            "|    iterations      | 2352     |\n",
            "|    time_elapsed    | 12032    |\n",
            "|    total_timesteps | 9408000  |\n",
            "---------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 400         |\n",
            "|    ep_rew_mean                  | 1.12e+03    |\n",
            "| time/                           |             |\n",
            "|    fps                          | 781         |\n",
            "|    iterations                   | 2353        |\n",
            "|    time_elapsed                 | 12038       |\n",
            "|    total_timesteps              | 9412000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.008241762 |\n",
            "|    clip_fraction                | 0.052       |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.643      |\n",
            "|    explained_variance           | 0.612       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 123         |\n",
            "|    n_updates                    | 4704        |\n",
            "|    policy_gradient_loss         | 0.00791     |\n",
            "|    value_loss                   | 251         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 354         |\n",
            "|    action_queue_updates_total   | 365         |\n",
            "|    ice_dug                      | 4.4e+03     |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 1.06e+03    |\n",
            "-------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 399          |\n",
            "|    ep_rew_mean                  | 1.09e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2354         |\n",
            "|    time_elapsed                 | 12042        |\n",
            "|    total_timesteps              | 9416000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0044475375 |\n",
            "|    clip_fraction                | 0.031        |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.7         |\n",
            "|    explained_variance           | 0.635        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 131          |\n",
            "|    n_updates                    | 4706         |\n",
            "|    policy_gradient_loss         | 0.00048      |\n",
            "|    value_loss                   | 289          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 322          |\n",
            "|    action_queue_updates_total   | 338          |\n",
            "|    ice_dug                      | 3.58e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 865          |\n",
            "--------------------------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 399         |\n",
            "|    ep_rew_mean                  | 1.1e+03     |\n",
            "| time/                           |             |\n",
            "|    fps                          | 781         |\n",
            "|    iterations                   | 2355        |\n",
            "|    time_elapsed                 | 12046       |\n",
            "|    total_timesteps              | 9420000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.009759465 |\n",
            "|    clip_fraction                | 0.0695      |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.75       |\n",
            "|    explained_variance           | 0.606       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 282         |\n",
            "|    n_updates                    | 4708        |\n",
            "|    policy_gradient_loss         | 0.00257     |\n",
            "|    value_loss                   | 650         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 370         |\n",
            "|    action_queue_updates_total   | 376         |\n",
            "|    ice_dug                      | 4.78e+03    |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 1.17e+03    |\n",
            "-------------------------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 399         |\n",
            "|    ep_rew_mean                  | 1.11e+03    |\n",
            "| time/                           |             |\n",
            "|    fps                          | 781         |\n",
            "|    iterations                   | 2356        |\n",
            "|    time_elapsed                 | 12052       |\n",
            "|    total_timesteps              | 9424000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.005523141 |\n",
            "|    clip_fraction                | 0.038       |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.699      |\n",
            "|    explained_variance           | 0.692       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 143         |\n",
            "|    n_updates                    | 4710        |\n",
            "|    policy_gradient_loss         | -0.000663   |\n",
            "|    value_loss                   | 277         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 377         |\n",
            "|    action_queue_updates_total   | 380         |\n",
            "|    ice_dug                      | 4.74e+03    |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 1.16e+03    |\n",
            "-------------------------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 399         |\n",
            "|    ep_rew_mean                  | 1.12e+03    |\n",
            "| time/                           |             |\n",
            "|    fps                          | 781         |\n",
            "|    iterations                   | 2357        |\n",
            "|    time_elapsed                 | 12056       |\n",
            "|    total_timesteps              | 9428000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.003869028 |\n",
            "|    clip_fraction                | 0.0264      |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.682      |\n",
            "|    explained_variance           | 0.605       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 111         |\n",
            "|    n_updates                    | 4712        |\n",
            "|    policy_gradient_loss         | 0.00349     |\n",
            "|    value_loss                   | 251         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 364         |\n",
            "|    action_queue_updates_total   | 371         |\n",
            "|    ice_dug                      | 4.54e+03    |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 1.08e+03    |\n",
            "-------------------------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 398         |\n",
            "|    ep_rew_mean                  | 1.12e+03    |\n",
            "| time/                           |             |\n",
            "|    fps                          | 782         |\n",
            "|    iterations                   | 2358        |\n",
            "|    time_elapsed                 | 12060       |\n",
            "|    total_timesteps              | 9432000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.003911536 |\n",
            "|    clip_fraction                | 0.0256      |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.688      |\n",
            "|    explained_variance           | 0.522       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 147         |\n",
            "|    n_updates                    | 4714        |\n",
            "|    policy_gradient_loss         | 0.00382     |\n",
            "|    value_loss                   | 277         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 340         |\n",
            "|    action_queue_updates_total   | 352         |\n",
            "|    ice_dug                      | 4.2e+03     |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 1.02e+03    |\n",
            "-------------------------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 398         |\n",
            "|    ep_rew_mean                  | 1.12e+03    |\n",
            "| time/                           |             |\n",
            "|    fps                          | 781         |\n",
            "|    iterations                   | 2359        |\n",
            "|    time_elapsed                 | 12066       |\n",
            "|    total_timesteps              | 9436000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.003938566 |\n",
            "|    clip_fraction                | 0.029       |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.75       |\n",
            "|    explained_variance           | 0.535       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 268         |\n",
            "|    n_updates                    | 4716        |\n",
            "|    policy_gradient_loss         | 0.00101     |\n",
            "|    value_loss                   | 550         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 365         |\n",
            "|    action_queue_updates_total   | 372         |\n",
            "|    ice_dug                      | 4.13e+03    |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 992         |\n",
            "-------------------------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 398         |\n",
            "|    ep_rew_mean                  | 1.09e+03    |\n",
            "| time/                           |             |\n",
            "|    fps                          | 782         |\n",
            "|    iterations                   | 2360        |\n",
            "|    time_elapsed                 | 12071       |\n",
            "|    total_timesteps              | 9440000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.003771893 |\n",
            "|    clip_fraction                | 0.022       |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.77       |\n",
            "|    explained_variance           | 0.511       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 127         |\n",
            "|    n_updates                    | 4718        |\n",
            "|    policy_gradient_loss         | -0.00257    |\n",
            "|    value_loss                   | 278         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 355         |\n",
            "|    action_queue_updates_total   | 363         |\n",
            "|    ice_dug                      | 3.81e+03    |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 899         |\n",
            "-------------------------------------------------\n",
            "------------------------------------------------\n",
            "| rollout/                        |            |\n",
            "|    ep_len_mean                  | 398        |\n",
            "|    ep_rew_mean                  | 1.09e+03   |\n",
            "| time/                           |            |\n",
            "|    fps                          | 782        |\n",
            "|    iterations                   | 2361       |\n",
            "|    time_elapsed                 | 12075      |\n",
            "|    total_timesteps              | 9444000    |\n",
            "| train/                          |            |\n",
            "|    approx_kl                    | 0.00558514 |\n",
            "|    clip_fraction                | 0.0241     |\n",
            "|    clip_range                   | 0.2        |\n",
            "|    entropy_loss                 | -0.809     |\n",
            "|    explained_variance           | 0.713      |\n",
            "|    learning_rate                | 0.0003     |\n",
            "|    loss                         | 204        |\n",
            "|    n_updates                    | 4720       |\n",
            "|    policy_gradient_loss         | -0.00117   |\n",
            "|    value_loss                   | 439        |\n",
            "| train_metrics/                  |            |\n",
            "|    action_queue_updates_success | 376        |\n",
            "|    action_queue_updates_total   | 377        |\n",
            "|    ice_dug                      | 4.81e+03   |\n",
            "|    lichen_produced              | 0          |\n",
            "|    water_produced               | 1.17e+03   |\n",
            "------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 398          |\n",
            "|    ep_rew_mean                  | 1.08e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 782          |\n",
            "|    iterations                   | 2362         |\n",
            "|    time_elapsed                 | 12081        |\n",
            "|    total_timesteps              | 9448000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0027294937 |\n",
            "|    clip_fraction                | 0.0186       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.738       |\n",
            "|    explained_variance           | 0.645        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 140          |\n",
            "|    n_updates                    | 4722         |\n",
            "|    policy_gradient_loss         | -0.00358     |\n",
            "|    value_loss                   | 270          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 376          |\n",
            "|    action_queue_updates_total   | 379          |\n",
            "|    ice_dug                      | 4.5e+03      |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.08e+03     |\n",
            "--------------------------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 398         |\n",
            "|    ep_rew_mean                  | 1.07e+03    |\n",
            "| time/                           |             |\n",
            "|    fps                          | 782         |\n",
            "|    iterations                   | 2363        |\n",
            "|    time_elapsed                 | 12085       |\n",
            "|    total_timesteps              | 9452000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.004557094 |\n",
            "|    clip_fraction                | 0.0226      |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.725      |\n",
            "|    explained_variance           | 0.554       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 169         |\n",
            "|    n_updates                    | 4724        |\n",
            "|    policy_gradient_loss         | 0.00424     |\n",
            "|    value_loss                   | 333         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 368         |\n",
            "|    action_queue_updates_total   | 374         |\n",
            "|    ice_dug                      | 3.85e+03    |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 897         |\n",
            "-------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 399          |\n",
            "|    ep_rew_mean                  | 1.1e+03      |\n",
            "| time/                           |              |\n",
            "|    fps                          | 782          |\n",
            "|    iterations                   | 2364         |\n",
            "|    time_elapsed                 | 12089        |\n",
            "|    total_timesteps              | 9456000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0041922675 |\n",
            "|    clip_fraction                | 0.026        |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.748       |\n",
            "|    explained_variance           | 0.71         |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 179          |\n",
            "|    n_updates                    | 4726         |\n",
            "|    policy_gradient_loss         | 0.000585     |\n",
            "|    value_loss                   | 376          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 363          |\n",
            "|    action_queue_updates_total   | 369          |\n",
            "|    ice_dug                      | 4.67e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.12e+03     |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 399          |\n",
            "|    ep_rew_mean                  | 1.09e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 782          |\n",
            "|    iterations                   | 2365         |\n",
            "|    time_elapsed                 | 12096        |\n",
            "|    total_timesteps              | 9460000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0009354042 |\n",
            "|    clip_fraction                | 0.001        |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.699       |\n",
            "|    explained_variance           | 0.599        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 127          |\n",
            "|    n_updates                    | 4728         |\n",
            "|    policy_gradient_loss         | -0.000391    |\n",
            "|    value_loss                   | 282          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 374          |\n",
            "|    action_queue_updates_total   | 374          |\n",
            "|    ice_dug                      | 4.46e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.09e+03     |\n",
            "--------------------------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 399         |\n",
            "|    ep_rew_mean                  | 1.08e+03    |\n",
            "| time/                           |             |\n",
            "|    fps                          | 782         |\n",
            "|    iterations                   | 2366        |\n",
            "|    time_elapsed                 | 12100       |\n",
            "|    total_timesteps              | 9464000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.002647465 |\n",
            "|    clip_fraction                | 0.0164      |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.692      |\n",
            "|    explained_variance           | 0.708       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 141         |\n",
            "|    n_updates                    | 4730        |\n",
            "|    policy_gradient_loss         | -0.000765   |\n",
            "|    value_loss                   | 283         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 354         |\n",
            "|    action_queue_updates_total   | 366         |\n",
            "|    ice_dug                      | 4.45e+03    |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 1.06e+03    |\n",
            "-------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 399          |\n",
            "|    ep_rew_mean                  | 1.08e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 782          |\n",
            "|    iterations                   | 2367         |\n",
            "|    time_elapsed                 | 12104        |\n",
            "|    total_timesteps              | 9468000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0016052686 |\n",
            "|    clip_fraction                | 0.007        |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.727       |\n",
            "|    explained_variance           | 0.585        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 165          |\n",
            "|    n_updates                    | 4732         |\n",
            "|    policy_gradient_loss         | -0.00115     |\n",
            "|    value_loss                   | 305          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 362          |\n",
            "|    action_queue_updates_total   | 367          |\n",
            "|    ice_dug                      | 4.4e+03      |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.05e+03     |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 400          |\n",
            "|    ep_rew_mean                  | 1.09e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 782          |\n",
            "|    iterations                   | 2368         |\n",
            "|    time_elapsed                 | 12110        |\n",
            "|    total_timesteps              | 9472000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0047125174 |\n",
            "|    clip_fraction                | 0.0346       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.753       |\n",
            "|    explained_variance           | 0.679        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 160          |\n",
            "|    n_updates                    | 4734         |\n",
            "|    policy_gradient_loss         | 0.00362      |\n",
            "|    value_loss                   | 326          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 372          |\n",
            "|    action_queue_updates_total   | 374          |\n",
            "|    ice_dug                      | 4.52e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.07e+03     |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 400          |\n",
            "|    ep_rew_mean                  | 1.09e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 782          |\n",
            "|    iterations                   | 2369         |\n",
            "|    time_elapsed                 | 12114        |\n",
            "|    total_timesteps              | 9476000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0016029751 |\n",
            "|    clip_fraction                | 0.009        |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.732       |\n",
            "|    explained_variance           | 0.671        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 121          |\n",
            "|    n_updates                    | 4736         |\n",
            "|    policy_gradient_loss         | -0.000539    |\n",
            "|    value_loss                   | 236          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 352          |\n",
            "|    action_queue_updates_total   | 360          |\n",
            "|    ice_dug                      | 4.29e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.01e+03     |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 400          |\n",
            "|    ep_rew_mean                  | 1.11e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 782          |\n",
            "|    iterations                   | 2370         |\n",
            "|    time_elapsed                 | 12118        |\n",
            "|    total_timesteps              | 9480000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0076731495 |\n",
            "|    clip_fraction                | 0.0387       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.719       |\n",
            "|    explained_variance           | 0.682        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 183          |\n",
            "|    n_updates                    | 4738         |\n",
            "|    policy_gradient_loss         | -0.00358     |\n",
            "|    value_loss                   | 351          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 362          |\n",
            "|    action_queue_updates_total   | 367          |\n",
            "|    ice_dug                      | 4.66e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.11e+03     |\n",
            "--------------------------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 400         |\n",
            "|    ep_rew_mean                  | 1.11e+03    |\n",
            "| time/                           |             |\n",
            "|    fps                          | 782         |\n",
            "|    iterations                   | 2371        |\n",
            "|    time_elapsed                 | 12124       |\n",
            "|    total_timesteps              | 9484000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.002299169 |\n",
            "|    clip_fraction                | 0.0114      |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.657      |\n",
            "|    explained_variance           | 0.572       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 160         |\n",
            "|    n_updates                    | 4740        |\n",
            "|    policy_gradient_loss         | 0.00144     |\n",
            "|    value_loss                   | 307         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 356         |\n",
            "|    action_queue_updates_total   | 362         |\n",
            "|    ice_dug                      | 4.66e+03    |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 1.11e+03    |\n",
            "-------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 399          |\n",
            "|    ep_rew_mean                  | 1.1e+03      |\n",
            "| time/                           |              |\n",
            "|    fps                          | 782          |\n",
            "|    iterations                   | 2372         |\n",
            "|    time_elapsed                 | 12129        |\n",
            "|    total_timesteps              | 9488000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0034670657 |\n",
            "|    clip_fraction                | 0.0257       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.71        |\n",
            "|    explained_variance           | 0.633        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 206          |\n",
            "|    n_updates                    | 4742         |\n",
            "|    policy_gradient_loss         | 0.00317      |\n",
            "|    value_loss                   | 408          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 341          |\n",
            "|    action_queue_updates_total   | 352          |\n",
            "|    ice_dug                      | 4.19e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.01e+03     |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 399          |\n",
            "|    ep_rew_mean                  | 1.11e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 782          |\n",
            "|    iterations                   | 2373         |\n",
            "|    time_elapsed                 | 12133        |\n",
            "|    total_timesteps              | 9492000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0027303149 |\n",
            "|    clip_fraction                | 0.0114       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.733       |\n",
            "|    explained_variance           | 0.482        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 265          |\n",
            "|    n_updates                    | 4744         |\n",
            "|    policy_gradient_loss         | 0.000133     |\n",
            "|    value_loss                   | 567          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 352          |\n",
            "|    action_queue_updates_total   | 361          |\n",
            "|    ice_dug                      | 4.21e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.01e+03     |\n",
            "--------------------------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 399         |\n",
            "|    ep_rew_mean                  | 1.11e+03    |\n",
            "| time/                           |             |\n",
            "|    fps                          | 782         |\n",
            "|    iterations                   | 2374        |\n",
            "|    time_elapsed                 | 12138       |\n",
            "|    total_timesteps              | 9496000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.009973625 |\n",
            "|    clip_fraction                | 0.0616      |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.756      |\n",
            "|    explained_variance           | 0.619       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 194         |\n",
            "|    n_updates                    | 4746        |\n",
            "|    policy_gradient_loss         | -0.00207    |\n",
            "|    value_loss                   | 364         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 371         |\n",
            "|    action_queue_updates_total   | 377         |\n",
            "|    ice_dug                      | 4.66e+03    |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 1.11e+03    |\n",
            "-------------------------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 399         |\n",
            "|    ep_rew_mean                  | 1.11e+03    |\n",
            "| time/                           |             |\n",
            "|    fps                          | 782         |\n",
            "|    iterations                   | 2375        |\n",
            "|    time_elapsed                 | 12143       |\n",
            "|    total_timesteps              | 9500000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.002712359 |\n",
            "|    clip_fraction                | 0.0109      |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.697      |\n",
            "|    explained_variance           | 0.618       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 158         |\n",
            "|    n_updates                    | 4748        |\n",
            "|    policy_gradient_loss         | -0.000574   |\n",
            "|    value_loss                   | 323         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 360         |\n",
            "|    action_queue_updates_total   | 367         |\n",
            "|    ice_dug                      | 4.65e+03    |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 1.11e+03    |\n",
            "-------------------------------------------------\n",
            "Eval num_timesteps=9504000, episode_reward=3149.84 +/- 154.93\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-------------------------------------------------\n",
            "| eval/                           |             |\n",
            "|    mean_ep_length               | 1e+03       |\n",
            "|    mean_reward                  | 3.15e+03    |\n",
            "| time/                           |             |\n",
            "|    total_timesteps              | 9504000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.001237954 |\n",
            "|    clip_fraction                | 0.00375     |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.692      |\n",
            "|    explained_variance           | 0.569       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 221         |\n",
            "|    n_updates                    | 4750        |\n",
            "|    policy_gradient_loss         | 6.76e-05    |\n",
            "|    value_loss                   | 430         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 359         |\n",
            "|    action_queue_updates_total   | 372         |\n",
            "|    ice_dug                      | 4.54e+03    |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 1.06e+03    |\n",
            "-------------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 399      |\n",
            "|    ep_rew_mean     | 1.11e+03 |\n",
            "| time/              |          |\n",
            "|    fps             | 781      |\n",
            "|    iterations      | 2376     |\n",
            "|    time_elapsed    | 12157    |\n",
            "|    total_timesteps | 9504000  |\n",
            "---------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 399          |\n",
            "|    ep_rew_mean                  | 1.11e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2377         |\n",
            "|    time_elapsed                 | 12161        |\n",
            "|    total_timesteps              | 9508000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0017017542 |\n",
            "|    clip_fraction                | 0.00925      |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.683       |\n",
            "|    explained_variance           | 0.593        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 117          |\n",
            "|    n_updates                    | 4752         |\n",
            "|    policy_gradient_loss         | 0.000137     |\n",
            "|    value_loss                   | 270          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 354          |\n",
            "|    action_queue_updates_total   | 371          |\n",
            "|    ice_dug                      | 4.27e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.04e+03     |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 399          |\n",
            "|    ep_rew_mean                  | 1.1e+03      |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2378         |\n",
            "|    time_elapsed                 | 12165        |\n",
            "|    total_timesteps              | 9512000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0040020607 |\n",
            "|    clip_fraction                | 0.0324       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.741       |\n",
            "|    explained_variance           | 0.625        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 182          |\n",
            "|    n_updates                    | 4754         |\n",
            "|    policy_gradient_loss         | -0.00191     |\n",
            "|    value_loss                   | 356          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 370          |\n",
            "|    action_queue_updates_total   | 375          |\n",
            "|    ice_dug                      | 4.26e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.01e+03     |\n",
            "--------------------------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 399         |\n",
            "|    ep_rew_mean                  | 1.11e+03    |\n",
            "| time/                           |             |\n",
            "|    fps                          | 781         |\n",
            "|    iterations                   | 2379        |\n",
            "|    time_elapsed                 | 12171       |\n",
            "|    total_timesteps              | 9516000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.004252027 |\n",
            "|    clip_fraction                | 0.0169      |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.776      |\n",
            "|    explained_variance           | 0.551       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 194         |\n",
            "|    n_updates                    | 4756        |\n",
            "|    policy_gradient_loss         | 0.00101     |\n",
            "|    value_loss                   | 380         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 377         |\n",
            "|    action_queue_updates_total   | 381         |\n",
            "|    ice_dug                      | 4.7e+03     |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 1.12e+03    |\n",
            "-------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 399          |\n",
            "|    ep_rew_mean                  | 1.11e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2380         |\n",
            "|    time_elapsed                 | 12175        |\n",
            "|    total_timesteps              | 9520000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0010354009 |\n",
            "|    clip_fraction                | 0.00387      |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.727       |\n",
            "|    explained_variance           | 0.536        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 135          |\n",
            "|    n_updates                    | 4758         |\n",
            "|    policy_gradient_loss         | 0.00104      |\n",
            "|    value_loss                   | 249          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 371          |\n",
            "|    action_queue_updates_total   | 376          |\n",
            "|    ice_dug                      | 4.48e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.09e+03     |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 399          |\n",
            "|    ep_rew_mean                  | 1.09e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2381         |\n",
            "|    time_elapsed                 | 12179        |\n",
            "|    total_timesteps              | 9524000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0029958542 |\n",
            "|    clip_fraction                | 0.0194       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.746       |\n",
            "|    explained_variance           | 0.573        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 115          |\n",
            "|    n_updates                    | 4760         |\n",
            "|    policy_gradient_loss         | -0.000644    |\n",
            "|    value_loss                   | 210          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 356          |\n",
            "|    action_queue_updates_total   | 365          |\n",
            "|    ice_dug                      | 3.92e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 952          |\n",
            "--------------------------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 400         |\n",
            "|    ep_rew_mean                  | 1.11e+03    |\n",
            "| time/                           |             |\n",
            "|    fps                          | 781         |\n",
            "|    iterations                   | 2382        |\n",
            "|    time_elapsed                 | 12185       |\n",
            "|    total_timesteps              | 9528000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.010277311 |\n",
            "|    clip_fraction                | 0.0825      |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.803      |\n",
            "|    explained_variance           | 0.706       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 177         |\n",
            "|    n_updates                    | 4762        |\n",
            "|    policy_gradient_loss         | 0.00212     |\n",
            "|    value_loss                   | 395         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 378         |\n",
            "|    action_queue_updates_total   | 384         |\n",
            "|    ice_dug                      | 4.78e+03    |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 1.15e+03    |\n",
            "-------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 400          |\n",
            "|    ep_rew_mean                  | 1.11e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2383         |\n",
            "|    time_elapsed                 | 12190        |\n",
            "|    total_timesteps              | 9532000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0016637053 |\n",
            "|    clip_fraction                | 0.00925      |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.749       |\n",
            "|    explained_variance           | 0.624        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 135          |\n",
            "|    n_updates                    | 4764         |\n",
            "|    policy_gradient_loss         | -0.000864    |\n",
            "|    value_loss                   | 268          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 348          |\n",
            "|    action_queue_updates_total   | 357          |\n",
            "|    ice_dug                      | 4.08e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 978          |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 400          |\n",
            "|    ep_rew_mean                  | 1.09e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 782          |\n",
            "|    iterations                   | 2384         |\n",
            "|    time_elapsed                 | 12194        |\n",
            "|    total_timesteps              | 9536000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0006877002 |\n",
            "|    clip_fraction                | 0.00025      |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.778       |\n",
            "|    explained_variance           | 0.65         |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 260          |\n",
            "|    n_updates                    | 4766         |\n",
            "|    policy_gradient_loss         | -0.000778    |\n",
            "|    value_loss                   | 545          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 354          |\n",
            "|    action_queue_updates_total   | 367          |\n",
            "|    ice_dug                      | 4.07e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 985          |\n",
            "--------------------------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 400         |\n",
            "|    ep_rew_mean                  | 1.09e+03    |\n",
            "| time/                           |             |\n",
            "|    fps                          | 781         |\n",
            "|    iterations                   | 2385        |\n",
            "|    time_elapsed                 | 12200       |\n",
            "|    total_timesteps              | 9540000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.004561414 |\n",
            "|    clip_fraction                | 0.0244      |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.747      |\n",
            "|    explained_variance           | 0.611       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 198         |\n",
            "|    n_updates                    | 4768        |\n",
            "|    policy_gradient_loss         | -0.000449   |\n",
            "|    value_loss                   | 436         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 374         |\n",
            "|    action_queue_updates_total   | 379         |\n",
            "|    ice_dug                      | 4.46e+03    |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 1.09e+03    |\n",
            "-------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 400          |\n",
            "|    ep_rew_mean                  | 1.1e+03      |\n",
            "| time/                           |              |\n",
            "|    fps                          | 782          |\n",
            "|    iterations                   | 2386         |\n",
            "|    time_elapsed                 | 12204        |\n",
            "|    total_timesteps              | 9544000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0054348824 |\n",
            "|    clip_fraction                | 0.0362       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.713       |\n",
            "|    explained_variance           | 0.629        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 165          |\n",
            "|    n_updates                    | 4770         |\n",
            "|    policy_gradient_loss         | 0.0012       |\n",
            "|    value_loss                   | 337          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 374          |\n",
            "|    action_queue_updates_total   | 381          |\n",
            "|    ice_dug                      | 4.83e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.17e+03     |\n",
            "--------------------------------------------------\n",
            "------------------------------------------------\n",
            "| rollout/                        |            |\n",
            "|    ep_len_mean                  | 399        |\n",
            "|    ep_rew_mean                  | 1.1e+03    |\n",
            "| time/                           |            |\n",
            "|    fps                          | 782        |\n",
            "|    iterations                   | 2387       |\n",
            "|    time_elapsed                 | 12208      |\n",
            "|    total_timesteps              | 9548000    |\n",
            "| train/                          |            |\n",
            "|    approx_kl                    | 0.00911857 |\n",
            "|    clip_fraction                | 0.0612     |\n",
            "|    clip_range                   | 0.2        |\n",
            "|    entropy_loss                 | -0.684     |\n",
            "|    explained_variance           | 0.717      |\n",
            "|    learning_rate                | 0.0003     |\n",
            "|    loss                         | 215        |\n",
            "|    n_updates                    | 4772       |\n",
            "|    policy_gradient_loss         | 0.00691    |\n",
            "|    value_loss                   | 401        |\n",
            "| train_metrics/                  |            |\n",
            "|    action_queue_updates_success | 349        |\n",
            "|    action_queue_updates_total   | 354        |\n",
            "|    ice_dug                      | 4.32e+03   |\n",
            "|    lichen_produced              | 0          |\n",
            "|    water_produced               | 1.02e+03   |\n",
            "------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 399          |\n",
            "|    ep_rew_mean                  | 1.11e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 782          |\n",
            "|    iterations                   | 2388         |\n",
            "|    time_elapsed                 | 12214        |\n",
            "|    total_timesteps              | 9552000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0017163455 |\n",
            "|    clip_fraction                | 0.00762      |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.681       |\n",
            "|    explained_variance           | 0.872        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 205          |\n",
            "|    n_updates                    | 4774         |\n",
            "|    policy_gradient_loss         | 0.00112      |\n",
            "|    value_loss                   | 402          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 372          |\n",
            "|    action_queue_updates_total   | 375          |\n",
            "|    ice_dug                      | 4.55e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.11e+03     |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 398          |\n",
            "|    ep_rew_mean                  | 1.11e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 782          |\n",
            "|    iterations                   | 2389         |\n",
            "|    time_elapsed                 | 12218        |\n",
            "|    total_timesteps              | 9556000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0038162123 |\n",
            "|    clip_fraction                | 0.025        |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.688       |\n",
            "|    explained_variance           | 0.664        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 172          |\n",
            "|    n_updates                    | 4776         |\n",
            "|    policy_gradient_loss         | -0.00108     |\n",
            "|    value_loss                   | 340          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 337          |\n",
            "|    action_queue_updates_total   | 346          |\n",
            "|    ice_dug                      | 4.41e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.06e+03     |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 398          |\n",
            "|    ep_rew_mean                  | 1.11e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 782          |\n",
            "|    iterations                   | 2390         |\n",
            "|    time_elapsed                 | 12223        |\n",
            "|    total_timesteps              | 9560000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0038439073 |\n",
            "|    clip_fraction                | 0.0204       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.677       |\n",
            "|    explained_variance           | 0.558        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 229          |\n",
            "|    n_updates                    | 4778         |\n",
            "|    policy_gradient_loss         | 0.000504     |\n",
            "|    value_loss                   | 558          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 355          |\n",
            "|    action_queue_updates_total   | 364          |\n",
            "|    ice_dug                      | 4.73e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.13e+03     |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 398          |\n",
            "|    ep_rew_mean                  | 1.13e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 782          |\n",
            "|    iterations                   | 2391         |\n",
            "|    time_elapsed                 | 12228        |\n",
            "|    total_timesteps              | 9564000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0035223619 |\n",
            "|    clip_fraction                | 0.0241       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.699       |\n",
            "|    explained_variance           | 0.562        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 161          |\n",
            "|    n_updates                    | 4780         |\n",
            "|    policy_gradient_loss         | -0.00243     |\n",
            "|    value_loss                   | 349          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 359          |\n",
            "|    action_queue_updates_total   | 368          |\n",
            "|    ice_dug                      | 4.58e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.13e+03     |\n",
            "--------------------------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 398         |\n",
            "|    ep_rew_mean                  | 1.12e+03    |\n",
            "| time/                           |             |\n",
            "|    fps                          | 782         |\n",
            "|    iterations                   | 2392        |\n",
            "|    time_elapsed                 | 12233       |\n",
            "|    total_timesteps              | 9568000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.008891339 |\n",
            "|    clip_fraction                | 0.052       |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.693      |\n",
            "|    explained_variance           | 0.662       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 170         |\n",
            "|    n_updates                    | 4782        |\n",
            "|    policy_gradient_loss         | 0.00577     |\n",
            "|    value_loss                   | 329         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 363         |\n",
            "|    action_queue_updates_total   | 370         |\n",
            "|    ice_dug                      | 4.28e+03    |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 1.04e+03    |\n",
            "-------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 398          |\n",
            "|    ep_rew_mean                  | 1.14e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 782          |\n",
            "|    iterations                   | 2393         |\n",
            "|    time_elapsed                 | 12237        |\n",
            "|    total_timesteps              | 9572000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0036544367 |\n",
            "|    clip_fraction                | 0.0215       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.691       |\n",
            "|    explained_variance           | 0.675        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 159          |\n",
            "|    n_updates                    | 4784         |\n",
            "|    policy_gradient_loss         | 0.0015       |\n",
            "|    value_loss                   | 313          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 355          |\n",
            "|    action_queue_updates_total   | 360          |\n",
            "|    ice_dug                      | 4.63e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.14e+03     |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 398          |\n",
            "|    ep_rew_mean                  | 1.15e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 782          |\n",
            "|    iterations                   | 2394         |\n",
            "|    time_elapsed                 | 12243        |\n",
            "|    total_timesteps              | 9576000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0047956044 |\n",
            "|    clip_fraction                | 0.0316       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.643       |\n",
            "|    explained_variance           | 0.595        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 117          |\n",
            "|    n_updates                    | 4786         |\n",
            "|    policy_gradient_loss         | -0.00308     |\n",
            "|    value_loss                   | 247          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 359          |\n",
            "|    action_queue_updates_total   | 368          |\n",
            "|    ice_dug                      | 4.77e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.15e+03     |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 398          |\n",
            "|    ep_rew_mean                  | 1.13e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 782          |\n",
            "|    iterations                   | 2395         |\n",
            "|    time_elapsed                 | 12247        |\n",
            "|    total_timesteps              | 9580000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0025566688 |\n",
            "|    clip_fraction                | 0.0145       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.664       |\n",
            "|    explained_variance           | 0.751        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 131          |\n",
            "|    n_updates                    | 4788         |\n",
            "|    policy_gradient_loss         | -0.0011      |\n",
            "|    value_loss                   | 305          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 351          |\n",
            "|    action_queue_updates_total   | 361          |\n",
            "|    ice_dug                      | 4.05e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 946          |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 398          |\n",
            "|    ep_rew_mean                  | 1.13e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 782          |\n",
            "|    iterations                   | 2396         |\n",
            "|    time_elapsed                 | 12251        |\n",
            "|    total_timesteps              | 9584000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0029106666 |\n",
            "|    clip_fraction                | 0.0192       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.672       |\n",
            "|    explained_variance           | 0.608        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 170          |\n",
            "|    n_updates                    | 4790         |\n",
            "|    policy_gradient_loss         | 0.000293     |\n",
            "|    value_loss                   | 404          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 362          |\n",
            "|    action_queue_updates_total   | 368          |\n",
            "|    ice_dug                      | 4.68e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.14e+03     |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 399          |\n",
            "|    ep_rew_mean                  | 1.13e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 782          |\n",
            "|    iterations                   | 2397         |\n",
            "|    time_elapsed                 | 12256        |\n",
            "|    total_timesteps              | 9588000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0012494667 |\n",
            "|    clip_fraction                | 0.00662      |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.671       |\n",
            "|    explained_variance           | 0.674        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 153          |\n",
            "|    n_updates                    | 4792         |\n",
            "|    policy_gradient_loss         | 0.00135      |\n",
            "|    value_loss                   | 317          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 351          |\n",
            "|    action_queue_updates_total   | 360          |\n",
            "|    ice_dug                      | 4.39e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.06e+03     |\n",
            "--------------------------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 399         |\n",
            "|    ep_rew_mean                  | 1.13e+03    |\n",
            "| time/                           |             |\n",
            "|    fps                          | 782         |\n",
            "|    iterations                   | 2398        |\n",
            "|    time_elapsed                 | 12262       |\n",
            "|    total_timesteps              | 9592000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.003112501 |\n",
            "|    clip_fraction                | 0.0237      |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.729      |\n",
            "|    explained_variance           | 0.693       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 157         |\n",
            "|    n_updates                    | 4794        |\n",
            "|    policy_gradient_loss         | -0.00139    |\n",
            "|    value_loss                   | 333         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 362         |\n",
            "|    action_queue_updates_total   | 374         |\n",
            "|    ice_dug                      | 4.61e+03    |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 1.08e+03    |\n",
            "-------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 400          |\n",
            "|    ep_rew_mean                  | 1.13e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 782          |\n",
            "|    iterations                   | 2399         |\n",
            "|    time_elapsed                 | 12266        |\n",
            "|    total_timesteps              | 9596000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0007558088 |\n",
            "|    clip_fraction                | 0.001        |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.696       |\n",
            "|    explained_variance           | 0.602        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 113          |\n",
            "|    n_updates                    | 4796         |\n",
            "|    policy_gradient_loss         | 0.000133     |\n",
            "|    value_loss                   | 230          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 373          |\n",
            "|    action_queue_updates_total   | 378          |\n",
            "|    ice_dug                      | 4.39e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.05e+03     |\n",
            "--------------------------------------------------\n",
            "Eval num_timesteps=9600000, episode_reward=2537.56 +/- 764.06\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "--------------------------------------------------\n",
            "| eval/                           |              |\n",
            "|    mean_ep_length               | 1e+03        |\n",
            "|    mean_reward                  | 2.54e+03     |\n",
            "| time/                           |              |\n",
            "|    total_timesteps              | 9600000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0010776881 |\n",
            "|    clip_fraction                | 0.00125      |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.718       |\n",
            "|    explained_variance           | 0.727        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 147          |\n",
            "|    n_updates                    | 4798         |\n",
            "|    policy_gradient_loss         | -0.000674    |\n",
            "|    value_loss                   | 329          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 377          |\n",
            "|    action_queue_updates_total   | 379          |\n",
            "|    ice_dug                      | 4.82e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.16e+03     |\n",
            "--------------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 400      |\n",
            "|    ep_rew_mean     | 1.14e+03 |\n",
            "| time/              |          |\n",
            "|    fps             | 781      |\n",
            "|    iterations      | 2400     |\n",
            "|    time_elapsed    | 12279    |\n",
            "|    total_timesteps | 9600000  |\n",
            "---------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 400          |\n",
            "|    ep_rew_mean                  | 1.13e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2401         |\n",
            "|    time_elapsed                 | 12283        |\n",
            "|    total_timesteps              | 9604000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0014972847 |\n",
            "|    clip_fraction                | 0.00837      |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.732       |\n",
            "|    explained_variance           | 0.661        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 129          |\n",
            "|    n_updates                    | 4800         |\n",
            "|    policy_gradient_loss         | -0.000737    |\n",
            "|    value_loss                   | 247          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 371          |\n",
            "|    action_queue_updates_total   | 377          |\n",
            "|    ice_dug                      | 4.65e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.11e+03     |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 400          |\n",
            "|    ep_rew_mean                  | 1.14e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2402         |\n",
            "|    time_elapsed                 | 12290        |\n",
            "|    total_timesteps              | 9608000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0015391059 |\n",
            "|    clip_fraction                | 0.00375      |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.749       |\n",
            "|    explained_variance           | 0.525        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 139          |\n",
            "|    n_updates                    | 4802         |\n",
            "|    policy_gradient_loss         | 0.000924     |\n",
            "|    value_loss                   | 297          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 377          |\n",
            "|    action_queue_updates_total   | 379          |\n",
            "|    ice_dug                      | 4.63e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.1e+03      |\n",
            "--------------------------------------------------\n",
            "---------------------------------------------------\n",
            "| rollout/                        |               |\n",
            "|    ep_len_mean                  | 400           |\n",
            "|    ep_rew_mean                  | 1.14e+03      |\n",
            "| time/                           |               |\n",
            "|    fps                          | 781           |\n",
            "|    iterations                   | 2403          |\n",
            "|    time_elapsed                 | 12294         |\n",
            "|    total_timesteps              | 9612000       |\n",
            "| train/                          |               |\n",
            "|    approx_kl                    | 0.00076702365 |\n",
            "|    clip_fraction                | 0.0025        |\n",
            "|    clip_range                   | 0.2           |\n",
            "|    entropy_loss                 | -0.762        |\n",
            "|    explained_variance           | 0.69          |\n",
            "|    learning_rate                | 0.0003        |\n",
            "|    loss                         | 153           |\n",
            "|    n_updates                    | 4804          |\n",
            "|    policy_gradient_loss         | -0.000651     |\n",
            "|    value_loss                   | 280           |\n",
            "| train_metrics/                  |               |\n",
            "|    action_queue_updates_success | 368           |\n",
            "|    action_queue_updates_total   | 376           |\n",
            "|    ice_dug                      | 4.68e+03      |\n",
            "|    lichen_produced              | 0             |\n",
            "|    water_produced               | 1.15e+03      |\n",
            "---------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 400          |\n",
            "|    ep_rew_mean                  | 1.13e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2404         |\n",
            "|    time_elapsed                 | 12298        |\n",
            "|    total_timesteps              | 9616000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0029646957 |\n",
            "|    clip_fraction                | 0.0174       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.716       |\n",
            "|    explained_variance           | 0.622        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 111          |\n",
            "|    n_updates                    | 4806         |\n",
            "|    policy_gradient_loss         | 0.00134      |\n",
            "|    value_loss                   | 218          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 369          |\n",
            "|    action_queue_updates_total   | 373          |\n",
            "|    ice_dug                      | 4.39e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.07e+03     |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 400          |\n",
            "|    ep_rew_mean                  | 1.14e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2405         |\n",
            "|    time_elapsed                 | 12304        |\n",
            "|    total_timesteps              | 9620000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0019828943 |\n",
            "|    clip_fraction                | 0.0109       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.748       |\n",
            "|    explained_variance           | 0.683        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 175          |\n",
            "|    n_updates                    | 4808         |\n",
            "|    policy_gradient_loss         | -0.00107     |\n",
            "|    value_loss                   | 364          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 373          |\n",
            "|    action_queue_updates_total   | 376          |\n",
            "|    ice_dug                      | 4.29e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.05e+03     |\n",
            "--------------------------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 400         |\n",
            "|    ep_rew_mean                  | 1.13e+03    |\n",
            "| time/                           |             |\n",
            "|    fps                          | 781         |\n",
            "|    iterations                   | 2406        |\n",
            "|    time_elapsed                 | 12308       |\n",
            "|    total_timesteps              | 9624000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.004187084 |\n",
            "|    clip_fraction                | 0.0289      |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.731      |\n",
            "|    explained_variance           | 0.606       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 134         |\n",
            "|    n_updates                    | 4810        |\n",
            "|    policy_gradient_loss         | -0.000327   |\n",
            "|    value_loss                   | 263         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 363         |\n",
            "|    action_queue_updates_total   | 367         |\n",
            "|    ice_dug                      | 4.29e+03    |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 1.05e+03    |\n",
            "-------------------------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 400         |\n",
            "|    ep_rew_mean                  | 1.14e+03    |\n",
            "| time/                           |             |\n",
            "|    fps                          | 781         |\n",
            "|    iterations                   | 2407        |\n",
            "|    time_elapsed                 | 12313       |\n",
            "|    total_timesteps              | 9628000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.001400429 |\n",
            "|    clip_fraction                | 0.00237     |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.719      |\n",
            "|    explained_variance           | 0.706       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 149         |\n",
            "|    n_updates                    | 4812        |\n",
            "|    policy_gradient_loss         | -0.000734   |\n",
            "|    value_loss                   | 325         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 362         |\n",
            "|    action_queue_updates_total   | 369         |\n",
            "|    ice_dug                      | 4.51e+03    |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 1.1e+03     |\n",
            "-------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 400          |\n",
            "|    ep_rew_mean                  | 1.14e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2408         |\n",
            "|    time_elapsed                 | 12319        |\n",
            "|    total_timesteps              | 9632000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0013210851 |\n",
            "|    clip_fraction                | 0.00362      |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.689       |\n",
            "|    explained_variance           | 0.666        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 160          |\n",
            "|    n_updates                    | 4814         |\n",
            "|    policy_gradient_loss         | -0.00128     |\n",
            "|    value_loss                   | 329          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 363          |\n",
            "|    action_queue_updates_total   | 370          |\n",
            "|    ice_dug                      | 4.6e+03      |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.11e+03     |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 400          |\n",
            "|    ep_rew_mean                  | 1.16e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2409         |\n",
            "|    time_elapsed                 | 12323        |\n",
            "|    total_timesteps              | 9636000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0015441072 |\n",
            "|    clip_fraction                | 0.00362      |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.661       |\n",
            "|    explained_variance           | 0.627        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 150          |\n",
            "|    n_updates                    | 4816         |\n",
            "|    policy_gradient_loss         | 0.000181     |\n",
            "|    value_loss                   | 282          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 370          |\n",
            "|    action_queue_updates_total   | 374          |\n",
            "|    ice_dug                      | 4.98e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.21e+03     |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 400          |\n",
            "|    ep_rew_mean                  | 1.13e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2410         |\n",
            "|    time_elapsed                 | 12327        |\n",
            "|    total_timesteps              | 9640000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0015274961 |\n",
            "|    clip_fraction                | 0.00737      |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.658       |\n",
            "|    explained_variance           | 0.694        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 200          |\n",
            "|    n_updates                    | 4818         |\n",
            "|    policy_gradient_loss         | -0.000712    |\n",
            "|    value_loss                   | 405          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 347          |\n",
            "|    action_queue_updates_total   | 359          |\n",
            "|    ice_dug                      | 3.96e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 945          |\n",
            "--------------------------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 400         |\n",
            "|    ep_rew_mean                  | 1.14e+03    |\n",
            "| time/                           |             |\n",
            "|    fps                          | 781         |\n",
            "|    iterations                   | 2411        |\n",
            "|    time_elapsed                 | 12333       |\n",
            "|    total_timesteps              | 9644000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.008889625 |\n",
            "|    clip_fraction                | 0.0315      |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.699      |\n",
            "|    explained_variance           | 0.711       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 183         |\n",
            "|    n_updates                    | 4820        |\n",
            "|    policy_gradient_loss         | -0.00297    |\n",
            "|    value_loss                   | 404         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 365         |\n",
            "|    action_queue_updates_total   | 373         |\n",
            "|    ice_dug                      | 4.75e+03    |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 1.12e+03    |\n",
            "-------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 400          |\n",
            "|    ep_rew_mean                  | 1.11e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2412         |\n",
            "|    time_elapsed                 | 12338        |\n",
            "|    total_timesteps              | 9648000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0029183147 |\n",
            "|    clip_fraction                | 0.0122       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.654       |\n",
            "|    explained_variance           | 0.523        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 113          |\n",
            "|    n_updates                    | 4822         |\n",
            "|    policy_gradient_loss         | -0.000124    |\n",
            "|    value_loss                   | 235          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 351          |\n",
            "|    action_queue_updates_total   | 356          |\n",
            "|    ice_dug                      | 3.78e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 848          |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 400          |\n",
            "|    ep_rew_mean                  | 1.11e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 782          |\n",
            "|    iterations                   | 2413         |\n",
            "|    time_elapsed                 | 12342        |\n",
            "|    total_timesteps              | 9652000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0028302558 |\n",
            "|    clip_fraction                | 0.0126       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.77        |\n",
            "|    explained_variance           | 0.719        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 393          |\n",
            "|    n_updates                    | 4824         |\n",
            "|    policy_gradient_loss         | 0.00308      |\n",
            "|    value_loss                   | 778          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 373          |\n",
            "|    action_queue_updates_total   | 376          |\n",
            "|    ice_dug                      | 4.61e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.13e+03     |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 400          |\n",
            "|    ep_rew_mean                  | 1.11e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2414         |\n",
            "|    time_elapsed                 | 12348        |\n",
            "|    total_timesteps              | 9656000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0004926316 |\n",
            "|    clip_fraction                | 0.0005       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.718       |\n",
            "|    explained_variance           | 0.677        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 119          |\n",
            "|    n_updates                    | 4826         |\n",
            "|    policy_gradient_loss         | -0.00202     |\n",
            "|    value_loss                   | 246          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 364          |\n",
            "|    action_queue_updates_total   | 368          |\n",
            "|    ice_dug                      | 4.4e+03      |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.06e+03     |\n",
            "--------------------------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 399         |\n",
            "|    ep_rew_mean                  | 1.1e+03     |\n",
            "| time/                           |             |\n",
            "|    fps                          | 782         |\n",
            "|    iterations                   | 2415        |\n",
            "|    time_elapsed                 | 12352       |\n",
            "|    total_timesteps              | 9660000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.004940097 |\n",
            "|    clip_fraction                | 0.034       |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.719      |\n",
            "|    explained_variance           | 0.577       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 147         |\n",
            "|    n_updates                    | 4828        |\n",
            "|    policy_gradient_loss         | 0.00206     |\n",
            "|    value_loss                   | 289         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 361         |\n",
            "|    action_queue_updates_total   | 362         |\n",
            "|    ice_dug                      | 3.96e+03    |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 962         |\n",
            "-------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 399          |\n",
            "|    ep_rew_mean                  | 1.09e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 782          |\n",
            "|    iterations                   | 2416         |\n",
            "|    time_elapsed                 | 12356        |\n",
            "|    total_timesteps              | 9664000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0048988285 |\n",
            "|    clip_fraction                | 0.0362       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.718       |\n",
            "|    explained_variance           | 0.571        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 378          |\n",
            "|    n_updates                    | 4830         |\n",
            "|    policy_gradient_loss         | -0.00166     |\n",
            "|    value_loss                   | 645          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 370          |\n",
            "|    action_queue_updates_total   | 374          |\n",
            "|    ice_dug                      | 4.22e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.01e+03     |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 398          |\n",
            "|    ep_rew_mean                  | 1.08e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 782          |\n",
            "|    iterations                   | 2417         |\n",
            "|    time_elapsed                 | 12362        |\n",
            "|    total_timesteps              | 9668000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0044345567 |\n",
            "|    clip_fraction                | 0.0249       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.759       |\n",
            "|    explained_variance           | 0.749        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 200          |\n",
            "|    n_updates                    | 4832         |\n",
            "|    policy_gradient_loss         | -0.00032     |\n",
            "|    value_loss                   | 432          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 369          |\n",
            "|    action_queue_updates_total   | 369          |\n",
            "|    ice_dug                      | 4.12e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 985          |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 398          |\n",
            "|    ep_rew_mean                  | 1.08e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 782          |\n",
            "|    iterations                   | 2418         |\n",
            "|    time_elapsed                 | 12367        |\n",
            "|    total_timesteps              | 9672000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0014496157 |\n",
            "|    clip_fraction                | 0.00712      |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.741       |\n",
            "|    explained_variance           | 0.493        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 362          |\n",
            "|    n_updates                    | 4834         |\n",
            "|    policy_gradient_loss         | -0.000276    |\n",
            "|    value_loss                   | 751          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 375          |\n",
            "|    action_queue_updates_total   | 381          |\n",
            "|    ice_dug                      | 4.69e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.13e+03     |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 398          |\n",
            "|    ep_rew_mean                  | 1.09e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 782          |\n",
            "|    iterations                   | 2419         |\n",
            "|    time_elapsed                 | 12371        |\n",
            "|    total_timesteps              | 9676000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0018701026 |\n",
            "|    clip_fraction                | 0.00912      |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.682       |\n",
            "|    explained_variance           | 0.599        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 124          |\n",
            "|    n_updates                    | 4836         |\n",
            "|    policy_gradient_loss         | -0.000202    |\n",
            "|    value_loss                   | 244          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 367          |\n",
            "|    action_queue_updates_total   | 373          |\n",
            "|    ice_dug                      | 4.75e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.17e+03     |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 398          |\n",
            "|    ep_rew_mean                  | 1.08e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 782          |\n",
            "|    iterations                   | 2420         |\n",
            "|    time_elapsed                 | 12376        |\n",
            "|    total_timesteps              | 9680000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0036058743 |\n",
            "|    clip_fraction                | 0.0255       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.653       |\n",
            "|    explained_variance           | 0.718        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 163          |\n",
            "|    n_updates                    | 4838         |\n",
            "|    policy_gradient_loss         | 0.000388     |\n",
            "|    value_loss                   | 321          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 352          |\n",
            "|    action_queue_updates_total   | 359          |\n",
            "|    ice_dug                      | 4e+03        |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 968          |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 398          |\n",
            "|    ep_rew_mean                  | 1.07e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 782          |\n",
            "|    iterations                   | 2421         |\n",
            "|    time_elapsed                 | 12381        |\n",
            "|    total_timesteps              | 9684000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0117550995 |\n",
            "|    clip_fraction                | 0.0292       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.668       |\n",
            "|    explained_variance           | 0.678        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 180          |\n",
            "|    n_updates                    | 4840         |\n",
            "|    policy_gradient_loss         | -8.62e-05    |\n",
            "|    value_loss                   | 394          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 354          |\n",
            "|    action_queue_updates_total   | 357          |\n",
            "|    ice_dug                      | 4.22e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 999          |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 397          |\n",
            "|    ep_rew_mean                  | 1.08e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 782          |\n",
            "|    iterations                   | 2422         |\n",
            "|    time_elapsed                 | 12385        |\n",
            "|    total_timesteps              | 9688000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0021407593 |\n",
            "|    clip_fraction                | 0.0147       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.666       |\n",
            "|    explained_variance           | 0.558        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 231          |\n",
            "|    n_updates                    | 4842         |\n",
            "|    policy_gradient_loss         | 0.00255      |\n",
            "|    value_loss                   | 483          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 353          |\n",
            "|    action_queue_updates_total   | 356          |\n",
            "|    ice_dug                      | 4.04e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 969          |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 397          |\n",
            "|    ep_rew_mean                  | 1.06e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 782          |\n",
            "|    iterations                   | 2423         |\n",
            "|    time_elapsed                 | 12390        |\n",
            "|    total_timesteps              | 9692000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0025911434 |\n",
            "|    clip_fraction                | 0.0117       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.658       |\n",
            "|    explained_variance           | 0.53         |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 363          |\n",
            "|    n_updates                    | 4844         |\n",
            "|    policy_gradient_loss         | -0.000383    |\n",
            "|    value_loss                   | 819          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 345          |\n",
            "|    action_queue_updates_total   | 350          |\n",
            "|    ice_dug                      | 3.97e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 939          |\n",
            "--------------------------------------------------\n",
            "Eval num_timesteps=9696000, episode_reward=2926.84 +/- 613.65\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "--------------------------------------------------\n",
            "| eval/                           |              |\n",
            "|    mean_ep_length               | 1e+03        |\n",
            "|    mean_reward                  | 2.93e+03     |\n",
            "| time/                           |              |\n",
            "|    total_timesteps              | 9696000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0038263116 |\n",
            "|    clip_fraction                | 0.0276       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.691       |\n",
            "|    explained_variance           | 0.741        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 248          |\n",
            "|    n_updates                    | 4846         |\n",
            "|    policy_gradient_loss         | -0.00204     |\n",
            "|    value_loss                   | 411          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 372          |\n",
            "|    action_queue_updates_total   | 376          |\n",
            "|    ice_dug                      | 4.88e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.2e+03      |\n",
            "--------------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 397      |\n",
            "|    ep_rew_mean     | 1.07e+03 |\n",
            "| time/              |          |\n",
            "|    fps             | 781      |\n",
            "|    iterations      | 2424     |\n",
            "|    time_elapsed    | 12407    |\n",
            "|    total_timesteps | 9696000  |\n",
            "---------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 398          |\n",
            "|    ep_rew_mean                  | 1.09e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2425         |\n",
            "|    time_elapsed                 | 12412        |\n",
            "|    total_timesteps              | 9700000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0016792786 |\n",
            "|    clip_fraction                | 0.00862      |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.671       |\n",
            "|    explained_variance           | 0.675        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 131          |\n",
            "|    n_updates                    | 4848         |\n",
            "|    policy_gradient_loss         | -0.00131     |\n",
            "|    value_loss                   | 286          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 364          |\n",
            "|    action_queue_updates_total   | 367          |\n",
            "|    ice_dug                      | 4.6e+03      |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.12e+03     |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 397          |\n",
            "|    ep_rew_mean                  | 1.09e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2426         |\n",
            "|    time_elapsed                 | 12416        |\n",
            "|    total_timesteps              | 9704000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0046179206 |\n",
            "|    clip_fraction                | 0.038        |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.678       |\n",
            "|    explained_variance           | 0.728        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 135          |\n",
            "|    n_updates                    | 4850         |\n",
            "|    policy_gradient_loss         | 0.0017       |\n",
            "|    value_loss                   | 286          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 359          |\n",
            "|    action_queue_updates_total   | 365          |\n",
            "|    ice_dug                      | 4.16e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.01e+03     |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 398          |\n",
            "|    ep_rew_mean                  | 1.1e+03      |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2427         |\n",
            "|    time_elapsed                 | 12421        |\n",
            "|    total_timesteps              | 9708000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0011560417 |\n",
            "|    clip_fraction                | 0.000875     |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.662       |\n",
            "|    explained_variance           | 0.484        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 319          |\n",
            "|    n_updates                    | 4852         |\n",
            "|    policy_gradient_loss         | 0.000168     |\n",
            "|    value_loss                   | 602          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 351          |\n",
            "|    action_queue_updates_total   | 363          |\n",
            "|    ice_dug                      | 4.63e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.09e+03     |\n",
            "--------------------------------------------------\n",
            "---------------------------------------------------\n",
            "| rollout/                        |               |\n",
            "|    ep_len_mean                  | 398           |\n",
            "|    ep_rew_mean                  | 1.1e+03       |\n",
            "| time/                           |               |\n",
            "|    fps                          | 781           |\n",
            "|    iterations                   | 2428          |\n",
            "|    time_elapsed                 | 12426         |\n",
            "|    total_timesteps              | 9712000       |\n",
            "| train/                          |               |\n",
            "|    approx_kl                    | 0.00055279897 |\n",
            "|    clip_fraction                | 0.00137       |\n",
            "|    clip_range                   | 0.2           |\n",
            "|    entropy_loss                 | -0.687        |\n",
            "|    explained_variance           | 0.651         |\n",
            "|    learning_rate                | 0.0003        |\n",
            "|    loss                         | 240           |\n",
            "|    n_updates                    | 4854          |\n",
            "|    policy_gradient_loss         | -0.000119     |\n",
            "|    value_loss                   | 460           |\n",
            "| train_metrics/                  |               |\n",
            "|    action_queue_updates_success | 365           |\n",
            "|    action_queue_updates_total   | 369           |\n",
            "|    ice_dug                      | 4.4e+03       |\n",
            "|    lichen_produced              | 0             |\n",
            "|    water_produced               | 1.05e+03      |\n",
            "---------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 397          |\n",
            "|    ep_rew_mean                  | 1.08e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2429         |\n",
            "|    time_elapsed                 | 12431        |\n",
            "|    total_timesteps              | 9716000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0064699575 |\n",
            "|    clip_fraction                | 0.0482       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.688       |\n",
            "|    explained_variance           | 0.681        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 178          |\n",
            "|    n_updates                    | 4856         |\n",
            "|    policy_gradient_loss         | 0.00229      |\n",
            "|    value_loss                   | 324          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 342          |\n",
            "|    action_queue_updates_total   | 359          |\n",
            "|    ice_dug                      | 4.2e+03      |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.02e+03     |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 397          |\n",
            "|    ep_rew_mean                  | 1.1e+03      |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2430         |\n",
            "|    time_elapsed                 | 12436        |\n",
            "|    total_timesteps              | 9720000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0083417455 |\n",
            "|    clip_fraction                | 0.0655       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.737       |\n",
            "|    explained_variance           | 0.534        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 229          |\n",
            "|    n_updates                    | 4858         |\n",
            "|    policy_gradient_loss         | 0.00398      |\n",
            "|    value_loss                   | 603          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 369          |\n",
            "|    action_queue_updates_total   | 373          |\n",
            "|    ice_dug                      | 4.61e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.14e+03     |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 397          |\n",
            "|    ep_rew_mean                  | 1.11e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2431         |\n",
            "|    time_elapsed                 | 12441        |\n",
            "|    total_timesteps              | 9724000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0014357239 |\n",
            "|    clip_fraction                | 0.00762      |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.667       |\n",
            "|    explained_variance           | 0.588        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 160          |\n",
            "|    n_updates                    | 4860         |\n",
            "|    policy_gradient_loss         | -0.00217     |\n",
            "|    value_loss                   | 299          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 358          |\n",
            "|    action_queue_updates_total   | 359          |\n",
            "|    ice_dug                      | 4.5e+03      |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.08e+03     |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 397          |\n",
            "|    ep_rew_mean                  | 1.1e+03      |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2432         |\n",
            "|    time_elapsed                 | 12445        |\n",
            "|    total_timesteps              | 9728000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0096847825 |\n",
            "|    clip_fraction                | 0.0645       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.683       |\n",
            "|    explained_variance           | 0.613        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 227          |\n",
            "|    n_updates                    | 4862         |\n",
            "|    policy_gradient_loss         | -0.00085     |\n",
            "|    value_loss                   | 450          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 316          |\n",
            "|    action_queue_updates_total   | 334          |\n",
            "|    ice_dug                      | 3.62e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 856          |\n",
            "--------------------------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 397         |\n",
            "|    ep_rew_mean                  | 1.11e+03    |\n",
            "| time/                           |             |\n",
            "|    fps                          | 781         |\n",
            "|    iterations                   | 2433        |\n",
            "|    time_elapsed                 | 12451       |\n",
            "|    total_timesteps              | 9732000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.003813576 |\n",
            "|    clip_fraction                | 0.0206      |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.737      |\n",
            "|    explained_variance           | 0.537       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 340         |\n",
            "|    n_updates                    | 4864        |\n",
            "|    policy_gradient_loss         | 0.00142     |\n",
            "|    value_loss                   | 918         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 370         |\n",
            "|    action_queue_updates_total   | 382         |\n",
            "|    ice_dug                      | 4.62e+03    |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 1.11e+03    |\n",
            "-------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 397          |\n",
            "|    ep_rew_mean                  | 1.1e+03      |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2434         |\n",
            "|    time_elapsed                 | 12456        |\n",
            "|    total_timesteps              | 9736000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0030173778 |\n",
            "|    clip_fraction                | 0.0251       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.681       |\n",
            "|    explained_variance           | 0.562        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 148          |\n",
            "|    n_updates                    | 4866         |\n",
            "|    policy_gradient_loss         | -0.000982    |\n",
            "|    value_loss                   | 328          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 374          |\n",
            "|    action_queue_updates_total   | 377          |\n",
            "|    ice_dug                      | 4.68e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.12e+03     |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 397          |\n",
            "|    ep_rew_mean                  | 1.11e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2435         |\n",
            "|    time_elapsed                 | 12460        |\n",
            "|    total_timesteps              | 9740000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0029752501 |\n",
            "|    clip_fraction                | 0.0234       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.647       |\n",
            "|    explained_variance           | 0.635        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 132          |\n",
            "|    n_updates                    | 4868         |\n",
            "|    policy_gradient_loss         | 0.00166      |\n",
            "|    value_loss                   | 323          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 367          |\n",
            "|    action_queue_updates_total   | 376          |\n",
            "|    ice_dug                      | 4.78e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.14e+03     |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 397          |\n",
            "|    ep_rew_mean                  | 1.11e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2436         |\n",
            "|    time_elapsed                 | 12465        |\n",
            "|    total_timesteps              | 9744000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0020863318 |\n",
            "|    clip_fraction                | 0.0109       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.676       |\n",
            "|    explained_variance           | 0.664        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 179          |\n",
            "|    n_updates                    | 4870         |\n",
            "|    policy_gradient_loss         | 0.000822     |\n",
            "|    value_loss                   | 364          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 353          |\n",
            "|    action_queue_updates_total   | 356          |\n",
            "|    ice_dug                      | 4.32e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.04e+03     |\n",
            "--------------------------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 396         |\n",
            "|    ep_rew_mean                  | 1.1e+03     |\n",
            "| time/                           |             |\n",
            "|    fps                          | 781         |\n",
            "|    iterations                   | 2437        |\n",
            "|    time_elapsed                 | 12470       |\n",
            "|    total_timesteps              | 9748000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.011169751 |\n",
            "|    clip_fraction                | 0.0316      |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.679      |\n",
            "|    explained_variance           | 0.707       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 301         |\n",
            "|    n_updates                    | 4872        |\n",
            "|    policy_gradient_loss         | 0.00631     |\n",
            "|    value_loss                   | 612         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 352         |\n",
            "|    action_queue_updates_total   | 361         |\n",
            "|    ice_dug                      | 4.31e+03    |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 1.04e+03    |\n",
            "-------------------------------------------------\n",
            "---------------------------------------------------\n",
            "| rollout/                        |               |\n",
            "|    ep_len_mean                  | 396           |\n",
            "|    ep_rew_mean                  | 1.11e+03      |\n",
            "| time/                           |               |\n",
            "|    fps                          | 781           |\n",
            "|    iterations                   | 2438          |\n",
            "|    time_elapsed                 | 12475         |\n",
            "|    total_timesteps              | 9752000       |\n",
            "| train/                          |               |\n",
            "|    approx_kl                    | 0.00085382944 |\n",
            "|    clip_fraction                | 0.00287       |\n",
            "|    clip_range                   | 0.2           |\n",
            "|    entropy_loss                 | -0.679        |\n",
            "|    explained_variance           | 0.576         |\n",
            "|    learning_rate                | 0.0003        |\n",
            "|    loss                         | 342           |\n",
            "|    n_updates                    | 4874          |\n",
            "|    policy_gradient_loss         | -0.00031      |\n",
            "|    value_loss                   | 697           |\n",
            "| train_metrics/                  |               |\n",
            "|    action_queue_updates_success | 369           |\n",
            "|    action_queue_updates_total   | 375           |\n",
            "|    ice_dug                      | 4.82e+03      |\n",
            "|    lichen_produced              | 0             |\n",
            "|    water_produced               | 1.11e+03      |\n",
            "---------------------------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 397         |\n",
            "|    ep_rew_mean                  | 1.11e+03    |\n",
            "| time/                           |             |\n",
            "|    fps                          | 781         |\n",
            "|    iterations                   | 2439        |\n",
            "|    time_elapsed                 | 12480       |\n",
            "|    total_timesteps              | 9756000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.006776628 |\n",
            "|    clip_fraction                | 0.027       |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.641      |\n",
            "|    explained_variance           | 0.531       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 221         |\n",
            "|    n_updates                    | 4876        |\n",
            "|    policy_gradient_loss         | 0.00309     |\n",
            "|    value_loss                   | 434         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 347         |\n",
            "|    action_queue_updates_total   | 360         |\n",
            "|    ice_dug                      | 4.59e+03    |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 1.09e+03    |\n",
            "-------------------------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 394         |\n",
            "|    ep_rew_mean                  | 1.07e+03    |\n",
            "| time/                           |             |\n",
            "|    fps                          | 781         |\n",
            "|    iterations                   | 2440        |\n",
            "|    time_elapsed                 | 12485       |\n",
            "|    total_timesteps              | 9760000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.004417113 |\n",
            "|    clip_fraction                | 0.0342      |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.687      |\n",
            "|    explained_variance           | 0.728       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 210         |\n",
            "|    n_updates                    | 4878        |\n",
            "|    policy_gradient_loss         | 0.00193     |\n",
            "|    value_loss                   | 425         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 308         |\n",
            "|    action_queue_updates_total   | 320         |\n",
            "|    ice_dug                      | 3.18e+03    |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 739         |\n",
            "-------------------------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 394         |\n",
            "|    ep_rew_mean                  | 1.08e+03    |\n",
            "| time/                           |             |\n",
            "|    fps                          | 781         |\n",
            "|    iterations                   | 2441        |\n",
            "|    time_elapsed                 | 12489       |\n",
            "|    total_timesteps              | 9764000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.017316641 |\n",
            "|    clip_fraction                | 0.065       |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.754      |\n",
            "|    explained_variance           | 0.705       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 532         |\n",
            "|    n_updates                    | 4880        |\n",
            "|    policy_gradient_loss         | 0.0012      |\n",
            "|    value_loss                   | 1e+03       |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 360         |\n",
            "|    action_queue_updates_total   | 365         |\n",
            "|    ice_dug                      | 4.9e+03     |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 1.19e+03    |\n",
            "-------------------------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 396         |\n",
            "|    ep_rew_mean                  | 1.1e+03     |\n",
            "| time/                           |             |\n",
            "|    fps                          | 781         |\n",
            "|    iterations                   | 2442        |\n",
            "|    time_elapsed                 | 12494       |\n",
            "|    total_timesteps              | 9768000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.007221549 |\n",
            "|    clip_fraction                | 0.0434      |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.653      |\n",
            "|    explained_variance           | 0.675       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 190         |\n",
            "|    n_updates                    | 4882        |\n",
            "|    policy_gradient_loss         | -0.00118    |\n",
            "|    value_loss                   | 386         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 360         |\n",
            "|    action_queue_updates_total   | 367         |\n",
            "|    ice_dug                      | 4.51e+03    |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 1.05e+03    |\n",
            "-------------------------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 396         |\n",
            "|    ep_rew_mean                  | 1.1e+03     |\n",
            "| time/                           |             |\n",
            "|    fps                          | 781         |\n",
            "|    iterations                   | 2443        |\n",
            "|    time_elapsed                 | 12500       |\n",
            "|    total_timesteps              | 9772000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.004184941 |\n",
            "|    clip_fraction                | 0.0237      |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.66       |\n",
            "|    explained_variance           | 0.574       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 254         |\n",
            "|    n_updates                    | 4884        |\n",
            "|    policy_gradient_loss         | -0.000453   |\n",
            "|    value_loss                   | 503         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 368         |\n",
            "|    action_queue_updates_total   | 373         |\n",
            "|    ice_dug                      | 4.76e+03    |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 1.1e+03     |\n",
            "-------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 396          |\n",
            "|    ep_rew_mean                  | 1.09e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2444         |\n",
            "|    time_elapsed                 | 12504        |\n",
            "|    total_timesteps              | 9776000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0039339205 |\n",
            "|    clip_fraction                | 0.0171       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.637       |\n",
            "|    explained_variance           | 0.618        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 198          |\n",
            "|    n_updates                    | 4886         |\n",
            "|    policy_gradient_loss         | 0.00526      |\n",
            "|    value_loss                   | 377          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 352          |\n",
            "|    action_queue_updates_total   | 358          |\n",
            "|    ice_dug                      | 4.3e+03      |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.03e+03     |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 396          |\n",
            "|    ep_rew_mean                  | 1.09e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2445         |\n",
            "|    time_elapsed                 | 12509        |\n",
            "|    total_timesteps              | 9780000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0028771623 |\n",
            "|    clip_fraction                | 0.0121       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.666       |\n",
            "|    explained_variance           | 0.763        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 233          |\n",
            "|    n_updates                    | 4888         |\n",
            "|    policy_gradient_loss         | 0.00202      |\n",
            "|    value_loss                   | 441          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 359          |\n",
            "|    action_queue_updates_total   | 363          |\n",
            "|    ice_dug                      | 4.92e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.18e+03     |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 397          |\n",
            "|    ep_rew_mean                  | 1.1e+03      |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2446         |\n",
            "|    time_elapsed                 | 12514        |\n",
            "|    total_timesteps              | 9784000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0007453274 |\n",
            "|    clip_fraction                | 0.001        |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.621       |\n",
            "|    explained_variance           | 0.673        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 127          |\n",
            "|    n_updates                    | 4890         |\n",
            "|    policy_gradient_loss         | 0.00219      |\n",
            "|    value_loss                   | 313          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 357          |\n",
            "|    action_queue_updates_total   | 363          |\n",
            "|    ice_dug                      | 4.55e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.1e+03      |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 398          |\n",
            "|    ep_rew_mean                  | 1.09e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2447         |\n",
            "|    time_elapsed                 | 12518        |\n",
            "|    total_timesteps              | 9788000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0013541394 |\n",
            "|    clip_fraction                | 0.00612      |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.688       |\n",
            "|    explained_variance           | 0.761        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 169          |\n",
            "|    n_updates                    | 4892         |\n",
            "|    policy_gradient_loss         | 0.00119      |\n",
            "|    value_loss                   | 293          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 333          |\n",
            "|    action_queue_updates_total   | 344          |\n",
            "|    ice_dug                      | 3.7e+03      |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 894          |\n",
            "--------------------------------------------------\n",
            "Eval num_timesteps=9792000, episode_reward=2702.52 +/- 796.93\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "--------------------------------------------------\n",
            "| eval/                           |              |\n",
            "|    mean_ep_length               | 1e+03        |\n",
            "|    mean_reward                  | 2.7e+03      |\n",
            "| time/                           |              |\n",
            "|    total_timesteps              | 9792000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0064442465 |\n",
            "|    clip_fraction                | 0.0415       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.718       |\n",
            "|    explained_variance           | 0.699        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 231          |\n",
            "|    n_updates                    | 4894         |\n",
            "|    policy_gradient_loss         | 0.00232      |\n",
            "|    value_loss                   | 481          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 342          |\n",
            "|    action_queue_updates_total   | 343          |\n",
            "|    ice_dug                      | 3.74e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 882          |\n",
            "--------------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 397      |\n",
            "|    ep_rew_mean     | 1.06e+03 |\n",
            "| time/              |          |\n",
            "|    fps             | 781      |\n",
            "|    iterations      | 2448     |\n",
            "|    time_elapsed    | 12532    |\n",
            "|    total_timesteps | 9792000  |\n",
            "---------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 397         |\n",
            "|    ep_rew_mean                  | 1.07e+03    |\n",
            "| time/                           |             |\n",
            "|    fps                          | 781         |\n",
            "|    iterations                   | 2449        |\n",
            "|    time_elapsed                 | 12536       |\n",
            "|    total_timesteps              | 9796000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.014487932 |\n",
            "|    clip_fraction                | 0.0662      |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.743      |\n",
            "|    explained_variance           | 0.792       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 324         |\n",
            "|    n_updates                    | 4896        |\n",
            "|    policy_gradient_loss         | 0.00568     |\n",
            "|    value_loss                   | 695         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 365         |\n",
            "|    action_queue_updates_total   | 366         |\n",
            "|    ice_dug                      | 4.45e+03    |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 1.06e+03    |\n",
            "-------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 399          |\n",
            "|    ep_rew_mean                  | 1.1e+03      |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2450         |\n",
            "|    time_elapsed                 | 12542        |\n",
            "|    total_timesteps              | 9800000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0047772303 |\n",
            "|    clip_fraction                | 0.0266       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.697       |\n",
            "|    explained_variance           | 0.748        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 257          |\n",
            "|    n_updates                    | 4898         |\n",
            "|    policy_gradient_loss         | -0.000265    |\n",
            "|    value_loss                   | 482          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 367          |\n",
            "|    action_queue_updates_total   | 368          |\n",
            "|    ice_dug                      | 4.5e+03      |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.08e+03     |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 399          |\n",
            "|    ep_rew_mean                  | 1.09e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2451         |\n",
            "|    time_elapsed                 | 12547        |\n",
            "|    total_timesteps              | 9804000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0058584823 |\n",
            "|    clip_fraction                | 0.0352       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.651       |\n",
            "|    explained_variance           | 0.694        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 157          |\n",
            "|    n_updates                    | 4900         |\n",
            "|    policy_gradient_loss         | 0.00165      |\n",
            "|    value_loss                   | 306          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 348          |\n",
            "|    action_queue_updates_total   | 352          |\n",
            "|    ice_dug                      | 4.33e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.05e+03     |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 399          |\n",
            "|    ep_rew_mean                  | 1.09e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2452         |\n",
            "|    time_elapsed                 | 12551        |\n",
            "|    total_timesteps              | 9808000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0023748951 |\n",
            "|    clip_fraction                | 0.0114       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.642       |\n",
            "|    explained_variance           | 0.678        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 207          |\n",
            "|    n_updates                    | 4902         |\n",
            "|    policy_gradient_loss         | 0.00163      |\n",
            "|    value_loss                   | 472          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 355          |\n",
            "|    action_queue_updates_total   | 364          |\n",
            "|    ice_dug                      | 4.56e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.1e+03      |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 399          |\n",
            "|    ep_rew_mean                  | 1.08e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2453         |\n",
            "|    time_elapsed                 | 12557        |\n",
            "|    total_timesteps              | 9812000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0014569563 |\n",
            "|    clip_fraction                | 0.013        |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.647       |\n",
            "|    explained_variance           | 0.642        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 215          |\n",
            "|    n_updates                    | 4904         |\n",
            "|    policy_gradient_loss         | -0.000995    |\n",
            "|    value_loss                   | 407          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 337          |\n",
            "|    action_queue_updates_total   | 347          |\n",
            "|    ice_dug                      | 4.24e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 978          |\n",
            "--------------------------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 399         |\n",
            "|    ep_rew_mean                  | 1.08e+03    |\n",
            "| time/                           |             |\n",
            "|    fps                          | 781         |\n",
            "|    iterations                   | 2454        |\n",
            "|    time_elapsed                 | 12561       |\n",
            "|    total_timesteps              | 9816000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.004649808 |\n",
            "|    clip_fraction                | 0.0305      |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.669      |\n",
            "|    explained_variance           | 0.623       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 252         |\n",
            "|    n_updates                    | 4906        |\n",
            "|    policy_gradient_loss         | -0.00171    |\n",
            "|    value_loss                   | 493         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 356         |\n",
            "|    action_queue_updates_total   | 365         |\n",
            "|    ice_dug                      | 4.41e+03    |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 1.06e+03    |\n",
            "-------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 399          |\n",
            "|    ep_rew_mean                  | 1.07e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2455         |\n",
            "|    time_elapsed                 | 12565        |\n",
            "|    total_timesteps              | 9820000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0038695876 |\n",
            "|    clip_fraction                | 0.0239       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.719       |\n",
            "|    explained_variance           | 0.741        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 203          |\n",
            "|    n_updates                    | 4908         |\n",
            "|    policy_gradient_loss         | -0.00113     |\n",
            "|    value_loss                   | 366          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 370          |\n",
            "|    action_queue_updates_total   | 373          |\n",
            "|    ice_dug                      | 4.46e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.08e+03     |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 399          |\n",
            "|    ep_rew_mean                  | 1.06e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2456         |\n",
            "|    time_elapsed                 | 12571        |\n",
            "|    total_timesteps              | 9824000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0040159863 |\n",
            "|    clip_fraction                | 0.0325       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.762       |\n",
            "|    explained_variance           | 0.757        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 215          |\n",
            "|    n_updates                    | 4910         |\n",
            "|    policy_gradient_loss         | -0.00154     |\n",
            "|    value_loss                   | 443          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 358          |\n",
            "|    action_queue_updates_total   | 363          |\n",
            "|    ice_dug                      | 4e+03        |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 957          |\n",
            "--------------------------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 399         |\n",
            "|    ep_rew_mean                  | 1.07e+03    |\n",
            "| time/                           |             |\n",
            "|    fps                          | 781         |\n",
            "|    iterations                   | 2457        |\n",
            "|    time_elapsed                 | 12576       |\n",
            "|    total_timesteps              | 9828000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.012182698 |\n",
            "|    clip_fraction                | 0.0704      |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.665      |\n",
            "|    explained_variance           | 0.655       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 166         |\n",
            "|    n_updates                    | 4912        |\n",
            "|    policy_gradient_loss         | 0.00447     |\n",
            "|    value_loss                   | 379         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 344         |\n",
            "|    action_queue_updates_total   | 352         |\n",
            "|    ice_dug                      | 4.31e+03    |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 1.06e+03    |\n",
            "-------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 400          |\n",
            "|    ep_rew_mean                  | 1.08e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2458         |\n",
            "|    time_elapsed                 | 12580        |\n",
            "|    total_timesteps              | 9832000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0026471526 |\n",
            "|    clip_fraction                | 0.0147       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.629       |\n",
            "|    explained_variance           | 0.776        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 170          |\n",
            "|    n_updates                    | 4914         |\n",
            "|    policy_gradient_loss         | 0.00251      |\n",
            "|    value_loss                   | 362          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 337          |\n",
            "|    action_queue_updates_total   | 349          |\n",
            "|    ice_dug                      | 4.18e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 991          |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 400          |\n",
            "|    ep_rew_mean                  | 1.08e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2459         |\n",
            "|    time_elapsed                 | 12585        |\n",
            "|    total_timesteps              | 9836000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0072353547 |\n",
            "|    clip_fraction                | 0.0349       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.699       |\n",
            "|    explained_variance           | 0.753        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 252          |\n",
            "|    n_updates                    | 4916         |\n",
            "|    policy_gradient_loss         | -0.00345     |\n",
            "|    value_loss                   | 486          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 350          |\n",
            "|    action_queue_updates_total   | 355          |\n",
            "|    ice_dug                      | 4.24e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 980          |\n",
            "--------------------------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 400         |\n",
            "|    ep_rew_mean                  | 1.08e+03    |\n",
            "| time/                           |             |\n",
            "|    fps                          | 781         |\n",
            "|    iterations                   | 2460        |\n",
            "|    time_elapsed                 | 12590       |\n",
            "|    total_timesteps              | 9840000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.006745474 |\n",
            "|    clip_fraction                | 0.0442      |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.725      |\n",
            "|    explained_variance           | 0.679       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 345         |\n",
            "|    n_updates                    | 4918        |\n",
            "|    policy_gradient_loss         | -0.00193    |\n",
            "|    value_loss                   | 771         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 360         |\n",
            "|    action_queue_updates_total   | 376         |\n",
            "|    ice_dug                      | 4.73e+03    |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 1.14e+03    |\n",
            "-------------------------------------------------\n",
            "------------------------------------------------\n",
            "| rollout/                        |            |\n",
            "|    ep_len_mean                  | 400        |\n",
            "|    ep_rew_mean                  | 1.08e+03   |\n",
            "| time/                           |            |\n",
            "|    fps                          | 781        |\n",
            "|    iterations                   | 2461       |\n",
            "|    time_elapsed                 | 12594      |\n",
            "|    total_timesteps              | 9844000    |\n",
            "| train/                          |            |\n",
            "|    approx_kl                    | 0.00187722 |\n",
            "|    clip_fraction                | 0.00825    |\n",
            "|    clip_range                   | 0.2        |\n",
            "|    entropy_loss                 | -0.693     |\n",
            "|    explained_variance           | 0.66       |\n",
            "|    learning_rate                | 0.0003     |\n",
            "|    loss                         | 192        |\n",
            "|    n_updates                    | 4920       |\n",
            "|    policy_gradient_loss         | 0.00194    |\n",
            "|    value_loss                   | 408        |\n",
            "| train_metrics/                  |            |\n",
            "|    action_queue_updates_success | 356        |\n",
            "|    action_queue_updates_total   | 364        |\n",
            "|    ice_dug                      | 4.21e+03   |\n",
            "|    lichen_produced              | 0          |\n",
            "|    water_produced               | 1.03e+03   |\n",
            "------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 400          |\n",
            "|    ep_rew_mean                  | 1.09e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2462         |\n",
            "|    time_elapsed                 | 12599        |\n",
            "|    total_timesteps              | 9848000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0021460727 |\n",
            "|    clip_fraction                | 0.01         |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.683       |\n",
            "|    explained_variance           | 0.658        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 171          |\n",
            "|    n_updates                    | 4922         |\n",
            "|    policy_gradient_loss         | -0.00151     |\n",
            "|    value_loss                   | 322          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 368          |\n",
            "|    action_queue_updates_total   | 376          |\n",
            "|    ice_dug                      | 4.9e+03      |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.18e+03     |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 400          |\n",
            "|    ep_rew_mean                  | 1.1e+03      |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2463         |\n",
            "|    time_elapsed                 | 12604        |\n",
            "|    total_timesteps              | 9852000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0017228592 |\n",
            "|    clip_fraction                | 0.00687      |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.654       |\n",
            "|    explained_variance           | 0.561        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 130          |\n",
            "|    n_updates                    | 4924         |\n",
            "|    policy_gradient_loss         | -0.000808    |\n",
            "|    value_loss                   | 270          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 353          |\n",
            "|    action_queue_updates_total   | 364          |\n",
            "|    ice_dug                      | 4.53e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.1e+03      |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 400          |\n",
            "|    ep_rew_mean                  | 1.11e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2464         |\n",
            "|    time_elapsed                 | 12608        |\n",
            "|    total_timesteps              | 9856000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0029825985 |\n",
            "|    clip_fraction                | 0.0139       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.7         |\n",
            "|    explained_variance           | 0.673        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 156          |\n",
            "|    n_updates                    | 4926         |\n",
            "|    policy_gradient_loss         | 0.00233      |\n",
            "|    value_loss                   | 342          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 360          |\n",
            "|    action_queue_updates_total   | 368          |\n",
            "|    ice_dug                      | 4.74e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.1e+03      |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 399          |\n",
            "|    ep_rew_mean                  | 1.1e+03      |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2465         |\n",
            "|    time_elapsed                 | 12613        |\n",
            "|    total_timesteps              | 9860000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0022725184 |\n",
            "|    clip_fraction                | 0.0151       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.694       |\n",
            "|    explained_variance           | 0.758        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 192          |\n",
            "|    n_updates                    | 4928         |\n",
            "|    policy_gradient_loss         | 0.00149      |\n",
            "|    value_loss                   | 395          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 346          |\n",
            "|    action_queue_updates_total   | 355          |\n",
            "|    ice_dug                      | 4.26e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.04e+03     |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 399          |\n",
            "|    ep_rew_mean                  | 1.12e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2466         |\n",
            "|    time_elapsed                 | 12619        |\n",
            "|    total_timesteps              | 9864000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0052301986 |\n",
            "|    clip_fraction                | 0.0225       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.712       |\n",
            "|    explained_variance           | 0.661        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 158          |\n",
            "|    n_updates                    | 4930         |\n",
            "|    policy_gradient_loss         | 0.000369     |\n",
            "|    value_loss                   | 312          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 377          |\n",
            "|    action_queue_updates_total   | 384          |\n",
            "|    ice_dug                      | 4.71e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.13e+03     |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 399          |\n",
            "|    ep_rew_mean                  | 1.12e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2467         |\n",
            "|    time_elapsed                 | 12623        |\n",
            "|    total_timesteps              | 9868000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0015275286 |\n",
            "|    clip_fraction                | 0.003        |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.718       |\n",
            "|    explained_variance           | 0.664        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 247          |\n",
            "|    n_updates                    | 4932         |\n",
            "|    policy_gradient_loss         | -0.00158     |\n",
            "|    value_loss                   | 487          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 372          |\n",
            "|    action_queue_updates_total   | 377          |\n",
            "|    ice_dug                      | 4.29e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.01e+03     |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 399          |\n",
            "|    ep_rew_mean                  | 1.14e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2468         |\n",
            "|    time_elapsed                 | 12627        |\n",
            "|    total_timesteps              | 9872000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0014416066 |\n",
            "|    clip_fraction                | 0.00862      |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.735       |\n",
            "|    explained_variance           | 0.723        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 177          |\n",
            "|    n_updates                    | 4934         |\n",
            "|    policy_gradient_loss         | 0.00113      |\n",
            "|    value_loss                   | 327          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 368          |\n",
            "|    action_queue_updates_total   | 377          |\n",
            "|    ice_dug                      | 4.86e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.2e+03      |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 399          |\n",
            "|    ep_rew_mean                  | 1.15e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2469         |\n",
            "|    time_elapsed                 | 12633        |\n",
            "|    total_timesteps              | 9876000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0042716293 |\n",
            "|    clip_fraction                | 0.0311       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.686       |\n",
            "|    explained_variance           | 0.692        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 93.9         |\n",
            "|    n_updates                    | 4936         |\n",
            "|    policy_gradient_loss         | 0.00329      |\n",
            "|    value_loss                   | 207          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 362          |\n",
            "|    action_queue_updates_total   | 378          |\n",
            "|    ice_dug                      | 4.52e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.08e+03     |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 399          |\n",
            "|    ep_rew_mean                  | 1.14e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2470         |\n",
            "|    time_elapsed                 | 12637        |\n",
            "|    total_timesteps              | 9880000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0042828172 |\n",
            "|    clip_fraction                | 0.0205       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.722       |\n",
            "|    explained_variance           | 0.607        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 132          |\n",
            "|    n_updates                    | 4938         |\n",
            "|    policy_gradient_loss         | -0.00356     |\n",
            "|    value_loss                   | 281          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 366          |\n",
            "|    action_queue_updates_total   | 372          |\n",
            "|    ice_dug                      | 4.54e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.08e+03     |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 399          |\n",
            "|    ep_rew_mean                  | 1.15e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2471         |\n",
            "|    time_elapsed                 | 12641        |\n",
            "|    total_timesteps              | 9884000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0011433291 |\n",
            "|    clip_fraction                | 0.00162      |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.671       |\n",
            "|    explained_variance           | 0.689        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 145          |\n",
            "|    n_updates                    | 4940         |\n",
            "|    policy_gradient_loss         | -0.000104    |\n",
            "|    value_loss                   | 292          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 376          |\n",
            "|    action_queue_updates_total   | 383          |\n",
            "|    ice_dug                      | 4.77e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.16e+03     |\n",
            "--------------------------------------------------\n",
            "Eval num_timesteps=9888000, episode_reward=2754.00 +/- 310.96\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "--------------------------------------------------\n",
            "| eval/                           |              |\n",
            "|    mean_ep_length               | 1e+03        |\n",
            "|    mean_reward                  | 2.75e+03     |\n",
            "| time/                           |              |\n",
            "|    total_timesteps              | 9888000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0018680599 |\n",
            "|    clip_fraction                | 0.011        |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.647       |\n",
            "|    explained_variance           | 0.564        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 133          |\n",
            "|    n_updates                    | 4942         |\n",
            "|    policy_gradient_loss         | 0.00149      |\n",
            "|    value_loss                   | 280          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 372          |\n",
            "|    action_queue_updates_total   | 378          |\n",
            "|    ice_dug                      | 4.73e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.16e+03     |\n",
            "--------------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 399      |\n",
            "|    ep_rew_mean     | 1.15e+03 |\n",
            "| time/              |          |\n",
            "|    fps             | 781      |\n",
            "|    iterations      | 2472     |\n",
            "|    time_elapsed    | 12655    |\n",
            "|    total_timesteps | 9888000  |\n",
            "---------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 399          |\n",
            "|    ep_rew_mean                  | 1.15e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2473         |\n",
            "|    time_elapsed                 | 12661        |\n",
            "|    total_timesteps              | 9892000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0008269308 |\n",
            "|    clip_fraction                | 0.00112      |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.678       |\n",
            "|    explained_variance           | 0.633        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 143          |\n",
            "|    n_updates                    | 4944         |\n",
            "|    policy_gradient_loss         | -0.0009      |\n",
            "|    value_loss                   | 303          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 370          |\n",
            "|    action_queue_updates_total   | 377          |\n",
            "|    ice_dug                      | 4.6e+03      |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.12e+03     |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 399          |\n",
            "|    ep_rew_mean                  | 1.14e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2474         |\n",
            "|    time_elapsed                 | 12665        |\n",
            "|    total_timesteps              | 9896000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0023309141 |\n",
            "|    clip_fraction                | 0.0162       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.72        |\n",
            "|    explained_variance           | 0.604        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 96.3         |\n",
            "|    n_updates                    | 4946         |\n",
            "|    policy_gradient_loss         | -0.000455    |\n",
            "|    value_loss                   | 204          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 348          |\n",
            "|    action_queue_updates_total   | 363          |\n",
            "|    ice_dug                      | 4.24e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1e+03        |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 400          |\n",
            "|    ep_rew_mean                  | 1.14e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2475         |\n",
            "|    time_elapsed                 | 12669        |\n",
            "|    total_timesteps              | 9900000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0119202165 |\n",
            "|    clip_fraction                | 0.0834       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.739       |\n",
            "|    explained_variance           | 0.625        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 219          |\n",
            "|    n_updates                    | 4948         |\n",
            "|    policy_gradient_loss         | 0.00566      |\n",
            "|    value_loss                   | 477          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 348          |\n",
            "|    action_queue_updates_total   | 361          |\n",
            "|    ice_dug                      | 4.39e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.03e+03     |\n",
            "--------------------------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 400         |\n",
            "|    ep_rew_mean                  | 1.14e+03    |\n",
            "| time/                           |             |\n",
            "|    fps                          | 781         |\n",
            "|    iterations                   | 2476        |\n",
            "|    time_elapsed                 | 12675       |\n",
            "|    total_timesteps              | 9904000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.006563359 |\n",
            "|    clip_fraction                | 0.0449      |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.671      |\n",
            "|    explained_variance           | 0.548       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 149         |\n",
            "|    n_updates                    | 4950        |\n",
            "|    policy_gradient_loss         | 0.00176     |\n",
            "|    value_loss                   | 354         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 364         |\n",
            "|    action_queue_updates_total   | 374         |\n",
            "|    ice_dug                      | 4.68e+03    |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 1.12e+03    |\n",
            "-------------------------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 400         |\n",
            "|    ep_rew_mean                  | 1.16e+03    |\n",
            "| time/                           |             |\n",
            "|    fps                          | 781         |\n",
            "|    iterations                   | 2477        |\n",
            "|    time_elapsed                 | 12679       |\n",
            "|    total_timesteps              | 9908000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.014043048 |\n",
            "|    clip_fraction                | 0.0751      |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.672      |\n",
            "|    explained_variance           | 0.534       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 206         |\n",
            "|    n_updates                    | 4952        |\n",
            "|    policy_gradient_loss         | 0.00854     |\n",
            "|    value_loss                   | 457         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 382         |\n",
            "|    action_queue_updates_total   | 384         |\n",
            "|    ice_dug                      | 5e+03       |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 1.18e+03    |\n",
            "-------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 398          |\n",
            "|    ep_rew_mean                  | 1.14e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2478         |\n",
            "|    time_elapsed                 | 12684        |\n",
            "|    total_timesteps              | 9912000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0016643464 |\n",
            "|    clip_fraction                | 0.00875      |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.653       |\n",
            "|    explained_variance           | 0.823        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 178          |\n",
            "|    n_updates                    | 4954         |\n",
            "|    policy_gradient_loss         | 0.000263     |\n",
            "|    value_loss                   | 365          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 349          |\n",
            "|    action_queue_updates_total   | 356          |\n",
            "|    ice_dug                      | 4.13e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1e+03        |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 398          |\n",
            "|    ep_rew_mean                  | 1.16e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2479         |\n",
            "|    time_elapsed                 | 12689        |\n",
            "|    total_timesteps              | 9916000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0012427305 |\n",
            "|    clip_fraction                | 0.00837      |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.674       |\n",
            "|    explained_variance           | 0.693        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 271          |\n",
            "|    n_updates                    | 4956         |\n",
            "|    policy_gradient_loss         | -0.00133     |\n",
            "|    value_loss                   | 629          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 385          |\n",
            "|    action_queue_updates_total   | 388          |\n",
            "|    ice_dug                      | 5.26e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.28e+03     |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 397          |\n",
            "|    ep_rew_mean                  | 1.16e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2480         |\n",
            "|    time_elapsed                 | 12694        |\n",
            "|    total_timesteps              | 9920000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0021547526 |\n",
            "|    clip_fraction                | 0.0115       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.628       |\n",
            "|    explained_variance           | 0.464        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 172          |\n",
            "|    n_updates                    | 4958         |\n",
            "|    policy_gradient_loss         | 0.000248     |\n",
            "|    value_loss                   | 352          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 362          |\n",
            "|    action_queue_updates_total   | 374          |\n",
            "|    ice_dug                      | 4.57e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.06e+03     |\n",
            "--------------------------------------------------\n",
            "------------------------------------------------\n",
            "| rollout/                        |            |\n",
            "|    ep_len_mean                  | 397        |\n",
            "|    ep_rew_mean                  | 1.16e+03   |\n",
            "| time/                           |            |\n",
            "|    fps                          | 781        |\n",
            "|    iterations                   | 2481       |\n",
            "|    time_elapsed                 | 12698      |\n",
            "|    total_timesteps              | 9924000    |\n",
            "| train/                          |            |\n",
            "|    approx_kl                    | 0.00267709 |\n",
            "|    clip_fraction                | 0.0199     |\n",
            "|    clip_range                   | 0.2        |\n",
            "|    entropy_loss                 | -0.653     |\n",
            "|    explained_variance           | 0.905      |\n",
            "|    learning_rate                | 0.0003     |\n",
            "|    loss                         | 143        |\n",
            "|    n_updates                    | 4960       |\n",
            "|    policy_gradient_loss         | 0.00132    |\n",
            "|    value_loss                   | 354        |\n",
            "| train_metrics/                  |            |\n",
            "|    action_queue_updates_success | 372        |\n",
            "|    action_queue_updates_total   | 379        |\n",
            "|    ice_dug                      | 4.78e+03   |\n",
            "|    lichen_produced              | 0          |\n",
            "|    water_produced               | 1.16e+03   |\n",
            "------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 397          |\n",
            "|    ep_rew_mean                  | 1.15e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2482         |\n",
            "|    time_elapsed                 | 12703        |\n",
            "|    total_timesteps              | 9928000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0018855343 |\n",
            "|    clip_fraction                | 0.0112       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.665       |\n",
            "|    explained_variance           | 0.572        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 155          |\n",
            "|    n_updates                    | 4962         |\n",
            "|    policy_gradient_loss         | 0.00255      |\n",
            "|    value_loss                   | 377          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 364          |\n",
            "|    action_queue_updates_total   | 376          |\n",
            "|    ice_dug                      | 4.43e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.07e+03     |\n",
            "--------------------------------------------------\n",
            "---------------------------------------------------\n",
            "| rollout/                        |               |\n",
            "|    ep_len_mean                  | 397           |\n",
            "|    ep_rew_mean                  | 1.16e+03      |\n",
            "| time/                           |               |\n",
            "|    fps                          | 781           |\n",
            "|    iterations                   | 2483          |\n",
            "|    time_elapsed                 | 12708         |\n",
            "|    total_timesteps              | 9932000       |\n",
            "| train/                          |               |\n",
            "|    approx_kl                    | 0.00090366835 |\n",
            "|    clip_fraction                | 0.00275       |\n",
            "|    clip_range                   | 0.2           |\n",
            "|    entropy_loss                 | -0.715        |\n",
            "|    explained_variance           | 0.735         |\n",
            "|    learning_rate                | 0.0003        |\n",
            "|    loss                         | 237           |\n",
            "|    n_updates                    | 4964          |\n",
            "|    policy_gradient_loss         | 0.000983      |\n",
            "|    value_loss                   | 454           |\n",
            "| train_metrics/                  |               |\n",
            "|    action_queue_updates_success | 375           |\n",
            "|    action_queue_updates_total   | 383           |\n",
            "|    ice_dug                      | 5e+03         |\n",
            "|    lichen_produced              | 0             |\n",
            "|    water_produced               | 1.22e+03      |\n",
            "---------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 397          |\n",
            "|    ep_rew_mean                  | 1.16e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2484         |\n",
            "|    time_elapsed                 | 12712        |\n",
            "|    total_timesteps              | 9936000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0016577458 |\n",
            "|    clip_fraction                | 0.00675      |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.675       |\n",
            "|    explained_variance           | 0.783        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 147          |\n",
            "|    n_updates                    | 4966         |\n",
            "|    policy_gradient_loss         | 0.000514     |\n",
            "|    value_loss                   | 330          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 368          |\n",
            "|    action_queue_updates_total   | 372          |\n",
            "|    ice_dug                      | 4.35e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.04e+03     |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 396          |\n",
            "|    ep_rew_mean                  | 1.16e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2485         |\n",
            "|    time_elapsed                 | 12717        |\n",
            "|    total_timesteps              | 9940000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0011705605 |\n",
            "|    clip_fraction                | 0.008        |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.691       |\n",
            "|    explained_variance           | 0.747        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 222          |\n",
            "|    n_updates                    | 4968         |\n",
            "|    policy_gradient_loss         | 0.000314     |\n",
            "|    value_loss                   | 392          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 356          |\n",
            "|    action_queue_updates_total   | 362          |\n",
            "|    ice_dug                      | 3.91e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 966          |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 396          |\n",
            "|    ep_rew_mean                  | 1.16e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2486         |\n",
            "|    time_elapsed                 | 12723        |\n",
            "|    total_timesteps              | 9944000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0041467343 |\n",
            "|    clip_fraction                | 0.0312       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.741       |\n",
            "|    explained_variance           | 0.863        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 256          |\n",
            "|    n_updates                    | 4970         |\n",
            "|    policy_gradient_loss         | 0.000175     |\n",
            "|    value_loss                   | 526          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 371          |\n",
            "|    action_queue_updates_total   | 376          |\n",
            "|    ice_dug                      | 4.73e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.13e+03     |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 396          |\n",
            "|    ep_rew_mean                  | 1.14e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2487         |\n",
            "|    time_elapsed                 | 12727        |\n",
            "|    total_timesteps              | 9948000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0016382497 |\n",
            "|    clip_fraction                | 0.00737      |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.711       |\n",
            "|    explained_variance           | 0.644        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 169          |\n",
            "|    n_updates                    | 4972         |\n",
            "|    policy_gradient_loss         | 0.000743     |\n",
            "|    value_loss                   | 282          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 358          |\n",
            "|    action_queue_updates_total   | 368          |\n",
            "|    ice_dug                      | 4.34e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.04e+03     |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 397          |\n",
            "|    ep_rew_mean                  | 1.13e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2488         |\n",
            "|    time_elapsed                 | 12732        |\n",
            "|    total_timesteps              | 9952000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0012182265 |\n",
            "|    clip_fraction                | 0.00387      |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.744       |\n",
            "|    explained_variance           | 0.761        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 234          |\n",
            "|    n_updates                    | 4974         |\n",
            "|    policy_gradient_loss         | 0.00157      |\n",
            "|    value_loss                   | 500          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 355          |\n",
            "|    action_queue_updates_total   | 360          |\n",
            "|    ice_dug                      | 4.01e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 960          |\n",
            "--------------------------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 397         |\n",
            "|    ep_rew_mean                  | 1.12e+03    |\n",
            "| time/                           |             |\n",
            "|    fps                          | 781         |\n",
            "|    iterations                   | 2489        |\n",
            "|    time_elapsed                 | 12738       |\n",
            "|    total_timesteps              | 9956000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.009789672 |\n",
            "|    clip_fraction                | 0.0467      |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.746      |\n",
            "|    explained_variance           | 0.911       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 215         |\n",
            "|    n_updates                    | 4976        |\n",
            "|    policy_gradient_loss         | 0.00382     |\n",
            "|    value_loss                   | 414         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 371         |\n",
            "|    action_queue_updates_total   | 374         |\n",
            "|    ice_dug                      | 4.55e+03    |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 1.11e+03    |\n",
            "-------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 398          |\n",
            "|    ep_rew_mean                  | 1.11e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2490         |\n",
            "|    time_elapsed                 | 12742        |\n",
            "|    total_timesteps              | 9960000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0029790658 |\n",
            "|    clip_fraction                | 0.0195       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.719       |\n",
            "|    explained_variance           | 0.765        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 180          |\n",
            "|    n_updates                    | 4978         |\n",
            "|    policy_gradient_loss         | -0.000653    |\n",
            "|    value_loss                   | 404          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 366          |\n",
            "|    action_queue_updates_total   | 369          |\n",
            "|    ice_dug                      | 4.4e+03      |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.04e+03     |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 398          |\n",
            "|    ep_rew_mean                  | 1.12e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2491         |\n",
            "|    time_elapsed                 | 12746        |\n",
            "|    total_timesteps              | 9964000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0037926226 |\n",
            "|    clip_fraction                | 0.0272       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.753       |\n",
            "|    explained_variance           | 0.71         |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 319          |\n",
            "|    n_updates                    | 4980         |\n",
            "|    policy_gradient_loss         | -4.54e-05    |\n",
            "|    value_loss                   | 615          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 369          |\n",
            "|    action_queue_updates_total   | 384          |\n",
            "|    ice_dug                      | 4.93e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.21e+03     |\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 398          |\n",
            "|    ep_rew_mean                  | 1.1e+03      |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2492         |\n",
            "|    time_elapsed                 | 12752        |\n",
            "|    total_timesteps              | 9968000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0019890044 |\n",
            "|    clip_fraction                | 0.0127       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.748       |\n",
            "|    explained_variance           | 0.766        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 243          |\n",
            "|    n_updates                    | 4982         |\n",
            "|    policy_gradient_loss         | 0.000295     |\n",
            "|    value_loss                   | 483          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 366          |\n",
            "|    action_queue_updates_total   | 373          |\n",
            "|    ice_dug                      | 4.21e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 970          |\n",
            "--------------------------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 398         |\n",
            "|    ep_rew_mean                  | 1.09e+03    |\n",
            "| time/                           |             |\n",
            "|    fps                          | 781         |\n",
            "|    iterations                   | 2493        |\n",
            "|    time_elapsed                 | 12756       |\n",
            "|    total_timesteps              | 9972000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.006870826 |\n",
            "|    clip_fraction                | 0.0351      |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.731      |\n",
            "|    explained_variance           | 0.618       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 190         |\n",
            "|    n_updates                    | 4984        |\n",
            "|    policy_gradient_loss         | 0.00408     |\n",
            "|    value_loss                   | 476         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 369         |\n",
            "|    action_queue_updates_total   | 371         |\n",
            "|    ice_dug                      | 4.55e+03    |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 1.1e+03     |\n",
            "-------------------------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 398          |\n",
            "|    ep_rew_mean                  | 1.08e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2494         |\n",
            "|    time_elapsed                 | 12760        |\n",
            "|    total_timesteps              | 9976000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0014516718 |\n",
            "|    clip_fraction                | 0.00812      |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.722       |\n",
            "|    explained_variance           | 0.779        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 159          |\n",
            "|    n_updates                    | 4986         |\n",
            "|    policy_gradient_loss         | 0.00143      |\n",
            "|    value_loss                   | 356          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 362          |\n",
            "|    action_queue_updates_total   | 368          |\n",
            "|    ice_dug                      | 4.26e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1e+03        |\n",
            "--------------------------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 397         |\n",
            "|    ep_rew_mean                  | 1.08e+03    |\n",
            "| time/                           |             |\n",
            "|    fps                          | 781         |\n",
            "|    iterations                   | 2495        |\n",
            "|    time_elapsed                 | 12766       |\n",
            "|    total_timesteps              | 9980000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.009814231 |\n",
            "|    clip_fraction                | 0.0381      |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.769      |\n",
            "|    explained_variance           | 0.732       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 230         |\n",
            "|    n_updates                    | 4988        |\n",
            "|    policy_gradient_loss         | -0.000467   |\n",
            "|    value_loss                   | 553         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 361         |\n",
            "|    action_queue_updates_total   | 364         |\n",
            "|    ice_dug                      | 4.04e+03    |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 882         |\n",
            "-------------------------------------------------\n",
            "Eval num_timesteps=9984000, episode_reward=3217.76 +/- 201.39\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-------------------------------------------------\n",
            "| eval/                           |             |\n",
            "|    mean_ep_length               | 1e+03       |\n",
            "|    mean_reward                  | 3.22e+03    |\n",
            "| time/                           |             |\n",
            "|    total_timesteps              | 9984000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.009575058 |\n",
            "|    clip_fraction                | 0.0637      |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.759      |\n",
            "|    explained_variance           | 0.76        |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 354         |\n",
            "|    n_updates                    | 4990        |\n",
            "|    policy_gradient_loss         | 0.00421     |\n",
            "|    value_loss                   | 798         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 382         |\n",
            "|    action_queue_updates_total   | 386         |\n",
            "|    ice_dug                      | 5e+03       |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 1.19e+03    |\n",
            "-------------------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 397      |\n",
            "|    ep_rew_mean     | 1.09e+03 |\n",
            "| time/              |          |\n",
            "|    fps             | 781      |\n",
            "|    iterations      | 2496     |\n",
            "|    time_elapsed    | 12780    |\n",
            "|    total_timesteps | 9984000  |\n",
            "---------------------------------\n",
            "--------------------------------------------------\n",
            "| rollout/                        |              |\n",
            "|    ep_len_mean                  | 397          |\n",
            "|    ep_rew_mean                  | 1.09e+03     |\n",
            "| time/                           |              |\n",
            "|    fps                          | 781          |\n",
            "|    iterations                   | 2497         |\n",
            "|    time_elapsed                 | 12784        |\n",
            "|    total_timesteps              | 9988000      |\n",
            "| train/                          |              |\n",
            "|    approx_kl                    | 0.0034111242 |\n",
            "|    clip_fraction                | 0.0219       |\n",
            "|    clip_range                   | 0.2          |\n",
            "|    entropy_loss                 | -0.719       |\n",
            "|    explained_variance           | 0.612        |\n",
            "|    learning_rate                | 0.0003       |\n",
            "|    loss                         | 133          |\n",
            "|    n_updates                    | 4992         |\n",
            "|    policy_gradient_loss         | 0.00159      |\n",
            "|    value_loss                   | 294          |\n",
            "| train_metrics/                  |              |\n",
            "|    action_queue_updates_success | 382          |\n",
            "|    action_queue_updates_total   | 384          |\n",
            "|    ice_dug                      | 4.31e+03     |\n",
            "|    lichen_produced              | 0            |\n",
            "|    water_produced               | 1.05e+03     |\n",
            "--------------------------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 398         |\n",
            "|    ep_rew_mean                  | 1.1e+03     |\n",
            "| time/                           |             |\n",
            "|    fps                          | 781         |\n",
            "|    iterations                   | 2498        |\n",
            "|    time_elapsed                 | 12788       |\n",
            "|    total_timesteps              | 9992000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.005490379 |\n",
            "|    clip_fraction                | 0.0365      |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.752      |\n",
            "|    explained_variance           | 0.755       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 201         |\n",
            "|    n_updates                    | 4994        |\n",
            "|    policy_gradient_loss         | 0.00152     |\n",
            "|    value_loss                   | 387         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 362         |\n",
            "|    action_queue_updates_total   | 370         |\n",
            "|    ice_dug                      | 4.25e+03    |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 1.03e+03    |\n",
            "-------------------------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 398         |\n",
            "|    ep_rew_mean                  | 1.1e+03     |\n",
            "| time/                           |             |\n",
            "|    fps                          | 781         |\n",
            "|    iterations                   | 2499        |\n",
            "|    time_elapsed                 | 12794       |\n",
            "|    total_timesteps              | 9996000     |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.001388611 |\n",
            "|    clip_fraction                | 0.00537     |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.714      |\n",
            "|    explained_variance           | 0.85        |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 191         |\n",
            "|    n_updates                    | 4996        |\n",
            "|    policy_gradient_loss         | -0.000426   |\n",
            "|    value_loss                   | 417         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 362         |\n",
            "|    action_queue_updates_total   | 373         |\n",
            "|    ice_dug                      | 4.41e+03    |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 1.07e+03    |\n",
            "-------------------------------------------------\n",
            "-------------------------------------------------\n",
            "| rollout/                        |             |\n",
            "|    ep_len_mean                  | 398         |\n",
            "|    ep_rew_mean                  | 1.12e+03    |\n",
            "| time/                           |             |\n",
            "|    fps                          | 781         |\n",
            "|    iterations                   | 2500        |\n",
            "|    time_elapsed                 | 12799       |\n",
            "|    total_timesteps              | 10000000    |\n",
            "| train/                          |             |\n",
            "|    approx_kl                    | 0.007068691 |\n",
            "|    clip_fraction                | 0.0441      |\n",
            "|    clip_range                   | 0.2         |\n",
            "|    entropy_loss                 | -0.686      |\n",
            "|    explained_variance           | 0.819       |\n",
            "|    learning_rate                | 0.0003      |\n",
            "|    loss                         | 146         |\n",
            "|    n_updates                    | 4998        |\n",
            "|    policy_gradient_loss         | -0.000501   |\n",
            "|    value_loss                   | 321         |\n",
            "| train_metrics/                  |             |\n",
            "|    action_queue_updates_success | 379         |\n",
            "|    action_queue_updates_total   | 384         |\n",
            "|    ice_dug                      | 5.18e+03    |\n",
            "|    lichen_produced              | 0           |\n",
            "|    water_produced               | 1.27e+03    |\n",
            "-------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo '' > debug.log ; cat debug.log"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71MAXA-Chaac",
        "outputId": "9f2e9a51-d0b6-41a6-e865-e1d32b80cbee"
      },
      "id": "71MAXA-Chaac",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!luxai-s2 main.py main.py -v 2 -s 5 -o replay.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFukwNNoc2wF",
        "outputId": "58bc4462-9130-413a-ba5a-49d373bd690c"
      },
      "id": "GFukwNNoc2wF",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pygame 2.3.0 (SDL 2.24.2, Python 3.9.16)\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
            "-4: player_1 tried to perform an action in the early phase when it is not its turn right now.\n",
            "93: Invalid Dig Action for unit \u001b[33m[1] unit_3 UnitType.HEAVY at (2, 39)\u001b[0m - Tried to dig requiring 60 power\n",
            "94: Invalid Dig Action for unit \u001b[33m[1] unit_3 UnitType.HEAVY at (2, 39)\u001b[0m - Tried to dig requiring 60 power\n",
            "149: Invalid Dig Action for unit \u001b[33m[0] unit_2 UnitType.HEAVY at (10, 3)\u001b[0m - Tried to dig requiring 60 power\n",
            "150: Invalid Dig Action for unit \u001b[33m[0] unit_2 UnitType.HEAVY at (10, 3)\u001b[0m - Tried to dig requiring 60 power\n",
            "152: Invalid movement action for unit \u001b[33m[0] unit_2 UnitType.HEAVY at (10, 3)\u001b[0m - Tried to move to (10, 2) requiring 20 power\n",
            "153: Invalid movement action for unit \u001b[33m[0] unit_2 UnitType.HEAVY at (10, 3)\u001b[0m - Tried to move to (10, 2) requiring 20 power\n",
            "244: Invalid Dig Action for unit \u001b[33m[1] unit_3 UnitType.HEAVY at (2, 39)\u001b[0m - Tried to dig requiring 60 power\n",
            "245: Invalid Dig Action for unit \u001b[33m[1] unit_3 UnitType.HEAVY at (2, 39)\u001b[0m - Tried to dig requiring 60 power\n",
            "246: Invalid Dig Action for unit \u001b[33m[1] unit_3 UnitType.HEAVY at (2, 39)\u001b[0m - Tried to dig requiring 60 power\n",
            "247: Invalid Dig Action for unit \u001b[33m[0] unit_2 UnitType.HEAVY at (10, 3)\u001b[0m - Tried to dig requiring 60 power\n",
            "247: Invalid Dig Action for unit \u001b[33m[1] unit_3 UnitType.HEAVY at (2, 39)\u001b[0m - Tried to dig requiring 60 power\n",
            "248: Invalid Dig Action for unit \u001b[33m[0] unit_2 UnitType.HEAVY at (10, 3)\u001b[0m - Tried to dig requiring 60 power\n",
            "249: Invalid Dig Action for unit \u001b[33m[0] unit_2 UnitType.HEAVY at (10, 3)\u001b[0m - Tried to dig requiring 60 power\n",
            "249: Invalid movement action for unit \u001b[33m[1] unit_3 UnitType.HEAVY at (2, 39)\u001b[0m - Tried to move to (2, 38) requiring 20 power\n",
            "250: Invalid Dig Action for unit \u001b[33m[0] unit_2 UnitType.HEAVY at (10, 3)\u001b[0m - Tried to dig requiring 60 power\n",
            "250: Invalid Dig Action for unit \u001b[33m[1] unit_3 UnitType.HEAVY at (2, 39)\u001b[0m - Tried to dig requiring 60 power\n",
            "251: Invalid Dig Action for unit \u001b[33m[0] unit_2 UnitType.HEAVY at (10, 3)\u001b[0m - Tried to dig requiring 60 power\n",
            "251: Invalid movement action for unit \u001b[33m[1] unit_3 UnitType.HEAVY at (2, 39)\u001b[0m - Tried to move to (2, 38) requiring 20 power\n",
            "252: Invalid movement action for unit \u001b[33m[1] unit_3 UnitType.HEAVY at (2, 39)\u001b[0m - Tried to move to (2, 38) requiring 20 power\n",
            "254: Invalid movement action for unit \u001b[33m[0] unit_2 UnitType.HEAVY at (10, 3)\u001b[0m - Tried to move to (10, 2) requiring 20 power\n",
            "255: Invalid movement action for unit \u001b[33m[0] unit_2 UnitType.HEAVY at (10, 3)\u001b[0m - Tried to move to (10, 2) requiring 20 power\n",
            "417: Invalid Dig Action for unit \u001b[33m[1] unit_3 UnitType.HEAVY at (2, 39)\u001b[0m - Tried to dig requiring 60 power\n",
            "420: Invalid movement action for unit \u001b[33m[1] unit_3 UnitType.HEAVY at (2, 39)\u001b[0m - Tried to move to (2, 38) requiring 20 power\n",
            "421: Invalid movement action for unit \u001b[33m[1] unit_3 UnitType.HEAVY at (2, 39)\u001b[0m - Tried to move to (2, 38) requiring 20 power\n",
            "607: Invalid Dig Action for unit \u001b[33m[0] unit_2 UnitType.HEAVY at (10, 3)\u001b[0m - Tried to dig requiring 60 power\n",
            "608: Invalid Dig Action for unit \u001b[33m[0] unit_2 UnitType.HEAVY at (10, 3)\u001b[0m - Tried to dig requiring 60 power\n",
            "754: Invalid Dig Action for unit \u001b[33m[0] unit_2 UnitType.HEAVY at (10, 3)\u001b[0m - Tried to dig requiring 60 power\n",
            "755: Invalid Dig Action for unit \u001b[33m[0] unit_2 UnitType.HEAVY at (10, 3)\u001b[0m - Tried to dig requiring 60 power\n",
            "817: Invalid Dig Action for unit \u001b[33m[0] unit_2 UnitType.HEAVY at (10, 3)\u001b[0m - Tried to dig requiring 60 power\n",
            "848: Invalid Dig Action for unit \u001b[33m[0] unit_2 UnitType.HEAVY at (10, 3)\u001b[0m - Tried to dig requiring 60 power\n",
            "849: Invalid Dig Action for unit \u001b[33m[0] unit_2 UnitType.HEAVY at (10, 3)\u001b[0m - Tried to dig requiring 60 power\n",
            "850: Invalid Dig Action for unit \u001b[33m[0] unit_2 UnitType.HEAVY at (10, 3)\u001b[0m - Tried to dig requiring 60 power\n",
            "851: Invalid Dig Action for unit \u001b[33m[0] unit_2 UnitType.HEAVY at (10, 3)\u001b[0m - Tried to dig requiring 60 power\n",
            "853: Invalid Dig Action for unit \u001b[33m[0] unit_2 UnitType.HEAVY at (10, 3)\u001b[0m - Tried to dig requiring 60 power\n",
            "854: Invalid Dig Action for unit \u001b[33m[0] unit_2 UnitType.HEAVY at (10, 3)\u001b[0m - Tried to dig requiring 60 power\n",
            "855: Invalid Dig Action for unit \u001b[33m[0] unit_2 UnitType.HEAVY at (10, 3)\u001b[0m - Tried to dig requiring 60 power\n",
            "856: Invalid Dig Action for unit \u001b[33m[0] unit_2 UnitType.HEAVY at (10, 3)\u001b[0m - Tried to dig requiring 60 power\n",
            "857: Invalid Dig Action for unit \u001b[33m[0] unit_2 UnitType.HEAVY at (10, 3)\u001b[0m - Tried to dig requiring 60 power\n",
            "858: Invalid Dig Action for unit \u001b[33m[0] unit_2 UnitType.HEAVY at (10, 3)\u001b[0m - Tried to dig requiring 60 power\n",
            "860: Invalid Dig Action for unit \u001b[33m[0] unit_2 UnitType.HEAVY at (10, 3)\u001b[0m - Tried to dig requiring 60 power\n",
            "862: Invalid movement action for unit \u001b[33m[0] unit_2 UnitType.HEAVY at (10, 3)\u001b[0m - Tried to move to (10, 2) requiring 20 power\n",
            "863: Invalid movement action for unit \u001b[33m[0] unit_2 UnitType.HEAVY at (10, 3)\u001b[0m - Tried to move to (10, 2) requiring 20 power\n",
            "5.953142404556274\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "689bd051",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T21:08:26.746226Z",
          "iopub.status.busy": "2023-02-20T21:08:26.7444Z",
          "iopub.status.idle": "2023-02-20T21:08:27.511818Z",
          "shell.execute_reply": "2023-02-20T21:08:27.51005Z"
        },
        "papermill": {
          "duration": 1.050097,
          "end_time": "2023-02-20T21:08:27.514671",
          "exception": false,
          "start_time": "2023-02-20T21:08:26.464574",
          "status": "completed"
        },
        "tags": [],
        "id": "689bd051"
      },
      "outputs": [],
      "source": [
        "# if running on kaggle, run below to copy the rl starter kit files to the working directory\n",
        "!cp -r ../input/luxai-s2-rl-sb3-kit/* .\n",
        "!mv best_model.dontunzipme best_model.zip # kaggle auto unzips files but we don't want it to here so we do this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a09869a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T21:08:28.035127Z",
          "iopub.status.busy": "2023-02-20T21:08:28.034693Z",
          "iopub.status.idle": "2023-02-20T21:08:28.345495Z",
          "shell.execute_reply": "2023-02-20T21:08:28.343299Z"
        },
        "papermill": {
          "duration": 0.578032,
          "end_time": "2023-02-20T21:08:28.348563",
          "exception": false,
          "start_time": "2023-02-20T21:08:27.770531",
          "status": "completed"
        },
        "tags": [],
        "id": "0a09869a"
      },
      "outputs": [],
      "source": [
        "# if you trained an actual agent, copy its model weights here\n",
        "!mv logs/exp_1/models/best_model.zip best_model.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82cffddf",
      "metadata": {
        "papermill": {
          "duration": 0.244234,
          "end_time": "2023-02-20T21:08:28.844464",
          "exception": false,
          "start_time": "2023-02-20T21:08:28.60023",
          "status": "completed"
        },
        "tags": [],
        "id": "82cffddf"
      },
      "source": [
        "\n",
        "To submit your trained agent create a .tar.gz file. You can download the submission.tar.gz file from the right and submit it to the competition directly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e79d5cde",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T21:08:29.3511Z",
          "iopub.status.busy": "2023-02-20T21:08:29.350631Z",
          "iopub.status.idle": "2023-02-20T21:08:29.852735Z",
          "shell.execute_reply": "2023-02-20T21:08:29.851137Z"
        },
        "papermill": {
          "duration": 0.754135,
          "end_time": "2023-02-20T21:08:29.855605",
          "exception": false,
          "start_time": "2023-02-20T21:08:29.10147",
          "status": "completed"
        },
        "tags": [],
        "id": "e79d5cde",
        "outputId": "22fcadab-4fdb-4162-e772-3c950aa9c39b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "README.md\r\n",
            "__notebook__.ipynb\r\n",
            "agent.py\r\n",
            "best_model.zip\r\n",
            "logs/\r\n",
            "logs/exp_1/\r\n",
            "logs/exp_1/eval_logs/\r\n",
            "logs/exp_1/eval_logs/evaluations.npz\r\n",
            "logs/exp_1/models/\r\n",
            "logs/exp_1/models/latest_model.zip\r\n",
            "logs/exp_1/PPO_1/\r\n",
            "logs/exp_1/PPO_1/events.out.tfevents.1676914953.84745ea85515.19.0\r\n",
            "lux/\r\n",
            "lux/team.py\r\n",
            "lux/config.py\r\n",
            "lux/cargo.py\r\n",
            "lux/factory.py\r\n",
            "lux/__init__.py\r\n",
            "lux/kit.py\r\n",
            "lux/utils.py\r\n",
            "lux/unit.py\r\n",
            "main.py\r\n",
            "train.py\r\n",
            "wrappers/\r\n",
            "wrappers/controllers.py\r\n",
            "wrappers/obs_wrappers.py\r\n",
            "wrappers/__init__.py\r\n"
          ]
        }
      ],
      "source": [
        "!tar -cvzf submission.tar.gz *"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9b81a1a",
      "metadata": {
        "papermill": {
          "duration": 0.237095,
          "end_time": "2023-02-20T21:08:30.343678",
          "exception": false,
          "start_time": "2023-02-20T21:08:30.106583",
          "status": "completed"
        },
        "tags": [],
        "id": "d9b81a1a"
      },
      "source": [
        "## Tips for Improving your Agent\n",
        "\n",
        "This tutorial agent will train a policy that can efficiently control a single heavy robot that learns to pickup power, constantly dig ice, and transfer ice back to the factory and survive the full 1000 turns in the game. A simple improvement would be to add lichen planting to the action space / controller or program it directly as a rule in the agent.py file, allowing you to score points by the end of the game as well as generate more power.\n",
        "\n",
        "Another easy idea is to modify the `agent.py` code so that you spawn multiple factories and multiple heavy robots, and simply run the trained policy on each heavy robot.\n",
        "\n",
        "\n",
        "If you want to look into more scalable solutions, it's critical to first figure out how to model multiple units at once. This kit shows you how to control a single heavy robot effectively but not multiple. Another thing to consider is what observations and features would be the most useful. Finally, you can always try and develop a more complex action controller in addition to developing better reward functions.\n",
        "\n",
        "If you feel you are experienced enough, you can take a look at [last season's winning solution by team Toad Brigade](https://www.kaggle.com/competitions/lux-ai-2021/discussion/294993) or [our paper: Emergent collective intelligence from massive-agent cooperation and competition](https://arxiv.org/abs/2301.01609) which show how to use convolutional neural nets and various other techniques (e.g. invalid action masking) to control a massive number of units at once."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 12452.19971,
      "end_time": "2023-02-20T21:08:33.226852",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2023-02-20T17:41:01.027142",
      "version": "2.3.4"
    },
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}